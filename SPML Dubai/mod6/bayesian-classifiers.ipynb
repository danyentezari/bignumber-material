{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Classifiers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example (1) Classifying for Categorical Features**\n",
    "\n",
    "Consider the following frequency table for the Iris data set with $N = 150$, and, specifically, two features: Sepal Length $= X_1$ and Sepal Width $= X_2$.\n",
    "\n",
    "All $150$ observations fall into one of two classes: $c_1$ and $c_2$. The prior probabilities for the classes are:\n",
    "- $P(c_1) = 50/150 = 0.333$\n",
    "- $P(c_2) = 100/150 = 0.67$\n",
    "\n",
    "For some observation $\\mathbf{x} = (5.3,3.0)^T$, where $5.3 \\in X_1$ and $3.0 \\in X_2$, we can find the class to which $x$ belons as follows.\n",
    "\n",
    "1. Find the $X_1$ bin in which $5.3$ falls.\n",
    "2. Find the $X_2$ bin in which $3.0$ falls.\n",
    "3. Note down the prior probability $P(c_i)$ for the class\n",
    "4. Lookup the likelihood $P(\\mathbf{x} | c_i)$ (i.e, joint probabilities of $X_1$ and $X_2$ ) in the frequency table.\n",
    "5. Calculate the posterior probability $f(c_i | \\mathbf{x}) \\propto P(\\mathbf{x} | c_i) \\times P(c_i)$\n",
    "6. Repeat step (1-5) for all classes\n",
    "7. Compare posteriors for all classes, $c_i$. The class with the highest posterior probability is the class to which $\\mathbf{x}$ belongs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$X_1 = $ Sepal Length**\n",
    "| Bins | Type |\n",
    "|-|-|\n",
    "| $[4.3, 5.2]$ | Very Short |\n",
    "| $(5.2, 6.1]$ | Short |\n",
    "| $(6.1, 7.0]$ | Long |\n",
    "| $(7.0, 7.9]$ | Very long |\n",
    "\n",
    "<br/>\n",
    "\n",
    "**$X_2 = $ Sepal Width**\n",
    "| Bins | Type |\n",
    "|-|-|\n",
    "| $[2.0, 2.8]$ | Short |\n",
    "| $(2.8, 3.6]$ | Medium |\n",
    "| $(3.6, 4.4]$ | Long |\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Class 1**\n",
    "| | $X_{2 \\text{, short}}$ | $X_{2 \\text{, medium}}$ | $X_{2 \\text{, long}}$ | $X_{1, \\text{total}}$ |\n",
    "|-|-|-|-|-|\n",
    "|$X_{1 \\text{, very short}}$ | 1/50 | 33/50 | 5/50 | 39/50 |\n",
    "|$X_{1 \\text{, short}}$ | 0 | 3/50 | 8/50 | 11/50 |\n",
    "|$X_{1 \\text{, long}}$ |0 | 0 | 0 | 0 |\n",
    "|$X_{1 \\text{, very long}}$ | 0 | 0 | 0 | 0 |\n",
    "|$X_{2, \\text{total}}$| 1/50 | 36/50 | 13/50 | 50/50 |\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Class 2**\n",
    "| | $X_{2 \\text{, short}}$ | $X_{2 \\text{, medium}}$ | $X_{2 \\text{, long}}$ | **$X_{1, \\text{total}}$** |\n",
    "|-|-|-|-|-|\n",
    "|$X_{1 \\text{, very short}}$ | 6/100 | 0 | 0 | 6/100 |\n",
    "|$X_{1 \\text{, short}}$ | 24/100 | 15/100 | 0 | 39/100 |\n",
    "|$X_{1 \\text{, long}}$ | 13/100 | 30/100 | 0 | 43/100 |\n",
    "|$X_{1 \\text{, very long}}$ | 3/100 | 7/100 | 2/100 | 12/100 |\n",
    "| **$X_{2, \\text{total}}$** | 46/100 | 52/100 | 2/100 | 100/100 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding $f(c_1 | \\mathbf{x})$**\n",
    "\n",
    "$$f(c_1 | \\mathbf{x}) \\propto P(\\mathbf{x} | c_1) \\times P(c_1) = 0.06 \\times 0.33 = 0.0198$$\n",
    "\n",
    "where\n",
    "- $P(c_1) = 50/150 = 0.333$\n",
    "- $P(\\mathbf{x} | c_1) = 3/50 = 0.06$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example (2) Classifying for Continuous Features**\n",
    "\n",
    "Given the following dataset, use the Bayesian Rule to classify the observation\n",
    "\n",
    "- $P(c_1 | \\mathbf{x}) \\propto p(\\mathbf{x}|c) \\times p(c_1)$\n",
    "- $\\mathbf{x} = (5.3, 3.0)$\n",
    "\n",
    "where\n",
    "- $n$ is sample size\n",
    "\n",
    "- $\\hat{P}(c_1) = \\dfrac{n_1}{n} = 50/150$ is the prior probability for $c_1$\n",
    "\n",
    "- $\\hat{P}(c_2) = \\dfrac{n_2}{n} = 100/150$  is the prior probability for $c_2$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PDF of a multivariate gaussian is given by\n",
    "$$f(\\mathbf{x}) = \\dfrac{1}{\\sqrt{(2\\pi)^k \\det(\\Sigma)}} \\exp \\left[-\\dfrac{1}{2} (\\mathbf{x} - \\mathbf{\\mu})^T \\: \\Sigma^{-1} (\\mathbf{x} - \\mathbf{\\mu})\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 1 probability: 1.6486729528270847e-07\n",
      "class 2 probability: 0.00665754843814572\n",
      "[6.75 4.25] is class 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "import numpy as np\n",
    "def f(x, mu, sigma):\n",
    "    \"\"\"\n",
    "    Compute the probability density function (PDF) of a multivariate Gaussian distribution.\n",
    "\n",
    "    Args:\n",
    "        x (array-like): Observation feature(s)\n",
    "        mu (array-like): Point of center of class distribution\n",
    "        covariance (array-like): Covariance matrix of the distribution.\n",
    "\n",
    "    Returns:\n",
    "        pdf (float or ndarray): Probability density value(s) for the given data point(s).\n",
    "    \"\"\"\n",
    "    k = len(mu)\n",
    "    det_cov = np.linalg.det(sigma)\n",
    "    sigma_inv = np.linalg.inv(sigma)\n",
    "    x_mu = x - mu\n",
    "    exponent = -(1/2) * np.dot(np.dot(x_mu.T, sigma_inv), x_mu)\n",
    "    coefficient = 1 / np.sqrt((2 * np.pi) ** k * det_cov)\n",
    "    pdf = coefficient * np.exp(exponent)\n",
    "    return pdf\n",
    "\n",
    "\n",
    "# Given\n",
    "x = np.array([ 6.75,4.25]).T\n",
    "\n",
    "\n",
    "# Class 1 Parameters\n",
    "mu_1 = np.array([ 5.006, 3.418 ])\n",
    "\n",
    "sigma_1 = np.array(\n",
    "    [\n",
    "        [0.1218, 0.0983],\n",
    "        [0.0983, 0.1423]\n",
    "    ]\n",
    ")\n",
    "\n",
    "sigma_1_inv = inv(sigma_1)\n",
    "\n",
    "prior_1 = 0.333\n",
    "likeihood_1 = f(x, mu_1, sigma_1)\n",
    "posterior_1 = likeihood_1 * prior_1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Class 2 Parameters\n",
    "mu_2 = np.array([ 5.006, 3.418 ])\n",
    "\n",
    "sigma_2 = np.array(\n",
    "    [\n",
    "        [0.435, 0.1209],\n",
    "        [0.1209, 0.435]\n",
    "    ]\n",
    ")\n",
    "\n",
    "sigma_2_inv = inv(sigma_2)\n",
    "\n",
    "prior_2 = 0.67\n",
    "likeihood_2 = f(x, mu_2, sigma_2)\n",
    "posterior_2 = likeihood_2 * prior_2\n",
    "\n",
    "\n",
    "# Classification Result\n",
    "print(f\"class 1 probability: {posterior_1}\")\n",
    "print(f\"class 2 probability: {posterior_2}\")\n",
    "\n",
    "if posterior_2 > posterior_1:\n",
    "    print(f\"{x} is class 2\")\n",
    "else:\n",
    "    print(f\"{x} is class 1\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6486729528271024e-07"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using scipy for calculating multivariate gaussian probability\n",
    "import scipy.stats as stats\n",
    "likeihood = stats.multivariate_normal.pdf(x, mu_1, sigma_1)\n",
    "prior = 0.333\n",
    "\n",
    "posterior = likeihood * prior\n",
    "posterior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
