WEBVTT - This file was automatically generated by VIMEO

0
00:00:00.600 --> 00:00:02.700
So today is the session.

1
00:00:06.400 --> 00:00:07.900
I want to start with the

2
00:00:11.700 --> 00:00:14.400
motivating reason before we continue with

3
00:00:14.400 --> 00:00:17.200
 the mathematics because in our last session

4
00:00:18.700 --> 00:00:19.700
I don't think it.

5
00:00:22.500 --> 00:00:25.800
we quite appreciated the

6
00:00:25.800 --> 00:00:26.600
 usefulness of

7
00:00:28.300 --> 00:00:31.300
the topics we're talking about, you

8
00:00:31.300 --> 00:00:31.700
 know, the

9
00:00:32.800 --> 00:00:35.700
Determinant of the Matrix eigenvectors. I

10
00:00:35.700 --> 00:00:38.800
 you know the stuff we talked about and I

11
00:00:38.800 --> 00:00:39.600
 think I should have started.

12
00:00:41.100 --> 00:00:42.300
that session perhaps the way

13
00:00:43.100 --> 00:00:45.200
kind of like what I was a

14
00:00:45.800 --> 00:00:46.700
what I'm gonna do now.

15
00:00:47.800 --> 00:00:50.100
so, of course if you remember the slides we said that we want

16
00:00:50.100 --> 00:00:53.300
 to work our way up to understanding this

17
00:00:53.300 --> 00:00:56.200
 thing called as yeah SVD and then

18
00:00:56.200 --> 00:00:58.000
 from there to PCA because

19
00:00:59.500 --> 00:01:02.900
we know we said it has a very nice applications and

20
00:01:02.900 --> 00:01:03.500
 in particular.

21
00:01:04.400 --> 00:01:05.700
I mean machine learning.

22
00:01:06.700 --> 00:01:08.900
I want to this time just to make it.

23
00:01:11.700 --> 00:01:11.900
You know.

24
00:01:12.900 --> 00:01:14.300
more interesting start

25
00:01:16.900 --> 00:01:17.100
not

26
00:01:20.200 --> 00:01:23.500
from where we are going to be and then work our way backwards,

27
00:01:23.500 --> 00:01:27.200
 but partially I'm going to do that. So I'm going

28
00:01:27.200 --> 00:01:29.900
 to give you a very small insight into

29
00:01:32.200 --> 00:01:32.900
machine learning

30
00:01:34.200 --> 00:01:36.400
so we will kind of go into statistics for for.

31
00:01:37.900 --> 00:01:40.500
It's a take a step in the

32
00:01:40.500 --> 00:01:43.200
 direction of Statistics briefly so we can

33
00:01:43.200 --> 00:01:46.200
 see you know, where PC could then help us with machine learning?

34
00:01:48.600 --> 00:01:51.500
And then we will make this session of the session that comes on Friday

35
00:01:51.500 --> 00:01:54.100
 about SVD and PCA.

36
00:01:55.200 --> 00:01:57.900
Okay, so first I'm going to talk about.

37
00:02:05.600 --> 00:02:06.200
prediction

38
00:02:10.200 --> 00:02:10.900
in machine learning

39
00:02:19.800 --> 00:02:22.700
I should say prediction metrics. Okay, because

40
00:02:22.700 --> 00:02:25.200
 we're not going to go into machine learning just yet. That's

41
00:02:25.200 --> 00:02:26.100
 for module 4.

42
00:02:26.800 --> 00:02:29.200
But just enough inside so that you know

43
00:02:29.200 --> 00:02:31.100
 say okay, this is okay. Let's

44
00:02:32.100 --> 00:02:33.200
Let's see. What all this.

45
00:02:34.300 --> 00:02:36.000
all this business hears about

46
00:02:38.700 --> 00:02:42.000
Okay, so this is from the perspective of PC?

47
00:02:43.800 --> 00:02:44.700
then we're going to

48
00:02:47.800 --> 00:02:48.700
revisit the topics we talked about.

49
00:02:50.100 --> 00:02:51.100
in our last session

50
00:02:52.900 --> 00:02:55.500
So we will review it very quickly and then continue.

51
00:02:56.600 --> 00:02:59.200
Covering some other topics that we did not cover and we

52
00:02:59.200 --> 00:02:59.900
 were meant to cover.

53
00:03:01.700 --> 00:03:03.600
So once we are appreciate the

54
00:03:08.300 --> 00:03:11.300
Purpose of what we're trying to do here in the context of machine learning.

55
00:03:11.300 --> 00:03:12.000
 We will then proceed.

56
00:03:14.900 --> 00:03:17.300
to look at an example of diagonalization

57
00:03:18.300 --> 00:03:19.600
diagonalization

58
00:03:22.300 --> 00:03:23.100
of a matrix

59
00:03:25.100 --> 00:03:27.900
diagonalization also known as eigen decomposition

60
00:03:30.700 --> 00:03:31.200
You see this?

61
00:03:32.400 --> 00:03:36.500
Is going to expose us to the topics. We're going

62
00:03:35.500 --> 00:03:38.400
 to talk about we talked about in

63
00:03:38.400 --> 00:03:38.800
 our last session.

64
00:03:40.200 --> 00:03:43.600
And they will all of those will be prerequisites. So

65
00:03:43.600 --> 00:03:45.000
 this will be a prerequisite for

66
00:03:46.200 --> 00:03:49.900
SVD SVD will be a prerequisite for PCA PC.

67
00:03:49.900 --> 00:03:51.400
 Will then be a prerequisite for us.

68
00:03:52.500 --> 00:03:53.200
to

69
00:03:55.400 --> 00:03:58.200
do two things reduce the dimensionality of our data.

70
00:04:01.300 --> 00:04:01.600
and

71
00:04:04.500 --> 00:04:07.800
increasing the or improving or optimizing the

72
00:04:07.800 --> 00:04:09.600
 prediction metric of our machine learning model.

73
00:04:11.100 --> 00:04:14.000
So in order for us to look at this problem, we will end up visiting.

74
00:04:14.800 --> 00:04:16.700
eigenvectors and eigenvalues

75
00:04:21.200 --> 00:04:23.200
the characteristic polynomial

76
00:04:24.900 --> 00:04:27.100
before he looked at this what this time it will

77
00:04:27.100 --> 00:04:28.200
 be a lot faster.

78
00:04:29.200 --> 00:04:30.500
the inversion of a matrix

79
00:04:34.200 --> 00:04:34.300
and

80
00:04:37.400 --> 00:04:38.800
let me see if I've left anything out.

81
00:04:51.100 --> 00:04:51.300
Yes.

82
00:04:56.400 --> 00:04:59.500
To understand what this means we will also encounter a few terms.

83
00:05:00.900 --> 00:05:02.100
something called basis

84
00:05:03.600 --> 00:05:05.400
The basis is a set of vectors.

85
00:05:06.300 --> 00:05:09.400
To which certain conditions to conditions apply?

86
00:05:10.600 --> 00:05:11.700
and so we will talk about

87
00:05:13.700 --> 00:05:14.600
a span

88
00:05:15.500 --> 00:05:15.800
and

89
00:05:17.700 --> 00:05:18.500
linear Independence

90
00:05:21.800 --> 00:05:24.200
Okay, so these are all terms with which you must be

91
00:05:24.200 --> 00:05:24.500
 familiar.

92
00:05:25.500 --> 00:05:27.700
and about which we must have Clarity in order to

93
00:05:29.300 --> 00:05:29.300
you know.

94
00:05:31.100 --> 00:05:32.900
Then talk about SVD and PCA.

95
00:05:37.900 --> 00:05:38.300
Okay, so

96
00:05:40.100 --> 00:05:41.000
in statistics

97
00:05:44.200 --> 00:05:44.900
and let me call this.

98
00:05:46.900 --> 00:05:47.200
file

99
00:05:51.100 --> 00:05:51.900
machine learning

100
00:05:53.700 --> 00:05:54.300
regression

101
00:05:55.500 --> 00:05:57.800
we have different types of machine learning.

102
00:05:58.900 --> 00:05:59.500
techniques

103
00:06:01.600 --> 00:06:01.900
and

104
00:06:03.300 --> 00:06:06.500
the fall under the following categories we

105
00:06:06.500 --> 00:06:06.500
 have

106
00:06:07.500 --> 00:06:08.100
regression

107
00:06:10.000 --> 00:06:10.800
classification

108
00:06:12.800 --> 00:06:14.200
clustering

109
00:06:15.200 --> 00:06:16.400
there is reinforcement learning.

110
00:06:22.800 --> 00:06:25.300
the first two fall under the category

111
00:06:28.500 --> 00:06:29.700
of supervised learning

112
00:06:31.200 --> 00:06:34.200
We won't get into why it's called supervised right now.

113
00:06:35.200 --> 00:06:37.500
Or why this is called for example unsupervised learning.

114
00:06:40.400 --> 00:06:43.100
And also other odd supervisors learning

115
00:06:43.100 --> 00:06:44.900
 we have dementia reduction.

116
00:06:47.800 --> 00:06:48.900
This is where PCA.

117
00:06:49.700 --> 00:06:50.600
comes into the picture

118
00:06:52.500 --> 00:06:54.200
reinforcement learning is about actions.

119
00:06:55.100 --> 00:06:57.800
That optimize optimized Rewards.

120
00:06:59.100 --> 00:07:00.700
So he we want.

121
00:07:01.900 --> 00:07:03.600
train a model

122
00:07:04.700 --> 00:07:05.400
or some sort of

123
00:07:07.100 --> 00:07:07.700
machine

124
00:07:09.400 --> 00:07:10.600
that can always

125
00:07:11.600 --> 00:07:14.300
Do the right thing to maximize it what

126
00:07:14.300 --> 00:07:17.800
 for example, it's also using trading trading

127
00:07:17.800 --> 00:07:18.300
 algorithms.

128
00:07:19.200 --> 00:07:19.600
to buy

129
00:07:20.400 --> 00:07:24.300
a stock at the right moment still the stock

130
00:07:23.300 --> 00:07:24.900
 at the right moment.

131
00:07:26.400 --> 00:07:29.200
Okay, so here we want actions that give

132
00:07:29.200 --> 00:07:30.200
 us the best rewards.

133
00:07:37.100 --> 00:07:37.900
deep learning

134
00:07:40.600 --> 00:07:43.500
Which really is Matrix operations

135
00:07:43.500 --> 00:07:46.600
 or it's fundamentally Matrix operate operations

136
00:07:46.600 --> 00:07:49.400
 implemented their python all the

137
00:07:49.400 --> 00:07:50.100
 machine learning models.

138
00:07:51.700 --> 00:07:54.900
And all for all of these categories are implemented machine

139
00:07:54.900 --> 00:07:57.900
 in python or at least a popular ones.

140
00:07:57.900 --> 00:07:59.500
 You can also do these in r

141
00:08:00.500 --> 00:08:01.200
and C++

142
00:08:02.600 --> 00:08:03.000
and very

143
00:08:05.900 --> 00:08:08.500
soon it will also JavaScript will

144
00:08:08.500 --> 00:08:11.600
 Encompass or be one of the programmable language

145
00:08:11.600 --> 00:08:12.500
 in which you can Implement these.

146
00:08:14.400 --> 00:08:17.500
this we will leave for module 4, but once we understand

147
00:08:17.500 --> 00:08:19.600
 the how deep Learning Works we could

148
00:08:20.600 --> 00:08:24.100
use neural networks to implement all of these

149
00:08:23.100 --> 00:08:25.900
 machine learning techniques

150
00:08:26.700 --> 00:08:27.700
okay, let's

151
00:08:30.200 --> 00:08:33.700
exclude these for the time being these are not this is all probability. This

152
00:08:33.700 --> 00:08:36.800
 is all Matrix algebra and multivariable calculus.

153
00:08:38.200 --> 00:08:38.700
This is all.

154
00:08:39.600 --> 00:08:40.800
probability Theory

155
00:08:41.800 --> 00:08:43.300
So let's eliminate these for now.

156
00:08:46.800 --> 00:08:49.400
We want to learn PCA to

157
00:08:49.400 --> 00:08:49.800
 do this.

158
00:08:52.500 --> 00:08:53.700
So we can do that.

159
00:08:55.200 --> 00:08:56.500
And do this very well.

160
00:08:59.900 --> 00:09:02.200
Dementia reduction will allow us to find.

161
00:09:08.100 --> 00:09:11.000
These things we call clusters which are how data is grouped.

162
00:09:13.200 --> 00:09:16.400
You see sometimes you will have data that is properly labeled.

163
00:09:17.100 --> 00:09:20.300
I imagine you have a data set of vehicles.

164
00:09:22.400 --> 00:09:24.200
There is no mention of the

165
00:09:26.300 --> 00:09:27.300
brand of the vehicle

166
00:09:29.100 --> 00:09:29.800
But perhaps there is.

167
00:09:31.700 --> 00:09:34.600
A categorization of the vehicle so

168
00:09:34.600 --> 00:09:35.700
 it can say truck.

169
00:09:37.700 --> 00:09:39.200
sports car

170
00:09:40.300 --> 00:09:40.800
then

171
00:09:42.200 --> 00:09:44.300
bus, okay.

172
00:09:45.100 --> 00:09:46.300
So that's label data.

173
00:09:47.100 --> 00:09:49.600
Sometimes however, we will come across it that has no label.

174
00:09:51.600 --> 00:09:54.500
And you have to group them somehow by

175
00:09:54.500 --> 00:09:55.000
 some sort of.

176
00:09:57.600 --> 00:09:58.500
characteristic

177
00:09:59.300 --> 00:10:00.100
now

178
00:10:01.900 --> 00:10:04.400
if I say that a car has more than

179
00:10:04.400 --> 00:10:05.300
 four wheels.

180
00:10:07.700 --> 00:10:10.300
You can say oh that's that's probably a truck, right?

181
00:10:13.200 --> 00:10:17.300
Eight wheels or more Wheels if I tell you that a car has more

182
00:10:16.300 --> 00:10:19.000
 than four seats.

183
00:10:20.200 --> 00:10:23.100
They have like I don't know 20 seats 30 seats or more you would

184
00:10:23.100 --> 00:10:24.000
 say it's a van or a bus.

185
00:10:25.200 --> 00:10:28.100
So even though the label doesn't exist from the description you can tell.

186
00:10:29.200 --> 00:10:30.400
What type of card this is?

187
00:10:31.400 --> 00:10:31.600
Okay.

188
00:10:32.600 --> 00:10:35.200
yeah, and yet you will come sometimes will come

189
00:10:35.200 --> 00:10:39.100
 across data that has no label and there is nothing discernible at

190
00:10:39.100 --> 00:10:40.300
 least not to you the

191
00:10:41.500 --> 00:10:44.100
Statistician or data scientist like there are

192
00:10:44.100 --> 00:10:44.600
 so many features.

193
00:10:46.200 --> 00:10:48.900
And these features not something about what you have domain expertise.

194
00:10:50.200 --> 00:10:51.200
and so you will not be able to

195
00:10:52.300 --> 00:10:55.300
a group that or cluster them

196
00:10:55.300 --> 00:10:56.600
 categorizing essentially.

197
00:10:57.200 --> 00:10:59.300
Say let's say none of us had seen a car before.

198
00:11:00.800 --> 00:11:02.600
or let's use

199
00:11:03.900 --> 00:11:06.600
the aircrafts there are different types

200
00:11:06.600 --> 00:11:09.500
 of Passenger passenger flights double engine

201
00:11:09.500 --> 00:11:12.100
 single engine and let's say you do not know the difference

202
00:11:12.100 --> 00:11:15.000
 between the two. How would you go about grouping them?

203
00:11:15.700 --> 00:11:18.500
And especially if there are so many things that describe them.

204
00:11:18.500 --> 00:11:21.500
 Well dimensionality reduction could help in

205
00:11:21.500 --> 00:11:24.100
 that process. It can reduce the features. So you have

206
00:11:24.100 --> 00:11:25.100
 less calculation to do.

207
00:11:27.800 --> 00:11:30.400
Also now by the way dimensional reduction there

208
00:11:30.400 --> 00:11:32.400
 are multiple ways to do this SVD.

209
00:11:33.300 --> 00:11:36.200
Is one of them PC is another one and there are

210
00:11:36.200 --> 00:11:37.000
 others like svm.

211
00:11:37.900 --> 00:11:40.400
singular support Vector machines

212
00:11:41.700 --> 00:11:44.100
So there are different ways to do this. So we're focused on

213
00:11:44.100 --> 00:11:44.600
 these two.

214
00:11:46.600 --> 00:11:47.000
Okay.

215
00:11:48.800 --> 00:11:51.100
Okay, so this will allow us to Cluster data.

216
00:11:51.600 --> 00:11:52.500
when it is otherwise

217
00:11:53.700 --> 00:11:55.500
very difficult just impossible to do.

218
00:11:57.100 --> 00:11:58.500
but also allow us to

219
00:11:59.900 --> 00:12:02.300
regression accurately another word for

220
00:12:02.300 --> 00:12:05.000
 regression is prediction or forecasting.

221
00:12:10.300 --> 00:12:14.500
Let me give you a just enough.

222
00:12:16.200 --> 00:12:18.400
Context so we can switch to PCA.

223
00:12:19.400 --> 00:12:20.300
on the regression

224
00:12:24.900 --> 00:12:27.300
and let me remove these for the time being.

225
00:12:27.700 --> 00:12:28.600
simplify our

226
00:12:30.700 --> 00:12:31.300
notes Here

227
00:12:33.600 --> 00:12:36.600
There are different ways for you to determine the quality

228
00:12:36.600 --> 00:12:37.500
 of the prediction.

229
00:12:39.400 --> 00:12:41.300
factor analysis

230
00:12:42.600 --> 00:12:44.500
which category supervised learning or

231
00:12:45.900 --> 00:12:46.900
otherwise learning

232
00:12:47.600 --> 00:12:49.000
I'm not even sure I've heard this.

233
00:12:50.600 --> 00:12:52.200
before factor analysis

234
00:13:01.200 --> 00:13:03.100
Okay, so this is also dimensionality reduction.

235
00:13:06.200 --> 00:13:09.100
I don't remember reading about this but I from a quick Google

236
00:13:09.100 --> 00:13:11.700
 search. This looks like a dimension I deduction problem.

237
00:13:15.200 --> 00:13:16.700
Yeah, so this would also fall under.

238
00:13:19.400 --> 00:13:21.200
unsupervised learning

239
00:13:22.300 --> 00:13:26.300
Okay, so there are different ways to

240
00:13:26.300 --> 00:13:26.900
 calculate.

241
00:13:27.900 --> 00:13:30.100
And empirically determine the quality of

242
00:13:30.100 --> 00:13:31.000
 a machine learning model.

243
00:13:33.500 --> 00:13:34.500
There is something called MSC.

244
00:13:36.100 --> 00:13:37.500
There is something called Mae.

245
00:13:40.200 --> 00:13:41.700
And there's something called r squared.

246
00:13:45.100 --> 00:13:47.300
A statistician would look at all three metrics.

247
00:13:48.900 --> 00:13:51.300
So you're looking at the model from different

248
00:13:51.300 --> 00:13:51.800
 angles?

249
00:13:53.800 --> 00:13:56.600
To make sure yeah, this this model is this.

250
00:13:58.500 --> 00:14:01.700
Is doing a good job. Okay, that's a very that simplification,

251
00:14:01.700 --> 00:14:01.900
 but

252
00:14:02.800 --> 00:14:05.500
At least when you implement this in programming.

253
00:14:06.900 --> 00:14:09.200
after you train a machine learning model, we will

254
00:14:09.200 --> 00:14:10.600
 talk about this wood training and

255
00:14:11.500 --> 00:14:14.200
we'll actually train about in practice.

256
00:14:14.900 --> 00:14:16.300
You want to look at these metrics?

257
00:14:17.500 --> 00:14:19.900
R squared is a number. That should converge.

258
00:14:21.200 --> 00:14:21.800
2 1

259
00:14:23.900 --> 00:14:26.400
The others are numbers that should

260
00:14:26.400 --> 00:14:27.300
 converge to zero.

261
00:14:28.300 --> 00:14:28.800
in other words

262
00:14:29.700 --> 00:14:31.800
You want all your r squared to be close to 1?

263
00:14:33.100 --> 00:14:34.700
You want your ma and MSE to be?

264
00:14:35.900 --> 00:14:39.100
zero, there's also something called RMS it

265
00:14:38.100 --> 00:14:40.100
 the root mean squared error, but

266
00:14:41.400 --> 00:14:43.900
that's just the square root of of that.

267
00:14:45.400 --> 00:14:45.600
now

268
00:14:50.600 --> 00:14:53.400
these two way these two techniques are two ways

269
00:14:53.400 --> 00:14:53.600
 of

270
00:14:56.600 --> 00:14:59.000
Calculating the error of your model.

271
00:14:59.500 --> 00:15:02.600
So why do you want this to be closed at easier? Because the smaller

272
00:15:02.600 --> 00:15:03.300
 the

273
00:15:04.700 --> 00:15:06.000
average error of the model

274
00:15:07.300 --> 00:15:10.500
Well, it's predictions are closer to what has

275
00:15:10.500 --> 00:15:10.900
 actually happened.

276
00:15:12.800 --> 00:15:14.700
Now this one uses squaring.

277
00:15:15.300 --> 00:15:18.600
And this one uses absolute the absolute operation while

278
00:15:18.600 --> 00:15:21.300
 let me show you let me break down the equation for you. Okay

279
00:15:21.300 --> 00:15:22.800
 you are you understand, MC.

280
00:15:23.600 --> 00:15:26.500
Me is what the purpose of it becomes

281
00:15:26.500 --> 00:15:26.900
 self-evident.

282
00:15:27.800 --> 00:15:29.500
so in statistics

283
00:15:30.700 --> 00:15:32.600
the idea of Statistics is to

284
00:15:37.300 --> 00:15:37.400
look at

285
00:15:38.600 --> 00:15:39.400
existing data

286
00:15:43.100 --> 00:15:46.000
and a data is a collection of observations. So a data.

287
00:15:46.500 --> 00:15:49.800
I want you to imagine an Excel sheet an Excel

288
00:15:49.800 --> 00:15:50.600
 sheet is data.

289
00:15:51.500 --> 00:15:52.500
It's composed.

290
00:15:53.400 --> 00:15:56.400
Of columns. Those columns are

291
00:15:56.400 --> 00:15:59.300
 the features. For example, let's say you're trying to predict the price of

292
00:15:59.300 --> 00:15:59.800
 a property.

293
00:16:00.500 --> 00:16:03.000
In real estate, what are things that?

294
00:16:05.400 --> 00:16:08.000
Influence the price of a property the size of

295
00:16:08.100 --> 00:16:11.100
 the let's say Apartments the size of the apartment.

296
00:16:12.300 --> 00:16:13.000
number of bedrooms

297
00:16:14.200 --> 00:16:17.800
the number of bathrooms proximity to

298
00:16:19.100 --> 00:16:23.200
Amenities like supermarkets so nurse schools

299
00:16:22.200 --> 00:16:25.600
 and and even the city center.

300
00:16:25.600 --> 00:16:28.200
 Okay the club, for example, you're in

301
00:16:28.200 --> 00:16:28.300
 New York.

302
00:16:29.200 --> 00:16:32.200
If you live in Manhattan, then the price of

303
00:16:32.200 --> 00:16:36.200
 properties are much more expensive than let's say if you were in that, New Jersey.

304
00:16:39.700 --> 00:16:42.800
or surrounding surrounding cities Okay,

305
00:16:42.800 --> 00:16:43.300
 so

306
00:16:47.200 --> 00:16:48.500
That's what we want to do. We want to learn.

307
00:16:50.500 --> 00:16:53.700
Why certain factors influence a

308
00:16:53.700 --> 00:16:54.200
 certain outcome?

309
00:16:54.800 --> 00:16:57.300
Okay, but let's keep it just let's keep

310
00:16:57.300 --> 00:16:59.100
 it minimum. So in in

311
00:17:01.600 --> 00:17:02.600
The mathematics is this.

312
00:17:03.500 --> 00:17:04.900
We use y for observation.

313
00:17:06.700 --> 00:17:09.100
And there's a common chat. Would you use both or which one?

314
00:17:11.200 --> 00:17:13.500
yeah, you could it's actually

315
00:17:14.200 --> 00:17:17.400
you could use multiple techniques and then see which one

316
00:17:17.400 --> 00:17:17.800
 produces.

317
00:17:19.300 --> 00:17:22.600
Which one is more effective and just like there are metrics for

318
00:17:22.600 --> 00:17:23.100
 regression.

319
00:17:24.200 --> 00:17:27.300
So just like there are ways that you can measure the quality of

320
00:17:27.300 --> 00:17:29.100
 your forecasting. There are.

321
00:17:30.900 --> 00:17:32.200
ways you can calculate the

322
00:17:34.300 --> 00:17:38.000
the quality of the dimensionality reduction

323
00:17:37.200 --> 00:17:40.300
 the quality of our clustering. So if I if you remember that

324
00:17:40.300 --> 00:17:43.300
 breakdown I had for all of those techniques there's a way

325
00:17:43.300 --> 00:17:44.300
 you can measure their quality.

326
00:17:45.500 --> 00:17:48.600
Okay, so why is the observation the word observation means

327
00:17:48.600 --> 00:17:50.100
 something that has actually happened?

328
00:17:51.700 --> 00:17:54.500
An actual if we stick to the story of

329
00:17:54.500 --> 00:17:58.000
 a predicting real real estate prices observation

330
00:17:57.100 --> 00:18:00.200
 is an actual property that it exists in the

331
00:18:00.200 --> 00:18:00.400
 real world.

332
00:18:01.400 --> 00:18:02.200
We use hat.

333
00:18:05.500 --> 00:18:06.600
To say it's an estimate.

334
00:18:08.900 --> 00:18:11.300
So basically we want to look at these observations. Let's

335
00:18:11.300 --> 00:18:14.500
 say we have 200 properties from these 200 properties. We

336
00:18:14.500 --> 00:18:17.800
 want to see why do one set

337
00:18:17.800 --> 00:18:20.300
 of properties cost so much and why do

338
00:18:20.300 --> 00:18:22.100
 these other sets of properties cost so little

339
00:18:23.600 --> 00:18:25.700
So that we can produce estimates.

340
00:18:26.800 --> 00:18:29.200
That is what it means to have a machine learning model

341
00:18:29.200 --> 00:18:30.100
 a model.

342
00:18:30.800 --> 00:18:31.000
in

343
00:18:32.100 --> 00:18:33.300
General terms it's something.

344
00:18:34.200 --> 00:18:36.300
Is it some sort of mathematical expression?

345
00:18:37.400 --> 00:18:40.100
That represents a real world phenomena.

346
00:18:40.900 --> 00:18:43.900
Okay, so that for example, the price

347
00:18:43.900 --> 00:18:47.100
 of one property is a function of its size the

348
00:18:46.100 --> 00:18:49.300
 number of bedrooms, and it's proximity to the

349
00:18:49.300 --> 00:18:49.800
 city center.

350
00:18:52.300 --> 00:18:55.300
Is the Hat also called a prediction? No, when you put the Hat

351
00:18:55.300 --> 00:18:58.700
 on top of the Y this whole thing becomes an estimate or prediction.

352
00:18:59.400 --> 00:19:02.300
There are different by the way, and something we have to be

353
00:19:02.300 --> 00:19:05.900
 careful is that these words come with common different names estimate is

354
00:19:05.900 --> 00:19:06.100
 one of them.

355
00:19:08.800 --> 00:19:10.100
Prediction is another one.

356
00:19:11.500 --> 00:19:14.000
And even this one for example the why?

357
00:19:14.700 --> 00:19:17.100
Okay, so specifically this response this

358
00:19:17.100 --> 00:19:19.200
 why represents the

359
00:19:21.500 --> 00:19:22.900
the value of the observation

360
00:19:23.600 --> 00:19:24.300
so why?

361
00:19:26.900 --> 00:19:30.200
is actually dependent on except

362
00:19:29.200 --> 00:19:31.300
 One X up to

363
00:19:34.700 --> 00:19:36.700
depends on x sub 1 x up to

364
00:19:38.800 --> 00:19:40.000
where these X's are

365
00:19:41.400 --> 00:19:45.300
You know features of the property size of the property number of

366
00:19:45.300 --> 00:19:48.900
 bedrooms and distance from the city center.

367
00:19:51.400 --> 00:19:51.500
Okay.

368
00:19:53.300 --> 00:19:56.300
So the observation or this is the value

369
00:19:56.300 --> 00:19:58.100
 this is the property value.

370
00:19:59.200 --> 00:20:01.200
It's based on these features.

371
00:20:02.900 --> 00:20:05.500
Okay without I'm not gonna show you the regression

372
00:20:05.500 --> 00:20:07.000
 model right now.

373
00:20:08.600 --> 00:20:11.100
Okay, but what I really want to highlight is

374
00:20:11.100 --> 00:20:13.500
 this is this how we calculate MSE.

375
00:20:14.700 --> 00:20:14.900
so

376
00:20:20.100 --> 00:20:21.800
Yes, so that's the observation.

377
00:20:23.700 --> 00:20:24.900
Let's say The observed.

378
00:20:26.800 --> 00:20:27.500
property value

379
00:20:29.800 --> 00:20:31.200
This is the estimated property value.

380
00:20:35.300 --> 00:20:35.500
Okay.

381
00:20:38.600 --> 00:20:40.900
what we want to do is this we want to

382
00:20:42.400 --> 00:20:42.900
find the model.

383
00:20:44.300 --> 00:20:45.300
Whose MSC?

384
00:20:47.200 --> 00:20:50.000
Is as close to zero as possible, and this is how you calculate it.

385
00:20:52.200 --> 00:20:53.600
so the function MSE

386
00:20:56.900 --> 00:20:57.600
is given by

387
00:21:02.700 --> 00:21:06.000
well here I'm going to

388
00:21:06.400 --> 00:21:06.900
 represent this as a

389
00:21:08.600 --> 00:21:11.300
single value not as a function, but what we

390
00:21:11.300 --> 00:21:13.100
 do is we take the difference of

391
00:21:15.500 --> 00:21:16.500
the observations

392
00:21:17.400 --> 00:21:19.100
so we have y minus.

393
00:21:20.200 --> 00:21:21.100
Hat why?

394
00:21:24.700 --> 00:21:26.300
now, of course, we're not going to compare just

395
00:21:28.100 --> 00:21:31.300
One single imagine an Excel

396
00:21:31.300 --> 00:21:33.100
 sheet, right one row is one property.

397
00:21:33.900 --> 00:21:35.800
Imagine in your data set you have

398
00:21:36.700 --> 00:21:37.900
1,000 properties

399
00:21:39.100 --> 00:21:41.000
okay, and by the way

400
00:21:43.400 --> 00:21:46.200
The way you would train a machine learning model is not to show the entirety of

401
00:21:46.200 --> 00:21:49.500
 the data. If we have 1,000 rows you would

402
00:21:49.500 --> 00:21:52.700
 show the model. Let's say 800 of them or 700 of

403
00:21:52.700 --> 00:21:52.800
 them.

404
00:21:53.800 --> 00:21:56.800
So you would show the model 700 properties and

405
00:21:56.800 --> 00:22:00.300
 say hey model look at these 700 properties and

406
00:22:00.300 --> 00:22:03.200
 see if we can find out why one is expensive one. Why is

407
00:22:03.200 --> 00:22:04.800
 and why the others are not expensive?

408
00:22:06.400 --> 00:22:08.600
Then to know if your model is actually learning something.

409
00:22:09.400 --> 00:22:11.300
Who will take the remaining 300?

410
00:22:13.200 --> 00:22:14.300
And use it to test the model.

411
00:22:15.400 --> 00:22:18.000
So in other words, we're going to

412
00:22:18.000 --> 00:22:18.400
 compare.

413
00:22:20.200 --> 00:22:23.500
The MSC the errors of 100 of

414
00:22:23.500 --> 00:22:26.100
 we're going to compare the those are the

415
00:22:26.100 --> 00:22:28.200
 model estimated versus the ones that the model the actual.

416
00:22:29.500 --> 00:22:31.300
properties now, of course since this is these are going to be

417
00:22:35.600 --> 00:22:38.500
collections of properties we will use uppercase letter y

418
00:22:41.300 --> 00:22:41.500
Okay.

419
00:22:43.200 --> 00:22:46.600
This is not a matrix. It's a random variable.

420
00:22:47.900 --> 00:22:49.500
Just imagine it's a collection of

421
00:22:50.800 --> 00:22:51.200
prices

422
00:22:52.900 --> 00:22:53.300
okay, like a

423
00:22:54.400 --> 00:22:57.000
list of prices. I don't even want to use the word Vector because I

424
00:22:57.200 --> 00:22:58.500
 don't I like I want to

425
00:22:59.500 --> 00:23:02.800
separate terms and notation in statistics

426
00:23:02.800 --> 00:23:05.000
 and linear algebra, but imagine this is a set of

427
00:23:06.500 --> 00:23:09.400
quantities so all of the retail prices

428
00:23:10.400 --> 00:23:13.400
That are actually in our Excel sheet,

429
00:23:13.400 --> 00:23:14.600
 and these are the ones that model has predicted.

430
00:23:15.300 --> 00:23:16.400
Now, of course you can see here.

431
00:23:18.100 --> 00:23:19.200
If we take the difference.

432
00:23:20.800 --> 00:23:23.200
In some instances they can cancel each other out.

433
00:23:24.100 --> 00:23:24.400
because

434
00:23:25.800 --> 00:23:28.400
maybe the price of one property is well.

435
00:23:30.000 --> 00:23:31.200
500,000

436
00:23:31.700 --> 00:23:34.700
the model predicted to be minus 500,000 so

437
00:23:34.700 --> 00:23:37.600
 they can cancel each other out. So

438
00:23:37.600 --> 00:23:40.200
 they're pretty to prevent this cancellation. What we do is we Square them.

439
00:23:43.100 --> 00:23:43.600
We Square them.

440
00:23:44.500 --> 00:23:48.300
But then but when you square the difference you blew

441
00:23:47.300 --> 00:23:48.300
 up.

442
00:23:49.500 --> 00:23:52.400
The proportion so we have to then take the

443
00:23:52.400 --> 00:23:52.700
 square root.

444
00:23:55.700 --> 00:23:57.000
of this Square difference

445
00:23:59.300 --> 00:24:02.300
Okay. Now we are going to do this we will take

446
00:24:02.300 --> 00:24:05.500
 this difference for all of the observations.

447
00:24:07.600 --> 00:24:09.100
So if we have n observations

448
00:24:15.600 --> 00:24:18.200
we're going to do this for all so it's this is the mean average.

449
00:24:19.900 --> 00:24:23.000
Okay, so that the difference between the observations and

450
00:24:22.200 --> 00:24:25.100
 the estimates. That's the error.

451
00:24:26.200 --> 00:24:30.000
So the closer what the month the closer the actual observation

452
00:24:29.400 --> 00:24:32.100
 The observed property price.

453
00:24:33.300 --> 00:24:36.200
The small the smaller difference between observed proper price

454
00:24:36.200 --> 00:24:39.100
 and the estimated price then the better the model is

455
00:24:39.100 --> 00:24:40.400
 at predicting.

456
00:24:41.800 --> 00:24:44.100
The farther apart and the model, you know.

457
00:24:44.900 --> 00:24:48.100
Doesn't has not really understood why one property

458
00:24:47.100 --> 00:24:49.300
 is expensive and the other isn't.

459
00:24:51.300 --> 00:24:54.000
Okay, so we will do this for all of the properties.

460
00:24:56.100 --> 00:24:58.200
and of course, this will be

461
00:24:59.700 --> 00:25:02.100
We'll use the sub notation here. So this will be

462
00:25:05.100 --> 00:25:05.900
some

463
00:25:13.700 --> 00:25:14.500
for my

464
00:25:15.500 --> 00:25:16.500
two and

465
00:25:27.300 --> 00:25:27.600
okay.

466
00:25:29.400 --> 00:25:30.600
We will get a single value.

467
00:25:31.400 --> 00:25:33.600
The closer this MSC is to zero the better.

468
00:25:36.200 --> 00:25:37.800
Now, of course, we will revisit this later on.

469
00:25:39.100 --> 00:25:40.300
What does have to do with PCA?

470
00:25:41.500 --> 00:25:42.400
long story short

471
00:25:43.300 --> 00:25:46.500
PCA will make it easier for us to get this to zero.

472
00:25:47.400 --> 00:25:50.100
By reducing the dimensionality of the data set.

473
00:25:52.700 --> 00:25:53.600
and of course we'll have to

474
00:25:55.300 --> 00:25:59.400
Like do the session on Friday and perhaps even revisit some

475
00:25:59.400 --> 00:26:01.600
 of the mathematics of PCA in the next session?

476
00:26:02.400 --> 00:26:05.300
But PCA will help us get this number.

477
00:26:06.100 --> 00:26:07.500
two zero

478
00:26:07.900 --> 00:26:09.100
make it converge.

479
00:26:11.400 --> 00:26:12.000
to zero

480
00:26:16.100 --> 00:26:16.200
that's

481
00:26:17.600 --> 00:26:17.800
one

482
00:26:20.100 --> 00:26:23.600
example of what PC will get us

483
00:26:23.600 --> 00:26:26.300
 to do not only will I reduce the dimensionality so

484
00:26:26.300 --> 00:26:28.000
 you can use it for clustering.

485
00:26:29.100 --> 00:26:32.700
You can also reduce the dimensionality to increase the quality of

486
00:26:32.700 --> 00:26:33.700
 your forecasting.

487
00:26:36.100 --> 00:26:39.400
All right. Okay. Now we will develop this machine

488
00:26:39.400 --> 00:26:42.400
 learning section A lot there is I this is obviously

489
00:26:43.700 --> 00:26:46.200
subject of its own that warrant its

490
00:26:46.200 --> 00:26:46.600
 own weeks, but

491
00:26:48.200 --> 00:26:50.800
let's just keep this as our motivating reason.

492
00:26:51.600 --> 00:26:52.000
to get

493
00:26:52.800 --> 00:26:55.400
to take the data set.

494
00:26:56.600 --> 00:26:57.600
reduce the dimensions

495
00:26:59.600 --> 00:27:02.700
ultimately for the purpose of getting the prediction to

496
00:27:02.700 --> 00:27:03.500
 be you know.

497
00:27:05.300 --> 00:27:06.800
at the best possible

498
00:27:08.600 --> 00:27:11.500
A metric so this is MSC is one metric Mae is

499
00:27:11.500 --> 00:27:14.200
 another metric. So in Mae instead of taking the square root.

500
00:27:15.300 --> 00:27:18.400
Of the difference you use the absolute value those two vertical bars.

501
00:27:18.400 --> 00:27:21.300
 They will produce very similar qualities, but it's

502
00:27:21.300 --> 00:27:22.300
 always good to look at.

503
00:27:23.200 --> 00:27:27.600
These two different measurements. Okay, let's let's return to linear

504
00:27:26.600 --> 00:27:27.900
 algebra.

505
00:27:29.400 --> 00:27:29.700
Okay.

506
00:27:33.000 --> 00:27:33.300
and

507
00:27:35.700 --> 00:27:38.500
let me show you one more thing. One more picture. I

508
00:27:38.500 --> 00:27:40.300
 did I think we saw this the

509
00:27:42.900 --> 00:27:43.800
the other session

510
00:27:44.800 --> 00:27:45.000
so

511
00:27:49.500 --> 00:27:50.900
I'm gonna type PCA.

512
00:27:52.000 --> 00:27:52.700
variance

513
00:28:06.400 --> 00:28:09.700
I remember there was one very nice animation, but I'm

514
00:28:09.700 --> 00:28:12.400
 not gonna spend this I don't have right now, but but

515
00:28:12.400 --> 00:28:13.600
 I'll definitely show it on Friday.

516
00:28:15.300 --> 00:28:16.400
what we want to do is we have

517
00:28:17.900 --> 00:28:19.900
multi-dimensional data and what we want to do is

518
00:28:21.600 --> 00:28:24.800
create two vectors two vectors that

519
00:28:24.800 --> 00:28:25.100
 are

520
00:28:26.000 --> 00:28:26.700
positioned

521
00:28:27.600 --> 00:28:29.400
In such a way where the data.

522
00:28:30.300 --> 00:28:34.200
These data points which we call the observations are farthest

523
00:28:33.200 --> 00:28:34.600
 from each other.

524
00:28:36.000 --> 00:28:36.200
Okay.

525
00:28:37.600 --> 00:28:38.900
The father they are from each other.

526
00:28:40.200 --> 00:28:40.700
the more

527
00:28:41.800 --> 00:28:44.800
variance or the more there is the

528
00:28:44.800 --> 00:28:45.700
 more this vector.

529
00:28:46.600 --> 00:28:47.400
explains

530
00:28:48.500 --> 00:28:49.800
something important about the data

531
00:28:51.200 --> 00:28:52.300
Now there's a missing link.

532
00:28:53.700 --> 00:28:57.200
There's a missing link that requires some mathematical prerequisites to

533
00:28:56.200 --> 00:29:00.700
 see why PCA equal will

534
00:28:59.700 --> 00:29:02.300
 get us to a smaller MSE.

535
00:29:03.300 --> 00:29:07.100
Okay, but in order for us to bridge this Gap we need to we need

536
00:29:06.100 --> 00:29:09.600
 to turn to our topic but PCA another

537
00:29:09.600 --> 00:29:12.700
 way to look at this is as a linear transformation. Let

538
00:29:12.700 --> 00:29:15.000
 me see if we can if I go to Wikipedia.

539
00:29:16.800 --> 00:29:19.300
I think I saw it there as well PCA.

540
00:29:20.400 --> 00:29:22.300
if you remember linear transformation

541
00:29:23.300 --> 00:29:26.800
we said that it can take you from two-dimensional from 2D

542
00:29:26.800 --> 00:29:29.400
 to 3D or from 3D to 2D or from 2D to

543
00:29:29.400 --> 00:29:30.200
 2D but in a different

544
00:29:30.800 --> 00:29:33.400
Arrangement like

545
00:29:33.400 --> 00:29:33.800
 we saw

546
00:29:35.700 --> 00:29:38.400
I think it was in session today this today's session

547
00:29:38.400 --> 00:29:42.900
 seven or this is session seven session eight.

548
00:29:42.900 --> 00:29:45.200
 Excuse me. I think it was session six or seven where we

549
00:29:45.200 --> 00:29:48.700
 saw half the sheer Matrix or the sheer vector.

550
00:29:49.700 --> 00:29:52.900
And then we also looked at an example of making one vector

551
00:29:52.900 --> 00:29:55.300
 perpendicular to another by the way that's also called

552
00:29:55.300 --> 00:29:59.200
 orthogonality. It's two vectors are perpendicular

553
00:29:58.200 --> 00:30:01.600
 to each other then in lineage. We'll

554
00:30:01.600 --> 00:30:02.900
 see where their orthogonal.

555
00:30:03.400 --> 00:30:03.700
but

556
00:30:04.700 --> 00:30:07.200
when we took that vector and we rotated in

557
00:30:07.200 --> 00:30:08.700
 the 90 degrees, that was a linear transformation.

558
00:30:09.500 --> 00:30:12.000
So PCA can also be perceived as some sort of

559
00:30:12.500 --> 00:30:13.000
 linear transformation.

560
00:30:14.400 --> 00:30:15.900
Where was that picture I saw?

561
00:30:19.800 --> 00:30:21.900
Maybe was svm SVD.

562
00:30:23.100 --> 00:30:25.100
SVD Wiki pedia

563
00:30:29.300 --> 00:30:30.400
Yeah, this is what I meant.

564
00:30:34.500 --> 00:30:36.300
So we are going to go from our data.

565
00:30:37.500 --> 00:30:41.400
Apply Transformations these basically

566
00:30:40.400 --> 00:30:43.300
 our Matrix is going to be decomposed.

567
00:30:44.900 --> 00:30:48.100
Into three matrices where each matrices responsible

568
00:30:47.100 --> 00:30:50.700
 for some sort of transformation this transformation.

569
00:30:51.800 --> 00:30:54.100
This ultimate transformation is going to

570
00:30:54.100 --> 00:30:56.400
 give us these vectors which we call the principal components.

571
00:30:57.500 --> 00:30:58.000
we will have

572
00:30:59.300 --> 00:31:02.100
several principal components, but the most

573
00:31:05.200 --> 00:31:06.700
explanation the most

574
00:31:11.400 --> 00:31:15.300
Let me use simple words the most. Yeah,

575
00:31:14.300 --> 00:31:17.400
 the first Vector which

576
00:31:17.400 --> 00:31:20.000
 is the first principle component will.

577
00:31:21.500 --> 00:31:22.900
Contain most of the useful information.

578
00:31:24.200 --> 00:31:27.500
And then the second Vector less than that the third Vector less

579
00:31:27.500 --> 00:31:27.900
 than that, so.

580
00:31:30.300 --> 00:31:33.300
And one another important detail is that these two vectors must

581
00:31:33.300 --> 00:31:34.800
 be orthogonal? So the

582
00:31:36.400 --> 00:31:39.700
Angle must be 90 degrees to make them perpendicular.

583
00:31:40.900 --> 00:31:43.100
okay, so this

584
00:31:44.400 --> 00:31:47.300
transformation this reshaping

585
00:31:48.000 --> 00:31:48.200
of

586
00:31:49.400 --> 00:31:49.800
our

587
00:31:50.800 --> 00:31:53.300
Data, and our coordinate system is quite allow us

588
00:31:53.300 --> 00:31:54.200
 to find these two vectors.

589
00:31:55.300 --> 00:31:58.300
We get these two vectors then our life becomes easier

590
00:31:58.300 --> 00:31:59.800
 when we want to group data.

591
00:32:00.400 --> 00:32:03.600
About what we Have No Label or make you

592
00:32:03.600 --> 00:32:06.400
 better predictions, but like I said, there's still a missing

593
00:32:06.400 --> 00:32:09.000
 Bridge here. I'm leaving out some details, but

594
00:32:09.900 --> 00:32:12.700
we're going to fill it today and on Friday.

595
00:32:16.000 --> 00:32:16.400
Okay.

596
00:32:17.900 --> 00:32:20.600
For example these sigmas these sigmas

597
00:32:20.600 --> 00:32:23.400
 that you see these are the eigenvalues. So, let's see what they

598
00:32:23.400 --> 00:32:24.100
 have to do with anything.

599
00:32:25.900 --> 00:32:26.200
Okay.

600
00:32:28.400 --> 00:32:30.400
Let me show you how diagonalization works.

601
00:32:32.400 --> 00:32:33.700
In the process we will see all of these.

602
00:32:34.700 --> 00:32:35.900
And you will Define all of these.

603
00:32:38.100 --> 00:32:40.600
Okay, I am going to open a new file.

604
00:32:43.400 --> 00:32:45.500
This is number 11. This is number 12.

605
00:32:58.100 --> 00:32:59.500
Let's create one called 13.

606
00:33:07.700 --> 00:33:09.000
So you're gonna lization.

607
00:33:12.400 --> 00:33:13.600
Yeah going all.

608
00:33:17.500 --> 00:33:17.800
or

609
00:33:19.000 --> 00:33:19.800
eigen

610
00:33:20.900 --> 00:33:22.000
decompo

611
00:33:23.200 --> 00:33:23.600
position

612
00:33:27.800 --> 00:33:28.600
to mount

613
00:33:32.200 --> 00:33:32.500
so

614
00:33:36.700 --> 00:33:39.300
I'm gonna have to type the code because I didn't have enough

615
00:33:39.300 --> 00:33:42.100
 time to write in advance, but I'll make this as quick as

616
00:33:42.100 --> 00:33:43.000
 possible. Say we have a

617
00:33:44.700 --> 00:33:46.300
square Matrix a

618
00:33:49.600 --> 00:33:49.800
Okay.

619
00:33:54.100 --> 00:33:55.300
Let me just copy some.

620
00:33:56.500 --> 00:33:57.500
code to make this faster

621
00:33:58.300 --> 00:34:00.500
I'm gonna copy this code for creating a matrix.

622
00:34:01.700 --> 00:34:02.900
We have a matrix a

623
00:34:06.700 --> 00:34:09.300
with the following

624
00:34:13.700 --> 00:34:14.400
components

625
00:34:16.700 --> 00:34:19.500
it's a square Matrix. So 2 by 2.

626
00:34:22.800 --> 00:34:25.200
And it's scaler values are two two one. Three

627
00:34:25.200 --> 00:34:25.800
 two, two.

628
00:34:28.300 --> 00:34:29.100
one three

629
00:34:30.700 --> 00:34:33.700
two diagonalization this Matrix

630
00:34:33.700 --> 00:34:35.300
 is to decompose it.

631
00:34:36.200 --> 00:34:36.900
or factory

632
00:34:38.300 --> 00:34:41.500
and the factors will be will represent

633
00:34:41.500 --> 00:34:42.500
 what the following letters.

634
00:34:43.200 --> 00:34:45.400
So if I scroll down here, it will become.

635
00:34:48.500 --> 00:34:49.900
It will become this.

636
00:34:53.700 --> 00:34:55.700
a will be the product of

637
00:34:57.800 --> 00:34:59.000
three matrices p

638
00:35:00.300 --> 00:35:01.700
D and P

639
00:35:06.400 --> 00:35:07.000
transpose

640
00:35:09.500 --> 00:35:11.100
let me double check that to make sure it's not.

641
00:35:15.900 --> 00:35:16.600
the inverse

642
00:35:28.400 --> 00:35:29.600
I think it's inverse so.

643
00:35:32.300 --> 00:35:33.000
like that

644
00:35:34.900 --> 00:35:37.100
so let me show you how to get P once we

645
00:35:37.100 --> 00:35:40.200
 get p we can talk about inversion so we can see how we

646
00:35:40.200 --> 00:35:44.300
 get this and of course the prerequisite for the inverse

647
00:35:43.300 --> 00:35:45.000
 of a matrix is

648
00:35:46.900 --> 00:35:49.300
Elimination matrices which we talked to an LED

649
00:35:49.300 --> 00:35:52.200
 composition and then the for this we will have talked about

650
00:35:52.200 --> 00:35:53.800
 bases or basis.

651
00:35:54.900 --> 00:35:55.100
and

652
00:35:56.300 --> 00:35:58.000
well everything we just

653
00:35:58.700 --> 00:35:59.900
listed in the agenda.

654
00:36:02.200 --> 00:36:05.700
So the composition of a will give us these three

655
00:36:05.700 --> 00:36:08.100
 Matrix. So let's see how what are the steps that we need

656
00:36:08.100 --> 00:36:11.400
 to perform to get to this and through these

657
00:36:11.400 --> 00:36:14.700
 steps. It will revisit eigenvalues eigenvectors.

658
00:36:16.400 --> 00:36:19.100
Bases right. So we want

659
00:36:19.100 --> 00:36:19.200
 to

660
00:36:20.300 --> 00:36:21.000
fill the

661
00:36:21.600 --> 00:36:24.900
check check the prerequisites before getting the

662
00:36:24.900 --> 00:36:25.300
 PCA.

663
00:36:29.000 --> 00:36:29.200
Okay.

664
00:36:34.100 --> 00:36:35.500
So the first thing we are going to do.

665
00:36:37.000 --> 00:36:37.400
is

666
00:36:39.100 --> 00:36:41.000
Get the characteristic polynomial.

667
00:36:43.700 --> 00:36:45.600
And to do that we will need to determinant.

668
00:36:46.300 --> 00:36:46.700
function

669
00:36:48.400 --> 00:36:49.200
whose argument

670
00:36:50.600 --> 00:36:53.400
is the identity Matrix multiplied?

671
00:36:54.900 --> 00:36:58.300
By Lambda, let me write it down. So we

672
00:36:57.300 --> 00:36:58.700
 will have

673
00:37:00.500 --> 00:37:01.100
step one

674
00:37:04.800 --> 00:37:05.400
step one

675
00:37:12.600 --> 00:37:14.100
direct heuristic

676
00:37:15.800 --> 00:37:16.700
Ali

677
00:37:19.100 --> 00:37:19.600
normal

678
00:37:22.900 --> 00:37:25.900
Let me add my own step because this is a

679
00:37:25.900 --> 00:37:26.100
 bit more.

680
00:37:27.600 --> 00:37:28.300
compressed

681
00:37:30.000 --> 00:37:30.400
the

682
00:37:41.000 --> 00:37:41.900
Lambda

683
00:37:45.700 --> 00:37:48.200
times are in linear algebra. I is

684
00:37:48.200 --> 00:37:49.700
 the identity Matrix.

685
00:37:59.100 --> 00:38:01.900
And step two will be the characteristic polynomial.

686
00:38:03.300 --> 00:38:06.400
So we have if you remember we said that the identity Matrix.

687
00:38:10.000 --> 00:38:10.300
is

688
00:38:11.900 --> 00:38:14.300
By the way, I have to remember to make this bold because the

689
00:38:14.300 --> 00:38:15.700
 notation is very important.

690
00:38:16.900 --> 00:38:17.800
copy this

691
00:38:20.100 --> 00:38:20.200
here

692
00:38:20.900 --> 00:38:22.100
so the identity Matrix

693
00:38:25.100 --> 00:38:28.400
since the Matrix a is a 2 by 2 the identity Matrix

694
00:38:28.400 --> 00:38:29.600
 here will be a 2 by 2.

695
00:38:37.100 --> 00:38:40.200
It will be one across the main diagonal.

696
00:38:41.300 --> 00:38:41.500
So I

697
00:38:44.600 --> 00:38:45.700
will be this Matrix.

698
00:38:49.300 --> 00:38:50.200
1 0

699
00:38:52.100 --> 00:38:53.100
0 1

700
00:39:02.800 --> 00:39:05.700
Yes, if we multiply the

701
00:39:05.700 --> 00:39:06.100
 scalar.

702
00:39:06.700 --> 00:39:09.700
With the identity Matrix, what do we get? So we

703
00:39:09.700 --> 00:39:10.900
 have the scale of Lambda?

704
00:39:12.600 --> 00:39:15.700
Whose value is to be determined? That's why this function called determinant.

705
00:39:16.400 --> 00:39:19.600
We are trying to determine the the undetermined which

706
00:39:19.600 --> 00:39:21.300
 and that untermined is that Lambda.

707
00:39:21.900 --> 00:39:23.200
a Greek letter

708
00:39:24.500 --> 00:39:28.400
So what we will do is then we will take this identity Matrix.

709
00:39:29.500 --> 00:39:31.300
multiplied by Lambda

710
00:39:37.000 --> 00:39:37.700
Lambda

711
00:39:39.600 --> 00:39:43.500
2 well, we know what we see what happens in Jupiter

712
00:39:42.500 --> 00:39:45.200
 notebook when you multiply the scalar.

713
00:39:45.600 --> 00:39:48.400
product on the with the identity Matrix

714
00:39:49.200 --> 00:39:50.300
just for clarity. I'm going to use the

715
00:39:51.600 --> 00:39:52.400
time symbol

716
00:39:54.700 --> 00:39:57.700
so multiply that skill and these will be replaced.

717
00:39:58.900 --> 00:40:01.800
So we can put the scalar here next to

718
00:40:01.800 --> 00:40:04.200
 it. And this will give us a new Matrix.

719
00:40:05.600 --> 00:40:07.100
But all the ones have now become.

720
00:40:08.900 --> 00:40:09.600
Lambda

721
00:40:12.300 --> 00:40:12.700
this

722
00:40:14.200 --> 00:40:16.500
we will then put inside the determinate function.

723
00:40:18.800 --> 00:40:19.100
Okay.

724
00:40:21.300 --> 00:40:23.100
So they get the characteristic polynomial.

725
00:40:28.600 --> 00:40:31.100
I think this is messy. So let me remove these and put them

726
00:40:31.100 --> 00:40:32.500
 somewhere where you won't see them.

727
00:40:33.600 --> 00:40:34.600
I'll put them here.

728
00:40:37.600 --> 00:40:39.000
Just get them out of your way.

729
00:40:40.500 --> 00:40:41.900
So what we will do is we will take.

730
00:40:46.700 --> 00:40:47.500
this Matrix

731
00:40:48.400 --> 00:40:51.600
Okay, I just put the times just so you know that we're multiplying it

732
00:40:51.600 --> 00:40:52.900
 together. I'm just going to go and remove them again.

733
00:40:53.700 --> 00:40:54.900
So we're gonna take this product.

734
00:40:55.700 --> 00:40:57.200
subtract it from a

735
00:40:59.900 --> 00:41:02.900
minus this Matrix a minus that

736
00:41:02.900 --> 00:41:03.300
 Matrix

737
00:41:04.100 --> 00:41:06.800
the difference we will put inside the determinate function.

738
00:41:07.700 --> 00:41:08.100
which will

739
00:41:09.200 --> 00:41:12.300
output the characteristic polynomial which will look like

740
00:41:12.300 --> 00:41:14.600
 you will see what it would look like now so we have

741
00:41:16.100 --> 00:41:17.800
we have the Matrix a

742
00:41:19.600 --> 00:41:20.700
The Matrix a

743
00:41:24.400 --> 00:41:24.900
minus

744
00:41:28.200 --> 00:41:29.300
Lambda times

745
00:41:30.400 --> 00:41:31.100
identity

746
00:41:33.900 --> 00:41:34.100
this

747
00:41:36.300 --> 00:41:38.400
will be the argument for the determinant function.

748
00:41:43.500 --> 00:41:46.700
And this will be basically be well.

749
00:41:48.700 --> 00:41:51.200
if you remember about the what we said about determinant, it

750
00:41:51.200 --> 00:41:52.400
 will be the

751
00:41:56.100 --> 00:41:56.800
the product

752
00:41:58.600 --> 00:42:01.200
of the numbers on the main diagonal subtracted by

753
00:42:01.200 --> 00:42:04.400
 the product of the numbers across other

754
00:42:04.400 --> 00:42:07.300
 diagonal but we must first take the difference of these two

755
00:42:07.300 --> 00:42:08.000
 matrices. So I'm going to take

756
00:42:10.700 --> 00:42:11.600
Matrix a

757
00:42:14.600 --> 00:42:14.900
matrix a

758
00:42:21.500 --> 00:42:23.700
and if we subtract from The Matrix a

759
00:42:24.500 --> 00:42:26.900
This product Matrix this new Matrix Lambda. I

760
00:42:27.600 --> 00:42:28.800
this will become 2 minus.

761
00:42:31.100 --> 00:42:31.800
Lambda

762
00:42:33.700 --> 00:42:35.000
3 minus Lambda

763
00:42:39.300 --> 00:42:40.600
so the determinant of that

764
00:42:50.100 --> 00:42:50.400
this

765
00:42:52.600 --> 00:42:53.200
expression

766
00:42:54.400 --> 00:42:54.800
times

767
00:42:55.700 --> 00:42:58.200
that expression minus this

768
00:43:00.200 --> 00:43:03.100
component times that component and we

769
00:43:03.100 --> 00:43:04.700
 will get the following polynomial.

770
00:43:06.200 --> 00:43:08.200
Which we call the characteristic polynomial.

771
00:43:09.100 --> 00:43:09.200
so

772
00:43:10.400 --> 00:43:13.300
skipping the product and difference and

773
00:43:14.100 --> 00:43:16.900
Expansion stuff we will get Lambda squared.

774
00:43:20.400 --> 00:43:21.500
Lambda squared

775
00:43:22.900 --> 00:43:24.300
minus 5 Lambda

776
00:43:27.100 --> 00:43:27.800
plus 4

777
00:43:28.700 --> 00:43:30.600
that is your characteristic polynomial.

778
00:43:32.700 --> 00:43:33.300
step 3

779
00:43:35.500 --> 00:43:36.600
for step 3 we must

780
00:43:37.600 --> 00:43:40.800
find the roots remember, this is the variable.

781
00:43:41.900 --> 00:43:43.500
And we want to know what this will be equal to.

782
00:43:46.300 --> 00:43:47.600
so to find the roots of the

783
00:43:49.400 --> 00:43:51.800
characteristic polynomial this will be step 3.

784
00:43:52.700 --> 00:43:53.200
roots

785
00:43:54.600 --> 00:43:54.900
of

786
00:43:58.900 --> 00:44:01.300
characteristic polynomial

787
00:44:04.600 --> 00:44:07.100
so we just solve for Lambda and we

788
00:44:07.100 --> 00:44:07.400
 will get

789
00:44:09.300 --> 00:44:09.500
two

790
00:44:11.200 --> 00:44:11.900
lambdas

791
00:44:13.400 --> 00:44:14.300
Lambda 1

792
00:44:21.300 --> 00:44:22.100
will be equal to

793
00:44:26.000 --> 00:44:26.300
4

794
00:44:28.600 --> 00:44:29.500
and the other one will be

795
00:44:31.700 --> 00:44:31.900
1

796
00:44:33.600 --> 00:44:36.000
eigenvalue 1 eigenvalue 2

797
00:44:37.500 --> 00:44:39.000
Those are your two eigenvalues.

798
00:44:40.900 --> 00:44:41.100
Okay.

799
00:44:44.100 --> 00:44:47.400
so to find the roots of the characteristic polymers to find the eigenvalues now

800
00:44:47.400 --> 00:44:49.000
 that we have the eigenvalues we can go ahead and

801
00:44:50.300 --> 00:44:52.700
Find the eigenvector for our Matrix.

802
00:44:53.400 --> 00:44:55.900
nuances should be negative 4 negative 1

803
00:44:58.900 --> 00:45:01.800
That I make a mistake again which Steps

804
00:45:01.800 --> 00:45:02.600
 step one steps.

805
00:45:05.600 --> 00:45:08.700
the roots of the Lambda squared

806
00:45:08.700 --> 00:45:11.800
 minus 5 if you have minus 5 then

807
00:45:13.400 --> 00:45:16.600
so it'll be Lambda minus 4 times Lambda minus

808
00:45:16.600 --> 00:45:17.700
 5 would be the

809
00:45:19.300 --> 00:45:22.200
factors of Lambda Square minus 5 Lambda Plus

810
00:45:26.600 --> 00:45:29.200
And why does it say something different here? You know

811
00:45:29.200 --> 00:45:30.200
 what? I'm going to cheat?

812
00:45:31.200 --> 00:45:34.100
Let's just double check. I'm going to copy.

813
00:45:35.800 --> 00:45:36.500
this bit

814
00:45:37.400 --> 00:45:40.400
and there's this very nice website called symbol that

815
00:45:41.800 --> 00:45:43.600
I don't like to spend too much time.

816
00:45:44.800 --> 00:45:45.900
on algebraic

817
00:45:49.200 --> 00:45:52.100
You know manipulation. So I'm just gonna swap the lambdas with x.

818
00:45:52.900 --> 00:45:56.300
And I'll tell this very nice website to solve Forex.

819
00:45:57.600 --> 00:46:00.200
It's the double check. Maybe the mistake is here.

820
00:46:01.500 --> 00:46:03.800
And all of the roots were the rules.

821
00:46:05.300 --> 00:46:08.300
Yeah X so if we would if we move negative wanted

822
00:46:08.300 --> 00:46:12.400
 other side. Yeah, you want. Yeah. Yeah, it's

823
00:46:11.400 --> 00:46:14.400
 a good thing we check. Yeah. Well, I also

824
00:46:14.400 --> 00:46:17.300
 use up opportunity to show you simple. That's very

825
00:46:17.300 --> 00:46:18.700
 helpful in the situations like this.

826
00:46:19.400 --> 00:46:19.600
Okay.

827
00:46:22.800 --> 00:46:24.100
so stuff for would be

828
00:46:25.100 --> 00:46:26.900
to Now find the eigen

829
00:46:28.100 --> 00:46:29.200
vectors so

830
00:46:30.800 --> 00:46:31.100
we have

831
00:46:34.800 --> 00:46:35.600
this expression

832
00:46:39.500 --> 00:46:40.300
step 4

833
00:46:45.200 --> 00:46:46.100
find the eigen.

834
00:46:49.200 --> 00:46:49.900
vectors

835
00:46:53.900 --> 00:46:55.500
so we want

836
00:46:58.700 --> 00:46:59.400
this equation

837
00:47:01.100 --> 00:47:01.500
a

838
00:47:05.800 --> 00:47:07.100
Lambda equals B

839
00:47:09.800 --> 00:47:10.000
now

840
00:47:11.800 --> 00:47:14.800
you may not be able to discern but

841
00:47:14.800 --> 00:47:17.200
 I'm gonna try to make the Lambda here bold.

842
00:47:18.200 --> 00:47:21.300
So math. Yes makes it bold.

843
00:47:24.600 --> 00:47:27.100
I don't I I don't think even I can see but this is

844
00:47:27.100 --> 00:47:29.700
 supposed to be the vector. It's slightly.

845
00:47:31.100 --> 00:47:32.200
more dense

846
00:47:33.400 --> 00:47:35.400
and those are the eigenvalues.

847
00:47:37.100 --> 00:47:40.400
It's not that clear. Just let's keep that in mind. Okay, so a is

848
00:47:40.400 --> 00:47:41.300
 going to be a matrix.

849
00:47:43.600 --> 00:47:44.800
He's going to be a matrix.

850
00:47:46.100 --> 00:47:49.500
B is going to be a vector and this is the eigenvector

851
00:47:51.400 --> 00:47:54.900
for emphasis. These are the eigenvalues. These must

852
00:47:54.900 --> 00:47:55.700
 go in there.

853
00:47:57.600 --> 00:48:00.800
Okay. So how do we find the eigenvectors we

854
00:48:00.800 --> 00:48:01.100
 do this?

855
00:48:03.700 --> 00:48:05.700
We take our original Matrix.

856
00:48:07.300 --> 00:48:07.700
a

857
00:48:18.300 --> 00:48:19.600
And we multiplied by.

858
00:48:21.600 --> 00:48:24.100
a vector with unknown quantities

859
00:48:26.200 --> 00:48:29.200
So the eigenvector whose values is

860
00:48:29.200 --> 00:48:29.800
 still not known?

861
00:48:31.800 --> 00:48:34.300
Multiplied by so what do we put here? We put

862
00:48:36.300 --> 00:48:36.700
X

863
00:48:39.500 --> 00:48:41.000
sub 1 x sub 2

864
00:48:44.200 --> 00:48:45.000
is a column.

865
00:48:47.800 --> 00:48:51.600
This will then turn it into a system of

866
00:48:51.600 --> 00:48:52.000
 equations.

867
00:48:53.800 --> 00:48:56.000
system of linear equations right because none of these

868
00:48:57.300 --> 00:49:00.300
Are they're all I mean these values are raised

869
00:49:00.300 --> 00:49:00.600
 to the power one.

870
00:49:01.500 --> 00:49:03.500
And this will be cool to the vector.

871
00:49:07.100 --> 00:49:07.300
0

872
00:49:13.200 --> 00:49:16.400
So we want to find the values for

873
00:49:16.400 --> 00:49:16.600
 x.

874
00:49:18.300 --> 00:49:21.200
That will make this matrix multiplication. Give us

875
00:49:21.200 --> 00:49:22.300
 a vector 0 0

876
00:49:24.900 --> 00:49:27.100
now, what does this if we were to

877
00:49:27.100 --> 00:49:29.800
 convert this into a matrix? What we what what would we get?

878
00:49:30.600 --> 00:49:33.200
We would get the following system of equations.

879
00:49:34.400 --> 00:49:34.600
So

880
00:49:39.500 --> 00:49:40.500
expressing as

881
00:49:42.500 --> 00:49:43.900
systems of equations

882
00:49:45.900 --> 00:49:46.500
we will get

883
00:49:52.600 --> 00:49:53.200
I think I

884
00:49:56.300 --> 00:49:56.800
have a typo.

885
00:50:02.300 --> 00:50:02.800
this might

886
00:50:05.400 --> 00:50:06.600
the table is

887
00:50:09.100 --> 00:50:10.200
213

888
00:50:11.300 --> 00:50:11.500
2

889
00:50:12.700 --> 00:50:14.400
to want to just so we actually want

890
00:50:18.500 --> 00:50:19.800
a minus 1 Lambda

891
00:50:22.700 --> 00:50:26.200
a minus 1 Lambda. So we want this Matrix multiplied

892
00:50:25.200 --> 00:50:27.100
 by the eigenvector.

893
00:50:28.100 --> 00:50:29.700
So this should become.

894
00:50:31.600 --> 00:50:32.600
A minus

895
00:50:39.100 --> 00:50:40.000
the identity

896
00:50:42.200 --> 00:50:43.000
Matrix

897
00:50:51.500 --> 00:50:52.100
times

898
00:50:54.800 --> 00:50:56.300
the vector Lambda

899
00:50:58.500 --> 00:50:59.300
okay, because here we

900
00:51:00.500 --> 00:51:03.700
Took the determinant of a minus Lambda and

901
00:51:03.700 --> 00:51:05.200
 the idea. Well, this is it. So

902
00:51:06.500 --> 00:51:08.200
same thing we've done up here.

903
00:51:09.100 --> 00:51:11.100
First we took the determinant of this Matrix.

904
00:51:12.700 --> 00:51:13.800
now we are taking the

905
00:51:14.800 --> 00:51:16.000
Now we're solving for.

906
00:51:16.800 --> 00:51:17.900
the eigenvector

907
00:51:19.100 --> 00:51:20.000
of this Matrix

908
00:51:21.500 --> 00:51:21.800
Okay.

909
00:51:23.900 --> 00:51:25.500
So this Matrix actually become.

910
00:51:26.700 --> 00:51:29.100
two two one three

911
00:51:32.600 --> 00:51:33.000
so two two

912
00:51:38.300 --> 00:51:38.900
one three

913
00:51:41.100 --> 00:51:41.300
and

914
00:51:49.300 --> 00:51:51.300
see if I skip something here.

915
00:52:04.100 --> 00:52:04.400
Yes.

916
00:52:05.300 --> 00:52:08.100
so if we will take we have to choose one

917
00:52:08.100 --> 00:52:11.300
 of these well to find the eigenvector you

918
00:52:11.300 --> 00:52:11.300
 must

919
00:52:12.300 --> 00:52:14.600
find the actor for specific eigenvalue.

920
00:52:15.600 --> 00:52:17.200
So I will denote.

921
00:52:17.900 --> 00:52:19.700
these as sub 1 and sub 2

922
00:52:22.600 --> 00:52:22.700
Okay.

923
00:52:24.800 --> 00:52:25.500
so these are

924
00:52:26.400 --> 00:52:26.500
the

925
00:52:27.800 --> 00:52:30.400
SE are the two Roots we found so let's first

926
00:52:30.400 --> 00:52:31.300
 solve for

927
00:52:33.600 --> 00:52:36.300
let me make them. Let me make this two and make this one because I want

928
00:52:36.300 --> 00:52:38.100
 to follow the or sequence I have here.

929
00:52:39.300 --> 00:52:42.100
Anyway, this is the first route. This is the second root.

930
00:52:43.200 --> 00:52:46.200
Okay, so we're gonna find the actor eigenvectors for

931
00:52:46.200 --> 00:52:47.300
 Lambda sub 1

932
00:52:50.800 --> 00:52:51.500
Lambda

933
00:52:55.800 --> 00:52:56.500
sub 1

934
00:52:57.800 --> 00:52:58.600
Which means that?

935
00:52:59.600 --> 00:53:02.400
We must evaluate this Matrix. So

936
00:53:02.400 --> 00:53:02.900
 2 minus.

937
00:53:03.900 --> 00:53:05.600
1 will make this

938
00:53:06.500 --> 00:53:06.700
one

939
00:53:10.700 --> 00:53:11.900
then this brings two.

940
00:53:12.800 --> 00:53:15.300
This remains one and three minus 1 is

941
00:53:15.300 --> 00:53:16.500
 just two. So this becomes 2.

942
00:53:18.600 --> 00:53:21.600
Okay, so this after we

943
00:53:21.600 --> 00:53:22.500
 plug in one for these?

944
00:53:23.900 --> 00:53:26.600
Variables evaluate the expressions and

945
00:53:26.600 --> 00:53:27.600
 evaluate these differences.

946
00:53:28.400 --> 00:53:29.900
And we will get this Matrix.

947
00:53:31.200 --> 00:53:33.400
For the other eigenvale value, we'll have a different.

948
00:53:34.900 --> 00:53:38.700
We'd have different components Matrix. Anyway, we

949
00:53:37.700 --> 00:53:41.100
 turn this into a system of a linear

950
00:53:40.100 --> 00:53:41.700
 equations. We will get

951
00:53:42.600 --> 00:53:42.900
the following

952
00:53:44.100 --> 00:53:45.600
to equations we will have

953
00:53:47.600 --> 00:53:47.800
one

954
00:53:49.600 --> 00:53:50.500
x sub 1

955
00:53:52.700 --> 00:53:54.500
plus 2 times x Up 2

956
00:53:56.400 --> 00:53:57.700
and of course equal to 0

957
00:54:01.200 --> 00:54:03.200
And you will get the second equation.

958
00:54:06.600 --> 00:54:09.300
And they will all be and since we also have one or two

959
00:54:09.300 --> 00:54:11.700
 down here. We also have the same.

960
00:54:12.500 --> 00:54:12.800
system

961
00:54:14.400 --> 00:54:16.400
So both of these equations are identical.

962
00:54:18.300 --> 00:54:21.100
If you remember from our last session, we eliminated one of these so we

963
00:54:21.100 --> 00:54:21.400
 can just

964
00:54:22.200 --> 00:54:23.200
take one of them.

965
00:54:24.400 --> 00:54:25.200
and solve for

966
00:54:27.400 --> 00:54:28.600
software X and Y

967
00:54:29.700 --> 00:54:31.200
or x sub 1 and x sub 2

968
00:54:32.200 --> 00:54:35.300
so x sub 1 excuse me x sub 1

969
00:54:38.300 --> 00:54:39.100
would become

970
00:54:44.100 --> 00:54:44.900
negative 2

971
00:54:46.500 --> 00:54:48.700
x sub 2 if we do the algebra.

972
00:54:49.700 --> 00:54:51.100
Will become one.

973
00:54:53.900 --> 00:54:55.500
Okay, so, you know the whole story.

974
00:54:57.300 --> 00:54:58.800
moving X up to another side

975
00:54:59.800 --> 00:55:02.200
And then moving except one other side. We'll get these two.

976
00:55:03.700 --> 00:55:04.800
We get these two routes.

977
00:55:05.400 --> 00:55:08.700
So we don't need to have this repetition we can just keep one of those systems since

978
00:55:08.700 --> 00:55:09.400
 they're identical.

979
00:55:10.900 --> 00:55:12.500
and solving

980
00:55:15.800 --> 00:55:16.200
or

981
00:55:18.100 --> 00:55:18.900
x sub 1

982
00:55:20.700 --> 00:55:21.500
and X up to

983
00:55:23.200 --> 00:55:26.100
now that we have x sub 1 and x sub 2 we will be know the components of

984
00:55:26.100 --> 00:55:27.200
 the eigenvector.

985
00:55:29.500 --> 00:55:32.300
So we know we can plug in these numbers we can plug in minus 2

986
00:55:32.300 --> 00:55:32.800
 and minus 1.

987
00:55:33.600 --> 00:55:34.100
in here

988
00:55:37.100 --> 00:55:38.700
and so our Vector becomes

989
00:55:42.800 --> 00:55:46.000
now here, we also need something called a basis. So we

990
00:55:45.200 --> 00:55:48.200
 need the eigenvector for

991
00:55:48.200 --> 00:55:52.200
 the first eigenvalid and the eigenvector of the second eigenvalue to

992
00:55:51.200 --> 00:55:54.900
 put them together inside the Matrix because we're

993
00:55:54.900 --> 00:55:57.100
 not just solving for the eigenvectors. We're actually

994
00:55:57.100 --> 00:56:00.000
 trying to get to diagonalization. So we're not quite done yet.

995
00:56:00.600 --> 00:56:01.800
which is why I will create a

996
00:56:03.900 --> 00:56:04.600
Vector here

997
00:56:08.100 --> 00:56:09.500
So let's say denote the first.

998
00:56:10.800 --> 00:56:11.600
eigenvector

999
00:56:13.200 --> 00:56:16.500
And we will use V sub 1 so V sub

1000
00:56:16.500 --> 00:56:17.300
 1 is going to be.

1001
00:56:18.300 --> 00:56:18.900
the vector

1002
00:56:22.400 --> 00:56:23.600
with the roots we have just found.

1003
00:56:27.800 --> 00:56:30.600
and oops the roots

1004
00:56:30.600 --> 00:56:30.800
 are

1005
00:56:33.400 --> 00:56:35.300
negative 2 and 1

1006
00:56:36.200 --> 00:56:37.100
so negative 2

1007
00:56:40.100 --> 00:56:40.600
and 1

1008
00:56:46.700 --> 00:56:49.100
we will put this eigenvector and the second one

1009
00:56:49.100 --> 00:56:49.700
 inside.

1010
00:56:50.700 --> 00:56:52.800
A matrix so these will become the columns.

1011
00:56:53.800 --> 00:56:54.400
of The Matrix

1012
00:56:55.400 --> 00:56:56.300
Why are you complaining?

1013
00:57:21.100 --> 00:57:24.300
That's step five is to of course find the eigenvector for

1014
00:57:24.300 --> 00:57:25.400
 the second eigenvalue.

1015
00:57:26.300 --> 00:57:27.800
I'm going to skip the steps.

1016
00:57:31.300 --> 00:57:32.000
Just to save time.

1017
00:57:33.600 --> 00:57:36.400
I'll complete the steps after today's session

1018
00:57:36.400 --> 00:57:39.800
 but when we solve for the second eigen.

1019
00:57:40.900 --> 00:57:42.400
Value which is equal to 4.

1020
00:57:43.700 --> 00:57:46.700
So I I can value top two

1021
00:57:46.700 --> 00:57:49.200
 is the four eigenvalues of what we say is equal to 1.

1022
00:57:52.800 --> 00:57:54.400
We will get a second eigenvector.

1023
00:57:55.400 --> 00:57:56.100
V sub 2

1024
00:57:57.100 --> 00:57:57.900
with components

1025
00:57:58.800 --> 00:57:59.500
one one

1026
00:58:01.400 --> 00:58:01.700
okay.

1027
00:58:02.600 --> 00:58:06.100
With these two together, we can construct The Matrix. So let's proceed

1028
00:58:05.100 --> 00:58:06.600
 to the next step.

1029
00:58:07.300 --> 00:58:07.400
step

1030
00:58:08.900 --> 00:58:09.200
6

1031
00:58:11.600 --> 00:58:11.800
Yes.

1032
00:58:14.300 --> 00:58:15.400
four steps six

1033
00:58:16.500 --> 00:58:17.500
There we go.

1034
00:58:18.600 --> 00:58:21.200
If I scroll up here to the beginning.

1035
00:58:31.100 --> 00:58:34.300
I remove the comment but we said that we want to decompose a into the

1036
00:58:34.300 --> 00:58:35.200
 following matrices.

1037
00:58:35.800 --> 00:58:37.500
We said we want to decompose.

1038
00:58:38.400 --> 00:58:41.800
a to the following matrices, so we have a

1039
00:58:45.200 --> 00:58:45.500
equals

1040
00:58:47.500 --> 00:58:47.800
p

1041
00:58:49.200 --> 00:58:52.900
Which is going to contain the eigenvectors as

1042
00:58:52.900 --> 00:58:53.200
 columns.

1043
00:58:55.300 --> 00:58:56.700
times d

1044
00:58:58.500 --> 00:58:59.900
And then the inverse of P.

1045
00:59:04.500 --> 00:59:06.700
p is going to contain the eigenvectors so p

1046
00:59:08.200 --> 00:59:08.600
where

1047
00:59:14.200 --> 00:59:15.100
p is the

1048
00:59:16.700 --> 00:59:17.400
Matrix

1049
00:59:19.700 --> 00:59:20.800
with eigenvectors

1050
00:59:23.300 --> 00:59:24.000
as columns

1051
00:59:31.500 --> 00:59:33.400
D will be the Matrix.

1052
00:59:40.400 --> 00:59:41.000
containing

1053
00:59:42.300 --> 00:59:43.400
the eigenvalues

1054
00:59:44.400 --> 00:59:45.500
for the eigenvectors

1055
00:59:47.600 --> 00:59:47.900
and

1056
00:59:50.300 --> 00:59:51.700
P to the power negative 1

1057
00:59:56.500 --> 00:59:58.200
is the invert is the

1058
01:00:00.600 --> 01:00:03.700
inversion of the Matrix this minus one

1059
01:00:03.700 --> 01:00:05.600
 business by the way has a very nice explanation.

1060
01:00:07.500 --> 01:00:08.500
and it has to do with

1061
01:00:12.600 --> 01:00:16.800
Division you see we cannot we cannot perform division in linear

1062
01:00:15.800 --> 01:00:18.700
 algebra. If you remember the axioms

1063
01:00:18.700 --> 01:00:21.500
 that we talked about. I think we talked about the axioms of

1064
01:00:21.500 --> 01:00:24.800
 vectors not the axioms of matrices, but anyway division is

1065
01:00:24.800 --> 01:00:24.800
 not

1066
01:00:26.300 --> 01:00:28.300
what you can do what you can't do however is

1067
01:00:30.000 --> 01:00:30.800
multiply

1068
01:00:34.500 --> 01:00:37.500
by the you know, one over the

1069
01:00:37.500 --> 01:00:40.600
 value. So for example, if you have a scalar three to

1070
01:00:40.600 --> 01:00:41.500
 cancel it out.

1071
01:00:42.300 --> 01:00:44.200
It can multiply by one over three.

1072
01:00:45.200 --> 01:00:45.400
so

1073
01:00:47.300 --> 01:00:50.800
basically, if you have a denominator, excuse

1074
01:00:50.800 --> 01:00:53.500
 me, if you have a ratio like like so

1075
01:00:53.500 --> 01:00:54.300
 you know like

1076
01:00:57.500 --> 01:01:00.200
I want right now. But if basically if you have one over three, you can

1077
01:01:00.200 --> 01:01:01.900
 represent us three to the power negative 1.

1078
01:01:03.500 --> 01:01:06.500
This is where the this is where the mind is one comes

1079
01:01:06.500 --> 01:01:08.300
 from. So this should be minus 1.

1080
01:01:10.500 --> 01:01:10.800
minus 1

1081
01:01:13.100 --> 01:01:14.200
and why is it not appearing?

1082
01:01:16.400 --> 01:01:17.400
Why is it out of here?

1083
01:01:20.600 --> 01:01:21.300
Save the file.

1084
01:01:27.400 --> 01:01:27.600
There we go.

1085
01:01:30.300 --> 01:01:31.900
There we go. Okay, so

1086
01:01:34.100 --> 01:01:35.100
We have just solved this.

1087
01:01:36.700 --> 01:01:40.000
We have also actually solved that we actually solve this before

1088
01:01:39.100 --> 01:01:40.400
 we did that.

1089
01:01:41.400 --> 01:01:44.000
And this I'll show you how it's the I'll remind you how it's done again.

1090
01:01:44.800 --> 01:01:47.700
So I'm going to scroll all the way down.

1091
01:01:49.600 --> 01:01:52.100
So we will take these together stack them into a matrix

1092
01:01:52.100 --> 01:01:52.600
 and we'll get

1093
01:01:53.600 --> 01:01:54.700
the Matrix p

1094
01:01:55.500 --> 01:01:55.800
Okay.

1095
01:01:57.500 --> 01:01:57.500
so

1096
01:01:58.800 --> 01:01:59.300
step six

1097
01:02:00.600 --> 01:02:01.200
you will say

1098
01:02:02.800 --> 01:02:03.000
is

1099
01:02:05.300 --> 01:02:07.400
plugin values

1100
01:02:09.600 --> 01:02:09.900
or

1101
01:02:14.100 --> 01:02:15.300
Math, yes.

1102
01:02:16.300 --> 01:02:17.700
p and

1103
01:02:21.900 --> 01:02:22.200
D

1104
01:02:24.600 --> 01:02:24.900
d

1105
01:02:35.200 --> 01:02:35.900
so that means that

1106
01:02:38.000 --> 01:02:38.600
a

1107
01:02:42.500 --> 01:02:43.600
will remain what it is.

1108
01:02:47.700 --> 01:02:48.300
That's a

1109
01:02:50.900 --> 01:02:51.200
p

1110
01:02:54.300 --> 01:02:55.900
Will be the eigenvectors.

1111
01:03:00.900 --> 01:03:03.200
So that's negative 2 and 1 for their first column.

1112
01:03:03.200 --> 01:03:03.500
 So

1113
01:03:04.400 --> 01:03:06.900
negative 2 and 1 for the first column

1114
01:03:10.300 --> 01:03:11.900
One and one for the second column so one.

1115
01:03:19.200 --> 01:03:20.400
and the one for the second column

1116
01:03:22.200 --> 01:03:25.400
if V sub 1 V sub 2 first eigenvector second

1117
01:03:25.400 --> 01:03:26.000
 eigenvector.

1118
01:03:27.900 --> 01:03:28.600
and then d

1119
01:03:31.100 --> 01:03:33.100
will be the diagonal matrix containing

1120
01:03:33.900 --> 01:03:36.300
The eigenvalue so I'm going to set this all to

1121
01:03:36.300 --> 01:03:37.700
 0 what were the eigenvalues again?

1122
01:03:38.700 --> 01:03:39.500
one of them was

1123
01:03:41.300 --> 01:03:44.400
yeah, the first argument value was one and the

1124
01:03:44.400 --> 01:03:46.600
 second argue value was 4 so this will become one.

1125
01:03:47.700 --> 01:03:48.400
and four

1126
01:03:52.200 --> 01:03:54.000
the inverse of a matrix

1127
01:03:55.500 --> 01:03:57.900
Let me take you to Google Sheets to Google Images to show you.

1128
01:03:58.700 --> 01:04:01.100
Pictorially how it solved that's lengthy. I'm

1129
01:04:01.100 --> 01:04:02.100
 not gonna we won't do it here.

1130
01:04:03.700 --> 01:04:04.600
But it's similar to.

1131
01:04:11.600 --> 01:04:12.000
LED composition

1132
01:04:15.900 --> 01:04:18.400
so P if had we solved for

1133
01:04:18.400 --> 01:04:20.400
 it and we inverted it it would become.

1134
01:04:23.200 --> 01:04:25.000
Beautiful. They don't eat it's not here.

1135
01:04:31.500 --> 01:04:34.300
But let me show you how it's done. Let me see

1136
01:04:34.300 --> 01:04:37.100
 if I can use some sort of online tool to invert The

1137
01:04:37.100 --> 01:04:39.200
 Matrix P sub 1 would become.

1138
01:04:40.600 --> 01:04:43.100
To find the inversion to inverted Matrix. I'm going to

1139
01:04:43.100 --> 01:04:43.700
 type in version of

1140
01:04:45.200 --> 01:04:45.800
Matrix

1141
01:04:52.400 --> 01:04:55.200
yeah, I think it was this picture

1142
01:04:55.200 --> 01:04:55.700
 looked up.

1143
01:04:56.900 --> 01:04:57.800
so to

1144
01:04:58.800 --> 01:05:00.000
imagine imagine

1145
01:05:05.900 --> 01:05:08.500
trying to get a bigger picture. There we go. Imagine. This

1146
01:05:08.500 --> 01:05:09.300
 is p

1147
01:05:11.500 --> 01:05:12.700
And we want to introvert it.

1148
01:05:13.600 --> 01:05:16.000
To invert this Matrix. We argument the whole

1149
01:05:16.600 --> 01:05:20.100
 Matrix with the identity Matrix. Why because we

1150
01:05:19.100 --> 01:05:21.000
 need to keep track.

1151
01:05:22.200 --> 01:05:22.600
of the

1152
01:05:24.300 --> 01:05:26.200
elimination process procedures

1153
01:05:27.100 --> 01:05:28.600
so this will become your

1154
01:05:33.100 --> 01:05:34.200
elimination Matrix

1155
01:05:35.200 --> 01:05:37.800
If you remember from Led composition that the L Matrix.

1156
01:05:39.600 --> 01:05:42.900
Is the result of all of the elimination matrices and

1157
01:05:42.900 --> 01:05:46.800
 each elimination Matrix is going to contain one.

1158
01:05:48.300 --> 01:05:49.700
gaussian elimination step

1159
01:05:51.200 --> 01:05:54.800
So here, for example, we have how many steps to.

1160
01:05:56.800 --> 01:05:59.600
we take the difference of row two and Row

1161
01:05:59.600 --> 01:06:02.500
 one plug that into road to we take

1162
01:06:02.500 --> 01:06:02.700
 the

1163
01:06:06.500 --> 01:06:09.100
We take Row one multiplied by 3 out of two Row three

1164
01:06:09.100 --> 01:06:10.300
 replace Row three.

1165
01:06:11.100 --> 01:06:14.300
So we go through a series of gaussian lamination, and we know that

1166
01:06:14.300 --> 01:06:17.500
 we have eliminated the Matrix once our original

1167
01:06:17.500 --> 01:06:20.100
 Matrix looks ends up

1168
01:06:20.100 --> 01:06:21.800
 in row reduce row Echelon form.

1169
01:06:22.300 --> 01:06:23.500
You can see we've gone from

1170
01:06:24.500 --> 01:06:27.800
you know this leading one leading one and leading minus

1171
01:06:27.800 --> 01:06:29.200
 3 to getting

1172
01:06:30.100 --> 01:06:31.700
once all the across the diagonal

1173
01:06:32.300 --> 01:06:35.000
but look what has happened to the original ident Matrix.

1174
01:06:35.700 --> 01:06:37.700
And as all of these components, what are these components?

1175
01:06:38.600 --> 01:06:39.900
all of the combinations

1176
01:06:41.100 --> 01:06:43.800
for eliminating this Matrix this

1177
01:06:44.900 --> 01:06:47.200
Is p to the power negative 1?

1178
01:06:47.900 --> 01:06:49.000
This is the inversion.

1179
01:06:50.500 --> 01:06:51.100
of that

1180
01:06:52.200 --> 01:06:55.300
Now I'm not going to go through a series of gas elimination to know what this is

1181
01:06:55.300 --> 01:06:57.400
 and it's not even here in this reference.

1182
01:06:59.100 --> 01:06:59.300
So

1183
01:07:01.500 --> 01:07:02.900
I guess we could use pandas.

1184
01:07:03.900 --> 01:07:04.100
but

1185
01:07:07.200 --> 01:07:10.200
I'm just going to for the time being just for this because

1186
01:07:10.200 --> 01:07:10.800
 we know

1187
01:07:11.400 --> 01:07:13.500
And I want to lose a lot of time call this.

1188
01:07:20.300 --> 01:07:21.300
inversion

1189
01:07:23.600 --> 01:07:25.100
of P

1190
01:07:29.300 --> 01:07:30.200
so the Matrix a

1191
01:07:32.900 --> 01:07:35.500
can be decomposed into these

1192
01:07:35.500 --> 01:07:38.300
 three matrices three matrices multiplying we

1193
01:07:38.300 --> 01:07:39.600
 get and you will get the original Matrix.

1194
01:07:41.600 --> 01:07:42.600
in the context of

1195
01:07:43.800 --> 01:07:44.900
SVD this

1196
01:07:46.200 --> 01:07:49.100
I give value is going to these this Matrix of eigenvalue is

1197
01:07:49.100 --> 01:07:49.800
 going to be very important.

1198
01:07:52.600 --> 01:07:55.100
So one of the things that will help us get to the principal component.

1199
01:07:57.600 --> 01:08:00.200
Is that is there any more steps that is

1200
01:08:00.200 --> 01:08:01.600
 the only step now?

1201
01:08:03.200 --> 01:08:05.200
So we have just we have reviewed.

1202
01:08:07.600 --> 01:08:10.600
The process I can decomposition so we have just gone

1203
01:08:10.600 --> 01:08:10.900
 over that.

1204
01:08:11.900 --> 01:08:14.400
We have reviewed this in the process and we

1205
01:08:14.400 --> 01:08:17.400
 have seen what it means to have a character's characteristic polynomial

1206
01:08:17.400 --> 01:08:20.300
 and solve for the problem. And I have just shown you at least

1207
01:08:20.300 --> 01:08:22.400
 pictorially how to get the invention of a matrix.

1208
01:08:23.700 --> 01:08:25.100
Now let's talk about the basis.

1209
01:08:25.900 --> 01:08:27.800
What this piece of set?

1210
01:08:29.300 --> 01:08:30.100
instead of vectors

1211
01:08:30.900 --> 01:08:33.300
But a set of vectors with special rules.

1212
01:08:35.000 --> 01:08:35.200
so

1213
01:08:36.500 --> 01:08:38.300
Let me see if I can explain a basis.

1214
01:08:41.100 --> 01:08:44.200
Related to this example. Let me just double check

1215
01:08:44.200 --> 01:08:45.700
 my comments in here.

1216
01:08:57.100 --> 01:09:00.200
And we also need to talk about change of basis, but not

1217
01:09:01.200 --> 01:09:01.800
Just yet.

1218
01:09:02.500 --> 01:09:04.300
So I'm going to type it pieces.

1219
01:09:33.500 --> 01:09:38.300
you

1220
01:09:48.200 --> 01:09:49.800
okay, so we also want to talk about

1221
01:10:00.700 --> 01:10:01.400
orthogonal

1222
01:10:04.900 --> 01:10:06.400
vectors and other than normal

1223
01:10:10.900 --> 01:10:11.900
orthonormal

1224
01:10:13.400 --> 01:10:15.900
I just want to see if I can relate it to the example. We just looked at so

1225
01:10:17.400 --> 01:10:18.600
not an isolation

1226
01:10:31.200 --> 01:10:34.400
Okay, let me let me tell you what a basis is and then our related to

1227
01:10:34.400 --> 01:10:34.800
 this example.

1228
01:10:35.700 --> 01:10:37.300
So let's save this.

1229
01:10:38.500 --> 01:10:39.600
secret another one

1230
01:10:40.500 --> 01:10:41.500
that's tutorial.

1231
01:10:44.300 --> 01:10:45.200
I've done.

1232
01:11:00.800 --> 01:11:03.200
You want to understand what a base is set

1233
01:11:03.200 --> 01:11:03.300
 is.

1234
01:11:04.900 --> 01:11:07.700
It's kind of redundant to say basis set because a

1235
01:11:07.700 --> 01:11:10.300
 basis we just say basis, but it is a set.

1236
01:11:12.400 --> 01:11:15.700
Let me bring you my comments. So my notes.

1237
01:11:21.500 --> 01:11:22.700
A basis is a set.

1238
01:11:24.100 --> 01:11:25.800
of vectors over RN

1239
01:11:26.900 --> 01:11:27.000
so

1240
01:11:34.100 --> 01:11:38.100
we have a set where V1 V2 VN are

1241
01:11:37.100 --> 01:11:38.600
 all vectors.

1242
01:11:40.200 --> 01:11:43.200
And they are over orange. So that means that they're all the

1243
01:11:43.200 --> 01:11:43.800
 same dimension.

1244
01:11:45.300 --> 01:11:48.300
So if we talk about a 2d space this will have two components.

1245
01:11:49.200 --> 01:11:52.300
Like X Y X Y X Y X Y. They will

1246
01:11:52.300 --> 01:11:52.600
 be like a

1247
01:11:54.100 --> 01:11:56.100
n vectors in a two-dimensional plane

1248
01:11:57.200 --> 01:12:00.100
in order for a set to be a basis set.

1249
01:12:03.300 --> 01:12:04.800
the vectors must span

1250
01:12:05.300 --> 01:12:07.800
to span means that they must all have the same dimension.

1251
01:12:08.600 --> 01:12:11.200
If this RN is 3D if it's R to

1252
01:12:11.200 --> 01:12:14.400
 the power 3 this must be three-dimensional. This must be through that

1253
01:12:14.400 --> 01:12:15.900
 dimensional. This must be dimension.

1254
01:12:16.800 --> 01:12:19.200
awareness are two which is

1255
01:12:19.200 --> 01:12:19.900
 two dimensional and

1256
01:12:21.200 --> 01:12:22.400
they all have to be two-dimensional.

1257
01:12:24.300 --> 01:12:27.600
And the second condition is that they must speak independent. Now

1258
01:12:27.600 --> 01:12:29.000
 what is independent mean?

1259
01:12:30.200 --> 01:12:32.400
So let's talk about dependence and Independence.

1260
01:12:33.500 --> 01:12:35.500
dependence and Independence

1261
01:12:37.800 --> 01:12:40.700
so I'm going to give you the formal definition but

1262
01:12:41.800 --> 01:12:44.300
its I think more

1263
01:12:44.300 --> 01:12:45.300
 helpful to see it visually.

1264
01:12:47.300 --> 01:12:50.900
So for two vectors to be dependent or linear

1265
01:12:50.900 --> 01:12:51.100
 dependent.

1266
01:12:52.600 --> 01:12:54.100
Is for this condition to hold?

1267
01:13:01.500 --> 01:13:02.600
by the way, I also going to

1268
01:13:04.600 --> 01:13:06.400
cite every example

1269
01:13:07.800 --> 01:13:09.300
I have created a list.

1270
01:13:10.400 --> 01:13:11.600
Of books I've used.

1271
01:13:12.700 --> 01:13:15.200
For this entire course, I think

1272
01:13:15.200 --> 01:13:15.900
 they will add up to.

1273
01:13:18.400 --> 01:13:20.900
Maybe six seven books up to this point. It's like six books.

1274
01:13:21.700 --> 01:13:24.500
I will list them in here. So there will be another file called references

1275
01:13:24.500 --> 01:13:26.200
 when you see something like five.

1276
01:13:28.900 --> 01:13:31.600
You will know which book from which

1277
01:13:31.600 --> 01:13:33.000
 book this has been borrowed.

1278
01:13:36.500 --> 01:13:37.300
This is from the

1279
01:13:39.400 --> 01:13:42.700
Outlines book I don't remember which page this is but I will I will

1280
01:13:42.700 --> 01:13:45.200
 also indicate the page where you

1281
01:13:45.200 --> 01:13:46.000
 can find this example anyway.

1282
01:13:47.300 --> 01:13:48.300
for a

1283
01:13:51.400 --> 01:13:51.800
set

1284
01:13:52.900 --> 01:13:55.800
to have vectors that are linearly dependent.

1285
01:13:57.100 --> 01:14:00.500
Is that you have these scalar values

1286
01:14:00.500 --> 01:14:02.700
 a sub one is up to a sub 3?

1287
01:14:04.300 --> 01:14:06.000
If you were to multiply these scalars.

1288
01:14:07.100 --> 01:14:08.100
by these vectors

1289
01:14:10.100 --> 01:14:13.100
and the scalars do not necessarily have to

1290
01:14:13.100 --> 01:14:13.500
 be zero.

1291
01:14:14.300 --> 01:14:17.700
You will have zero. So let me show you an example of an

1292
01:14:17.700 --> 01:14:20.200
 actual example, of course Independence is when this is not true.

1293
01:14:24.200 --> 01:14:24.500
so

1294
01:14:28.100 --> 01:14:30.200
let me give you an example. So the example I have is.

1295
01:14:40.500 --> 01:14:41.300
I'll tell you what the examples.

1296
01:14:50.000 --> 01:14:50.700
page

1297
01:14:58.400 --> 01:14:59.200
97

1298
01:15:12.700 --> 01:15:14.300
so let's consider a

1299
01:15:23.200 --> 01:15:24.000
example of

1300
01:15:28.600 --> 01:15:30.600
a set whose vectors are dependent

1301
01:15:31.800 --> 01:15:34.000
Basis they must be independent, but let me show you

1302
01:15:34.100 --> 01:15:37.100
 what it means to be dependent and then you will know what it is what it means

1303
01:15:37.100 --> 01:15:37.700
 to be independent.

1304
01:15:38.500 --> 01:15:41.500
So an example under this topic

1305
01:15:41.500 --> 01:15:42.300
 under this section.

1306
01:15:45.400 --> 01:15:46.900
And I will show you in python as well.

1307
01:15:48.600 --> 01:15:48.900
example one

1308
01:15:50.400 --> 01:15:51.600
say we have a set.

1309
01:15:54.600 --> 01:15:56.000
Whose vectors are all?

1310
01:15:56.600 --> 01:15:57.600
over R3

1311
01:16:00.900 --> 01:16:03.100
we have a set. Let's call it B.

1312
01:16:08.800 --> 01:16:11.100
And let me copy The Matrix snippet from

1313
01:16:11.100 --> 01:16:11.700
 the other file.

1314
01:16:16.300 --> 01:16:18.100
And this Matrix?

1315
01:16:20.200 --> 01:16:20.600
and

1316
01:16:23.700 --> 01:16:26.400
three vectors, so it's columns are vectors.

1317
01:16:28.200 --> 01:16:30.900
And the values are as follows. I will.

1318
01:16:32.400 --> 01:16:33.000
type in

1319
01:16:38.400 --> 01:16:38.900
one one

1320
01:16:41.200 --> 01:16:41.500
two

1321
01:16:45.400 --> 01:16:46.200
one one two

1322
01:16:49.900 --> 01:16:52.100
Or let me use this other one. It's easier zero one two.

1323
01:16:56.300 --> 01:16:57.800
0 1 2 0 1 2

1324
01:17:04.700 --> 01:17:05.000
okay.

1325
01:17:10.700 --> 01:17:13.200
So B if I can

1326
01:17:13.200 --> 01:17:15.400
 express it in a different way is actually a set.

1327
01:17:17.900 --> 01:17:20.100
Remember because matrices are sets. Yes.

1328
01:17:20.100 --> 01:17:24.000
 We just use square brackets.

1329
01:17:27.100 --> 01:17:29.400
For convenience, but this is actually a set.

1330
01:17:30.100 --> 01:17:32.900
Another way to express it is as V1.

1331
01:17:45.900 --> 01:17:48.400
Okay, this is V1. This is

1332
01:17:48.400 --> 01:17:50.200
 V2. This is V3.

1333
01:17:52.400 --> 01:17:55.600
Now you want to see if if these vectors are dependent or

1334
01:17:55.600 --> 01:17:55.800
 not.

1335
01:17:57.700 --> 01:18:00.700
If they are dependent there exists scalar

1336
01:18:00.700 --> 01:18:01.100
 values.

1337
01:18:04.600 --> 01:18:07.300
That will help make this condition that will make this equation

1338
01:18:07.300 --> 01:18:08.100
 be true.

1339
01:18:08.800 --> 01:18:10.700
Let me go to numpy to recreate this.

1340
01:18:11.500 --> 01:18:14.100
A call after you recreate this example.

1341
01:18:15.700 --> 01:18:18.100
So according to my example here from this book.

1342
01:18:19.100 --> 01:18:21.600
These vectors are dependent because there exists.

1343
01:18:24.200 --> 01:18:25.200
three scalar volumes

1344
01:18:26.200 --> 01:18:28.900
and the values are one zero.

1345
01:18:29.700 --> 01:18:32.800
0 so in this example if we

1346
01:18:32.800 --> 01:18:35.100
 plug in y a one for a sub 1

1347
01:18:35.600 --> 01:18:38.900
0 for a sub two zero for a sub 3 then

1348
01:18:38.900 --> 01:18:41.900
 this expression will be equal to zero and

1349
01:18:41.900 --> 01:18:42.600
 that is how we know that this

1350
01:18:43.800 --> 01:18:44.900
set B

1351
01:18:46.300 --> 01:18:49.000
is not a basis because it's vectors are dependent on each other.

1352
01:18:50.600 --> 01:18:52.700
Let me show you in Python.

1353
01:18:54.100 --> 01:18:55.500
And then I'll give you a pictorial.

1354
01:18:57.400 --> 01:19:00.100
Illustration so you know, why does what is actually

1355
01:19:00.100 --> 01:19:01.900
 mean? So what's this? Why is this useful?

1356
01:19:04.200 --> 01:19:05.400
So I'm going to go to collab.

1357
01:19:08.400 --> 01:19:11.100
And I will create a new notebook.

1358
01:19:15.100 --> 01:19:17.500
Are we really we just need no pie for this example?

1359
01:19:19.900 --> 01:19:22.000
import numpy as NP

1360
01:19:22.700 --> 01:19:23.900
so we have three vectors. Yes.

1361
01:19:26.300 --> 01:19:29.100
The vectors are okay. There is V sub

1362
01:19:29.100 --> 01:19:29.300
 1

1363
01:19:30.100 --> 01:19:31.400
NP dot array

1364
01:19:32.700 --> 01:19:35.500
the values zero zero zero

1365
01:19:37.300 --> 01:19:38.500
This one will be one.

1366
01:19:41.100 --> 01:19:42.600
And this will be all two.

1367
01:19:48.500 --> 01:19:50.500
Okay, the coefficients.

1368
01:19:53.400 --> 01:19:53.700
and that

1369
01:19:54.900 --> 01:19:57.300
linear combination by the way, this is a linear

1370
01:19:57.300 --> 01:19:58.200
 company, make sure

1371
01:19:58.900 --> 01:20:02.200
When you add these killers in the vectors and add these products,

1372
01:20:01.200 --> 01:20:03.600
 that's a linear combination.

1373
01:20:06.300 --> 01:20:08.800
so the skill is for the linear combination are

1374
01:20:11.600 --> 01:20:12.900
1 0 1 0

1375
01:20:13.700 --> 01:20:16.600
So the original equation or the equation?

1376
01:20:17.700 --> 01:20:21.500
or which we must plug in values are a sub

1377
01:20:21.500 --> 01:20:21.700
 1

1378
01:20:23.800 --> 01:20:25.400
times V sub 1

1379
01:20:27.900 --> 01:20:29.100
and we do this for all the other.

1380
01:20:31.700 --> 01:20:32.000
factors

1381
01:20:36.700 --> 01:20:39.400
If this equation equals 0 then we

1382
01:20:39.400 --> 01:20:41.400
 we have linear dependence.

1383
01:20:43.300 --> 01:20:46.300
so a Subs what one is zero as

1384
01:20:46.300 --> 01:20:49.100
 one a sub 2 is 0

1385
01:20:51.200 --> 01:20:51.700
and

1386
01:20:52.700 --> 01:20:53.700
So is a sub 3?

1387
01:20:56.400 --> 01:20:57.100
I run this.

1388
01:21:09.900 --> 01:21:12.400
I think we'll get a vector whose values

1389
01:21:12.400 --> 01:21:13.700
 are three, but that's just the nature of

1390
01:21:14.500 --> 01:21:15.700
numpy

1391
01:21:17.400 --> 01:21:20.000
But what we should have gotten is a maybe there's a method for

1392
01:21:20.200 --> 01:21:22.800
 this but we would have gotten a scalar value. Who's

1393
01:21:24.600 --> 01:21:25.800
Could be that would be zero.

1394
01:21:28.300 --> 01:21:28.600
for

1395
01:21:29.800 --> 01:21:30.700
these vectors

1396
01:21:32.400 --> 01:21:35.600
All right. Yeah for these vectors now these vectors must be in

1397
01:21:35.600 --> 01:21:39.400
 the same Subspace. They must be the same subsets or

1398
01:21:39.400 --> 01:21:40.200
 be the subset, right?

1399
01:21:40.900 --> 01:21:42.900
B is a subset of which

1400
01:21:45.600 --> 01:21:47.600
Set it is a subset.

1401
01:21:48.600 --> 01:21:49.500
of our

1402
01:21:51.700 --> 01:21:52.800
to the power 3

1403
01:21:58.800 --> 01:21:59.000
Okay.

1404
01:22:00.600 --> 01:22:00.700
so

1405
01:22:02.300 --> 01:22:03.800
dependence and Independence

1406
01:22:06.400 --> 01:22:09.600
only apply to this subset or Subspace

1407
01:22:09.600 --> 01:22:11.000
 if you want to use linear algebra terminology.

1408
01:22:12.500 --> 01:22:15.700
So if there exists any three scalars

1409
01:22:15.700 --> 01:22:18.200
 or any end scalars that would result

1410
01:22:18.200 --> 01:22:20.800
 in such an equation then we have dependence.

1411
01:22:22.600 --> 01:22:25.300
Assuming they're not all zero if they're also really will obviously

1412
01:22:25.300 --> 01:22:25.800
 be zero.

1413
01:22:26.800 --> 01:22:29.000
Okay. So linear Independence is the opposite of

1414
01:22:29.300 --> 01:22:29.800
 what we have just seen.

1415
01:22:31.800 --> 01:22:32.800
Now pick thoroughly.

1416
01:22:33.900 --> 01:22:36.300
Let me see if I can show you a picture. If not,

1417
01:22:36.300 --> 01:22:37.600
 I'll draw it for you. It's very easy to do.

1418
01:22:38.500 --> 01:22:39.300
linear

1419
01:22:40.400 --> 01:22:41.200
dependence

1420
01:22:42.700 --> 01:22:43.900
versus Independence

1421
01:22:46.400 --> 01:22:47.100
vectors

1422
01:22:48.400 --> 01:22:51.500
You know Google can be really let down sometimes.

1423
01:22:54.700 --> 01:22:55.900
Yeah, here we go.

1424
01:22:58.300 --> 01:22:59.500
Let me keep this here.

1425
01:23:07.400 --> 01:23:08.500
I'm not so sure about that.

1426
01:23:09.500 --> 01:23:12.300
And let's see if there's

1427
01:23:12.300 --> 01:23:12.900
 another one.

1428
01:23:26.700 --> 01:23:27.900
Just two dimensions.

1429
01:23:30.100 --> 01:23:30.800
Yes.

1430
01:23:32.200 --> 01:23:32.700
Here we go.

1431
01:23:35.700 --> 01:23:38.000
And can I give you a third one?

1432
01:23:44.400 --> 01:23:45.700
Let's take you to dimensions.

1433
01:23:46.300 --> 01:23:47.200
these two vectors

1434
01:23:48.900 --> 01:23:50.300
are dependent imagine.

1435
01:23:51.200 --> 01:23:51.400
that

1436
01:23:52.600 --> 01:23:55.500
the on the right hand side. We have one two-dimensional.

1437
01:23:56.300 --> 01:23:59.200
Cartesian coordinate and the other on the left. You also

1438
01:23:59.200 --> 01:24:01.100
 have a Cartesian coordinate.

1439
01:24:03.500 --> 01:24:05.000
this is dependent why because

1440
01:24:05.800 --> 01:24:06.800
these two vectors

1441
01:24:09.900 --> 01:24:13.100
are are on one dimension despite this

1442
01:24:12.100 --> 01:24:15.600
 being a two-dimensional plane.

1443
01:24:16.600 --> 01:24:19.300
When you put them together, let's say I think this Edition when

1444
01:24:19.300 --> 01:24:21.900
 you add them together, they both fought on the same.

1445
01:24:23.400 --> 01:24:24.000
axis

1446
01:24:26.100 --> 01:24:29.500
What I'm trying to say is they don't form you cannot for example form.

1447
01:24:30.500 --> 01:24:32.200
a plane

1448
01:24:34.200 --> 01:24:37.200
The Plainfield a plane is for two Dimensions, right? You could not

1449
01:24:37.200 --> 01:24:39.900
 form a plane with these two vectors. They are dependent on each other.

1450
01:24:41.400 --> 01:24:43.700
With this one you could form a plane.

1451
01:24:45.300 --> 01:24:47.000
so if your basis

1452
01:24:48.600 --> 01:24:49.200
contains vectors

1453
01:24:50.300 --> 01:24:53.200
Over r squared so all that's all the

1454
01:24:53.200 --> 01:24:56.400
 all the vectors are two dimensional. So B is

1455
01:24:56.400 --> 01:24:57.500
 two dimensional e is the dimensional

1456
01:24:58.100 --> 01:24:59.900
And when you plot them.

1457
01:25:00.600 --> 01:25:01.300
They both.

1458
01:25:02.300 --> 01:25:03.900
With both they could produce a plane.

1459
01:25:04.600 --> 01:25:05.700
Then they are independent.

1460
01:25:06.600 --> 01:25:07.500
the third example

1461
01:25:09.100 --> 01:25:10.700
where they will go into three directions

1462
01:25:12.200 --> 01:25:12.500
so if we have

1463
01:25:15.800 --> 01:25:16.100
a

1464
01:25:17.400 --> 01:25:19.400
basis with three vectors

1465
01:25:21.200 --> 01:25:22.200
and the exceed

1466
01:25:23.400 --> 01:25:25.500
or fall below the number of dimensions of that.

1467
01:25:26.700 --> 01:25:29.700
Set that basis. Well that said

1468
01:25:29.700 --> 01:25:30.800
 then they will not form a basis.

1469
01:25:31.600 --> 01:25:34.200
Okay. Hope that makes sense. But if it doesn't

1470
01:25:34.200 --> 01:25:37.400
 let me just let's just keep this simple example. This is

1471
01:25:37.400 --> 01:25:41.600
 the this is dependent because they both

1472
01:25:41.600 --> 01:25:42.600
 are on top of each other.

1473
01:25:43.400 --> 01:25:44.500
This one is independent.

1474
01:25:45.900 --> 01:25:48.500
Now this is not to be confused with orthogonal vectors

1475
01:25:48.500 --> 01:25:51.200
 for two vectors to be orthogonal. They must

1476
01:25:51.200 --> 01:25:51.300
 form.

1477
01:25:51.800 --> 01:25:52.900
an 90 degree angle

1478
01:25:53.800 --> 01:25:54.700
That's a separate thing.

1479
01:25:56.100 --> 01:25:56.400
Okay.

1480
01:25:58.400 --> 01:26:01.600
That's what a basis is. Hope that's simple enough.

1481
01:26:05.600 --> 01:26:08.600
Now let me return here. So we talked about bases. So

1482
01:26:08.600 --> 01:26:11.100
 we said what a span is. So span is when you

1483
01:26:11.100 --> 01:26:13.200
 have a set or all the vectors are in the same.

1484
01:26:15.200 --> 01:26:16.100
or of the same

1485
01:26:17.100 --> 01:26:17.600
dimension

1486
01:26:18.400 --> 01:26:21.200
and linear Independence is where there exists

1487
01:26:21.200 --> 01:26:21.900
 no coefficient.

1488
01:26:23.300 --> 01:26:25.700
That would make with which you could produce a third.

1489
01:26:28.400 --> 01:26:29.400
Vector so for example

1490
01:26:30.900 --> 01:26:31.900
Let me show you one more.

1491
01:26:35.400 --> 01:26:36.800
Say we have another bacteria with.

1492
01:26:39.500 --> 01:26:39.900
one

1493
01:26:41.600 --> 01:26:42.300
one two

1494
01:26:45.100 --> 01:26:45.600
one one

1495
01:26:48.600 --> 01:26:49.100
one

1496
01:26:50.500 --> 01:26:51.300
two two one

1497
01:26:51.900 --> 01:26:54.400
You see with these three vectors, for example, you

1498
01:26:54.400 --> 01:26:56.900
 can add these two together given some coefficients.

1499
01:26:57.700 --> 01:26:58.800
To get this third one.

1500
01:26:59.600 --> 01:27:02.900
Or it could take this third Vector multiplied

1501
01:27:02.900 --> 01:27:05.500
 by some scalar multiplied by some coefficient and

1502
01:27:05.500 --> 01:27:08.500
 this Vector multiply by some coefficient to get that one.

1503
01:27:09.900 --> 01:27:11.000
Or it could take these two.

1504
01:27:12.100 --> 01:27:15.500
Multiply them to together by two separate coefficients to

1505
01:27:15.500 --> 01:27:18.100
 get that Vector. This is what it means to be linear dependent.

1506
01:27:20.100 --> 01:27:22.600
So you can use two vectors to create a third vector.

1507
01:27:24.900 --> 01:27:28.300
For this set to be linearly independent.

1508
01:27:27.300 --> 01:27:29.800
 That means you could not lose your thing.

1509
01:27:31.200 --> 01:27:34.100
No matter how you add or multiply two vectors. There's no way you could

1510
01:27:34.100 --> 01:27:34.800
 get the third vector.

1511
01:27:38.700 --> 01:27:41.900
this concept of the basis is yet

1512
01:27:41.900 --> 01:27:42.900
 another prerequisite for

1513
01:27:44.700 --> 01:27:46.100
singular validity composition

1514
01:27:48.300 --> 01:27:52.300
You have two more minutes. Let me see if I can leave with anything else orthogonal orthon,

1515
01:27:51.300 --> 01:27:54.200
 or okay orthogonal. Let

1516
01:27:54.200 --> 01:27:55.600
 me see if I have comments in here from

1517
01:27:57.900 --> 01:27:59.000
four or thought

1518
01:27:59.300 --> 01:27:59.500
here

1519
01:28:00.900 --> 01:28:01.500
here, baby

1520
01:28:08.400 --> 01:28:10.300
Okay, there's only two minutes left. Maybe let's Wikipedia.

1521
01:28:11.600 --> 01:28:12.600
This is like a Gamble.

1522
01:28:13.200 --> 01:28:17.600
Either we get a good definition or not also normal.

1523
01:28:21.600 --> 01:28:22.200
Matrix

1524
01:28:31.800 --> 01:28:34.200
well, let's actually do it make it pictures right

1525
01:28:34.200 --> 01:28:35.700
 also normal vector.

1526
01:28:37.300 --> 01:28:41.600
Yes, so in an orthonormal Matrix they are

1527
01:28:41.600 --> 01:28:44.400
 well, they are let me tell you the conditions. First of all, they

1528
01:28:44.400 --> 01:28:46.600
 have unit vectors, which means they

1529
01:28:48.200 --> 01:28:50.700
well, the length is 1

1530
01:28:52.100 --> 01:28:53.600
so that's what unit Vector is.

1531
01:28:54.200 --> 01:28:57.600
And they are also orthogonal. So

1532
01:28:57.600 --> 01:28:58.100
 if you remember the

1533
01:29:03.400 --> 01:29:06.000
the example with the plotting of the vectors.

1534
01:29:06.800 --> 01:29:09.700
And where we used when we

1535
01:29:09.700 --> 01:29:12.600
 converted from polar coordinate to Cartesian coordinate.

1536
01:29:13.100 --> 01:29:17.000
perpendicularity, basically, yes, if two vectors if the

1537
01:29:16.400 --> 01:29:19.300
 vectors in this Matrix

1538
01:29:19.300 --> 01:29:21.100
 become orthogonal

1539
01:29:22.400 --> 01:29:25.900
And they are unit vectors. That's an orthonormal basis. That's normal

1540
01:29:25.900 --> 01:29:28.200
 orthonormal Matrix. So for

1541
01:29:28.200 --> 01:29:31.900
 example, if you have a matrix whose vectors look

1542
01:29:31.900 --> 01:29:32.900
 like that.

1543
01:29:33.900 --> 01:29:36.500
their orthography the former 90 degree angle

1544
01:29:37.100 --> 01:29:39.200
And they are the unit.

1545
01:29:40.800 --> 01:29:43.800
They are unit vectors. This is now so this

1546
01:29:43.800 --> 01:29:46.500
 is the Matrix with oh with orthonormal vectors.

1547
01:29:48.500 --> 01:29:51.200
And an orthogonal Matrix if we

1548
01:29:51.200 --> 01:29:52.300
 go back to Wikipedia.

1549
01:30:01.400 --> 01:30:02.700
Wait a minute. Are they synonyms?

1550
01:30:09.300 --> 01:30:10.300
Am I forgetting or?

1551
01:30:15.200 --> 01:30:16.200
They have a different meaning.

1552
01:30:18.100 --> 01:30:21.000
So apparently if we look at this PDF.

1553
01:30:22.400 --> 01:30:23.800
They seem to be synonyms.

1554
01:30:24.700 --> 01:30:26.400
And Wikipedia says they're synonyms.

1555
01:30:27.600 --> 01:30:28.700
I guess then the synonyms.

1556
01:30:30.300 --> 01:30:31.900
So I'm just going to put this in parentheses.

1557
01:30:33.800 --> 01:30:34.000
Okay.

1558
01:30:35.600 --> 01:30:35.800
so

1559
01:30:37.700 --> 01:30:40.300
Now that we've covered these Concepts. I hope

1560
01:30:40.300 --> 01:30:41.300
 we can on Friday.

1561
01:30:42.300 --> 01:30:45.200
Use these words without having to explain them any

1562
01:30:45.200 --> 01:30:45.300
 further.

1563
01:30:46.300 --> 01:30:47.800
Now I did promise to make.

1564
01:30:49.500 --> 01:30:52.300
The notes and iPad embarked and

1565
01:30:52.300 --> 01:30:52.800
 file I will.

1566
01:30:54.600 --> 01:30:57.100
But yeah, hopefully come Friday

1567
01:30:57.100 --> 01:31:00.100
 we can just jump right into as feet. We can

1568
01:31:00.100 --> 01:31:03.900
 jump right at SVD and then we would like a few steps away from PCA. So

1569
01:31:03.900 --> 01:31:06.400
 we covered the prerequisites or rather.

1570
01:31:06.400 --> 01:31:10.200
 We briefly talked about the motivating reason for want

1571
01:31:09.200 --> 01:31:11.100
 to talk about PCA.

1572
01:31:15.100 --> 01:31:19.500
Tomorrow I'll on Friday. I will give you a the mathematical.

1573
01:31:21.600 --> 01:31:22.200
example

1574
01:31:23.500 --> 01:31:26.000
but next week we will jump into.

1575
01:31:28.200 --> 01:31:29.700
the programming implementation so

1576
01:31:31.200 --> 01:31:34.000
we will use a library called psychic learn.

1577
01:31:35.800 --> 01:31:38.100
So a scaler numpy pandas together.

1578
01:31:39.400 --> 01:31:40.200
matplotlib

1579
01:31:40.900 --> 01:31:41.400
and then

1580
01:31:43.400 --> 01:31:46.200
the session that follows will get an attention flow because I

1581
01:31:46.200 --> 01:31:48.300
 think now we're getting like we're almost

1582
01:31:49.300 --> 01:31:50.300
there with all the

1583
01:31:51.800 --> 01:31:53.100
prerequisite knowledge

1584
01:31:54.800 --> 01:31:55.400
Okay, everyone.

1585
01:31:56.500 --> 01:31:57.600
Thank you very much for joining me.

1586
01:31:59.700 --> 01:32:02.400
And enjoy the rest of your day, and I'll see you on Friday

1587
01:32:02.400 --> 01:32:03.500
 for now. Take care. Bye.
