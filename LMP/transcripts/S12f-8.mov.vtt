WEBVTT - This file was automatically generated by VIMEO

0
00:00:01.500 --> 00:00:04.200
Now before I take the sigma, let me

1
00:00:04.200 --> 00:00:07.100
 actually take it the playground playground that tensorflow so you can

2
00:00:07.100 --> 00:00:08.900
 see why you would use other activation functions.

3
00:00:11.500 --> 00:00:13.400
Let me tell you what we were why we're looking at here.

4
00:00:18.700 --> 00:00:20.000
First this is the neural network.

5
00:00:22.500 --> 00:00:23.400
this entire section

6
00:00:25.900 --> 00:00:28.200
you have your features your input Dimensions if

7
00:00:28.200 --> 00:00:29.600
 we use tensorflow terminology.

8
00:00:32.500 --> 00:00:33.600
your hidden layers

9
00:00:35.700 --> 00:00:35.900
now

10
00:00:36.900 --> 00:00:40.200
there is no hard rule or formula

11
00:00:39.200 --> 00:00:42.400
 for choosing the number of hidden layers.

12
00:00:43.600 --> 00:00:45.200
but for most problems

13
00:00:45.900 --> 00:00:48.000
two hidden layers is sufficient.

14
00:00:48.900 --> 00:00:49.800
for most problems

15
00:00:51.400 --> 00:00:54.900
or at least numerical problems data, that

16
00:00:54.900 --> 00:00:55.600
 is numerical and

17
00:00:56.400 --> 00:00:57.600
Like if you're doing regression.

18
00:00:58.800 --> 00:01:01.200
for that so for majority of problems, this is this is

19
00:01:01.200 --> 00:01:04.600
 this architecture's sufficient for things like pictures and

20
00:01:07.100 --> 00:01:10.300
sound bites or text. No you do

21
00:01:10.300 --> 00:01:13.800
 you definitely more elaborate neural network, and

22
00:01:13.800 --> 00:01:14.800
 then you have the alpha layer.

23
00:01:17.500 --> 00:01:20.000
So this entire thing is your neural network?

24
00:01:22.700 --> 00:01:23.600
Then up here we have.

25
00:01:24.600 --> 00:01:26.300
the hyper parameters

26
00:01:27.700 --> 00:01:30.700
Remember, we should hyper parameters are synonymous with

27
00:01:30.700 --> 00:01:32.000
 the configuration of the new network.

28
00:01:33.800 --> 00:01:35.500
This will allow you to run this for.

29
00:01:36.500 --> 00:01:40.200
different number of epoch so you can keep feeding your data

30
00:01:39.200 --> 00:01:40.700
 to the network to see

31
00:01:41.900 --> 00:01:42.800
and how it's doing.

32
00:01:44.800 --> 00:01:47.300
And then you have these hyper parameters, which allow you

33
00:01:47.300 --> 00:01:47.700
 to control.

34
00:01:48.800 --> 00:01:51.500
how the model learned and

35
00:01:51.500 --> 00:01:52.700
 how to control it

36
00:01:53.400 --> 00:01:54.400
s the overfitting

37
00:01:55.400 --> 00:01:57.300
so we have we can choose the learning rate.

38
00:01:58.900 --> 00:02:00.000
the regularization function

39
00:02:01.600 --> 00:02:03.500
the regularization rate

40
00:02:05.900 --> 00:02:06.300
and then here

41
00:02:08.000 --> 00:02:08.200
to

42
00:02:09.700 --> 00:02:10.500
illustrate

43
00:02:11.300 --> 00:02:13.200
how effective and neural network is

44
00:02:14.900 --> 00:02:17.600
They have chosen some very unusual.

45
00:02:19.400 --> 00:02:22.500
Shapes of data. I mean, this is look at this look at what's

46
00:02:22.500 --> 00:02:23.000
 going on here.

47
00:02:24.100 --> 00:02:27.700
This is supposed to be like a scatter plot. We have two types

48
00:02:27.700 --> 00:02:30.000
 of data two data classes.

49
00:02:30.500 --> 00:02:32.400
The blue one is centered.

50
00:02:33.300 --> 00:02:36.300
In the middle and the second class is surround again,

51
00:02:36.300 --> 00:02:39.900
 you're unlikely to see something like this in the real

52
00:02:39.900 --> 00:02:42.100
 world. This is supposed to be like a extreme example.

53
00:02:43.100 --> 00:02:46.400
The point of this demonstration show you how a new network is still

54
00:02:46.400 --> 00:02:47.300
 able to classify.

55
00:02:49.800 --> 00:02:50.100
the

56
00:02:51.500 --> 00:02:53.100
two classes in the data set

57
00:02:53.700 --> 00:02:54.400
Here's another one.

58
00:02:56.100 --> 00:02:57.600
Here's another one. This is easier.

59
00:02:58.400 --> 00:03:00.300
And there's another one. Yeah, I mean, this is look at this. This is

60
00:03:03.600 --> 00:03:05.100
the point that what now?

61
00:03:06.600 --> 00:03:09.700
I have to play around with this, but we can use a

62
00:03:09.700 --> 00:03:10.400
 Samuel law work.

63
00:03:11.100 --> 00:03:13.300
to completely separate

64
00:03:14.400 --> 00:03:14.800
these

65
00:03:15.800 --> 00:03:16.500
observations

66
00:03:19.600 --> 00:03:20.500
now, how do we

67
00:03:23.300 --> 00:03:23.800
separate

68
00:03:28.500 --> 00:03:30.200
we need to talk about regression for a moment.

69
00:03:32.200 --> 00:03:35.200
If I come back to this slide if I go all the way to

70
00:03:35.200 --> 00:03:36.100
 up here.

71
00:03:37.100 --> 00:03:40.600
This is supposed to be a picture that illustrates the application

72
00:03:40.600 --> 00:03:43.700
 of the general regression model regression is

73
00:03:43.700 --> 00:03:44.400
 used for.

74
00:03:50.400 --> 00:03:52.700
modeling the direction of a data

75
00:03:53.600 --> 00:03:55.100
and that's how you forecast. That's

76
00:03:57.600 --> 00:04:00.300
an application of forecasting or others known

77
00:04:00.300 --> 00:04:02.400
 as a regress. It's called regression because

78
00:04:04.300 --> 00:04:04.600
in a

79
00:04:05.900 --> 00:04:09.600
forecasting model the observations should

80
00:04:08.600 --> 00:04:11.900
 regress towards this

81
00:04:11.900 --> 00:04:12.500
 line.

82
00:04:18.500 --> 00:04:21.400
A regression model this is obviously not linear because well

83
00:04:21.400 --> 00:04:24.300
 it's curved can also be used to separate the data.

84
00:04:25.500 --> 00:04:28.300
into two groups if in the case of a binary

85
00:04:28.300 --> 00:04:28.800
 classification

86
00:04:30.500 --> 00:04:32.600
So this would be a polynomial model.

87
00:04:34.200 --> 00:04:37.600
And the idea is to draw the boundaries or to

88
00:04:37.600 --> 00:04:38.300
 draw boundary.

89
00:04:39.600 --> 00:04:42.100
Or rather model the boundary of the data set.

90
00:04:44.700 --> 00:04:47.000
Of course, it won't be perfect. So yeah, I hope you can see

91
00:04:47.200 --> 00:04:50.200
 on my screen. We have some light green observations some like green data points.

92
00:04:50.800 --> 00:04:52.000
in the second cluster

93
00:04:52.800 --> 00:04:54.000
Conversely we have some of these.

94
00:04:54.700 --> 00:04:57.400
Dark, green or turquoise if you like to call it in the

95
00:04:57.400 --> 00:04:57.900
 first cluster.

96
00:04:58.400 --> 00:05:01.200
But the majority have are well partitioned.

97
00:05:03.000 --> 00:05:03.100
now

98
00:05:08.100 --> 00:05:11.700
here's another reason why you can never want to use a linear model for classification

99
00:05:11.700 --> 00:05:14.100
 because it's linear. It's a single

100
00:05:14.100 --> 00:05:15.900
 line. You cannot use a single line.

101
00:05:16.900 --> 00:05:19.400
To partition a sea of data points

102
00:05:19.400 --> 00:05:22.700
 like the one you see here, like imagine if this were a straight line you could

103
00:05:22.700 --> 00:05:23.700
 not clearly.

104
00:05:26.000 --> 00:05:26.700
delineate

105
00:05:28.700 --> 00:05:29.300
this section

106
00:05:33.900 --> 00:05:37.000
you can't also do this with our value

107
00:05:36.200 --> 00:05:37.500
 model either.

108
00:05:40.200 --> 00:05:41.200
Unless of course.

109
00:05:44.200 --> 00:05:47.200
You use multiple ready models. Let me let me demonstrate.

110
00:05:49.600 --> 00:05:51.500
I'm going to return to the

111
00:05:53.600 --> 00:05:54.600
first example

112
00:05:57.200 --> 00:05:59.300
I will not change the hyper parameters.

113
00:06:01.800 --> 00:06:04.200
And I will not change the neural network. I will

114
00:06:04.200 --> 00:06:05.100
 not change the configuration.

115
00:06:06.200 --> 00:06:07.000
I'm gonna have to play.

116
00:06:08.300 --> 00:06:09.100
and what I want you to look at

117
00:06:10.300 --> 00:06:10.700
is

118
00:06:12.200 --> 00:06:13.200
the animation in here

119
00:06:16.200 --> 00:06:19.600
now what you're going to see is this epox are quickly going to increment.

120
00:06:21.200 --> 00:06:22.300
like some sort of

121
00:06:23.200 --> 00:06:24.000
time-lap

122
00:06:27.500 --> 00:06:30.400
And with each Epoch another thing you will see here is that

123
00:06:30.400 --> 00:06:31.400
 is the loss?

124
00:06:32.800 --> 00:06:35.300
And we probably care for the loss. We want

125
00:06:35.300 --> 00:06:38.300
 this to converge to zero and it will be animated here. So

126
00:06:38.300 --> 00:06:41.000
 if I hit let's let's watch what happens. Okay, so you want to watch

127
00:06:41.700 --> 00:06:44.100
you want to watch this and you want

128
00:06:44.100 --> 00:06:45.500
 to watch this space over here?

129
00:06:48.300 --> 00:06:50.700
and we want to see if we're able to use for

130
00:06:52.100 --> 00:06:53.400
really U models

131
00:06:54.100 --> 00:06:55.000
not linear

132
00:06:56.400 --> 00:06:59.300
not polynomial. We want to see if we can use that

133
00:06:59.300 --> 00:07:01.700
 rally that L looking model four of them.

134
00:07:02.300 --> 00:07:03.100
to delineate

135
00:07:04.500 --> 00:07:07.400
the boundaries of these two classes ready

136
00:07:07.400 --> 00:07:08.400
 one, two three

137
00:07:10.500 --> 00:07:13.400
All right. Look at the last function is already converging to zero you

138
00:07:13.400 --> 00:07:14.400
 see how it has climbed down.

139
00:07:15.800 --> 00:07:18.100
It is getting closer and closer to zero. We

140
00:07:18.100 --> 00:07:21.800
 are not at how many epochs 100 200 I'm

141
00:07:21.800 --> 00:07:24.500
 gonna hit pause 236 epochs

142
00:07:24.500 --> 00:07:25.500
 watch what has happened.

143
00:07:27.800 --> 00:07:29.400
You see these boundaries.

144
00:07:30.100 --> 00:07:31.900
These are formed by those four.

145
00:07:32.800 --> 00:07:34.000
value functions

146
00:07:38.200 --> 00:07:41.200
1 2 3 4 you can see here. We have formed the

147
00:07:41.200 --> 00:07:41.300
 first.

148
00:07:44.500 --> 00:07:46.100
Angle and this is the second angle.

149
00:07:46.900 --> 00:07:47.800
Put these together.

150
00:07:54.300 --> 00:07:54.900
and you're able to

151
00:07:55.900 --> 00:07:58.400
you know separate these two

152
00:07:58.400 --> 00:07:59.100
 clusters of data.

153
00:08:04.300 --> 00:08:07.300
Is it clear like has this example, have you understand what we're doing?

154
00:08:07.300 --> 00:08:10.500
 What if I had said? Okay, by the way, this is tan H.

155
00:08:10.500 --> 00:08:12.000
 I should have changed us to value.

156
00:08:12.900 --> 00:08:14.500
Let me set this to rally and try again.

157
00:08:16.500 --> 00:08:19.300
One two three, I'm gonna hit play so you can see it

158
00:08:19.300 --> 00:08:19.800
 still does a good job.

159
00:08:20.700 --> 00:08:22.300
Obviously the corners are sharper.

160
00:08:23.100 --> 00:08:24.000
But that's what really does.

161
00:08:25.400 --> 00:08:26.900
What if I would set this to linear?

162
00:08:28.200 --> 00:08:28.900
and hit play

163
00:08:32.300 --> 00:08:32.600
it's not able to.

164
00:08:34.100 --> 00:08:37.200
Because there's nothing linear about the pattern of this data.

165
00:08:39.700 --> 00:08:41.800
Let's try this other one.

166
00:08:42.600 --> 00:08:43.400
and I'm going to use

167
00:08:44.900 --> 00:08:47.000
A value again, and I'm going to hit play.

168
00:08:53.400 --> 00:08:56.300
And sometimes you actually have to restart this 4 to work properly. So I'm

169
00:08:56.300 --> 00:08:56.400
 going to

170
00:08:57.300 --> 00:08:58.600
hard refresh this

171
00:09:00.300 --> 00:09:00.900
Try again.

172
00:09:01.700 --> 00:09:02.100
There we go.

173
00:09:03.300 --> 00:09:05.500
You can clearly see the value right now.

174
00:09:14.100 --> 00:09:17.400
And for something like this, well, you need something that

175
00:09:17.400 --> 00:09:20.600
 is more curved like 10 age.

176
00:09:20.600 --> 00:09:21.900
 I hit play.

177
00:09:23.200 --> 00:09:24.800
This might take a while longer.

178
00:09:29.600 --> 00:09:30.500
so the loss is

179
00:09:32.400 --> 00:09:33.400
a climbing

180
00:09:35.300 --> 00:09:35.500
it's

181
00:09:37.200 --> 00:09:37.900
consistent

182
00:09:39.500 --> 00:09:41.500
I think I'm gonna have to a hard refresh.

183
00:09:42.400 --> 00:09:43.300
To run this again.

184
00:09:47.300 --> 00:09:49.600
So 10 age can hit play once more.

185
00:09:51.800 --> 00:09:54.000
I remember this example always takes a bit longer.

186
00:09:56.300 --> 00:09:59.400
But it is ultimately able to see you

187
00:09:59.400 --> 00:09:59.400
 know.

188
00:10:02.200 --> 00:10:02.500
separate

189
00:10:04.400 --> 00:10:06.000
these two classes

190
00:10:08.400 --> 00:10:11.600
Okay, look at the loss is is dropping. It's

191
00:10:11.600 --> 00:10:14.000
 getting closer and closer to zero very slowly, but it is

192
00:10:15.100 --> 00:10:15.900
still not good enough.

193
00:10:16.700 --> 00:10:18.800
That this let's let it run a little longer.

194
00:10:20.400 --> 00:10:23.000
It's 300. Is it going to go down to 200?

195
00:10:28.800 --> 00:10:30.600
Look at that. Look at that. Look at that.

196
00:10:32.300 --> 00:10:34.100
We're almost 1,000 epochs.

197
00:10:35.200 --> 00:10:35.500
and

198
00:10:36.800 --> 00:10:39.700
the test loss is kind of stuck at 300.

199
00:10:41.300 --> 00:10:44.500
So what we might have to do is play around

200
00:10:44.500 --> 00:10:46.100
 with these hyper parameters like

201
00:10:47.500 --> 00:10:48.600
change the regularization rate.

202
00:10:50.800 --> 00:10:52.500
Even just a bad size.

203
00:10:54.300 --> 00:10:57.100
But it's kind of oh look at that. Hold on.

204
00:10:57.100 --> 00:10:58.100
 Hold on what something's happening?

205
00:11:00.200 --> 00:11:02.600
It is it's dropping again. It's dropped some more.

206
00:11:04.100 --> 00:11:05.800
That's 1500 epochs.

207
00:11:07.500 --> 00:11:10.500
I'm gonna I don't know if I should keep running this.

208
00:11:13.800 --> 00:11:16.500
But it is it's done somewhat. Well, I mean the Tesla

209
00:11:16.500 --> 00:11:17.200
 is still not.

210
00:11:18.400 --> 00:11:20.900
Good enough if we wanted to get closer to zero.

211
00:11:21.900 --> 00:11:24.400
But clearly we want to use this activation function.

212
00:11:24.400 --> 00:11:26.300
 I think we had pause here.

213
00:11:27.100 --> 00:11:30.300
But yes had I played around with this

214
00:11:30.300 --> 00:11:33.400
 with the hyper parameters. I could have gotten

215
00:11:33.400 --> 00:11:34.000
 it to perfectly.

216
00:11:35.500 --> 00:11:38.500
You know separate the two classes.
