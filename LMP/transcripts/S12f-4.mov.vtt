WEBVTT - This file was automatically generated by VIMEO

0
00:00:00.100 --> 00:00:00.500
the

1
00:00:01.200 --> 00:00:03.300
two steps that we're not going to look at today are

2
00:00:04.200 --> 00:00:07.500
saving the weights of the model. So there are a few

3
00:00:07.500 --> 00:00:10.400
 file formats in which you could save the parameters of the model like

4
00:00:10.400 --> 00:00:12.800
 CSV. There's one called H5.

5
00:00:14.200 --> 00:00:17.100
And another thing we won't be looking at in this course is deploying the

6
00:00:17.100 --> 00:00:20.400
 machine learning model. So go to something like AWS or Google

7
00:00:20.400 --> 00:00:22.300
 cloud and deploying this.

8
00:00:24.400 --> 00:00:28.300
Depending on the model you or Library. I should say you may have

9
00:00:27.300 --> 00:00:28.500
 to

10
00:00:30.600 --> 00:00:33.300
going to something like compute engine

11
00:00:33.300 --> 00:00:33.800
 or

12
00:00:35.500 --> 00:00:38.600
An ec2 instance on AWS and then

13
00:00:38.600 --> 00:00:41.300
 you would need to use Docker to download the

14
00:00:41.300 --> 00:00:44.300
 image and create a container. So

15
00:00:44.300 --> 00:00:46.700
 it will go into more of envelopes.

16
00:00:47.300 --> 00:00:50.600
That's what it takes to deploy machine learning model. In other

17
00:00:50.600 --> 00:00:53.800
 cases if using Library like tensorflow on Google Cloud specifically

18
00:00:53.800 --> 00:00:56.600
 you can just upload the script and go Cloud

19
00:00:56.600 --> 00:00:57.200
 will take care of

20
00:00:58.500 --> 00:01:02.000
You know preparing the environment and by environment, I mean installing operating

21
00:01:01.100 --> 00:01:04.700
 system on the the hardware.

22
00:01:06.300 --> 00:01:09.900
Installing the right version of python installing the library dependencies.

23
00:01:09.900 --> 00:01:12.600
 Let's switch then now until this,

24
00:01:12.600 --> 00:01:13.900
 you know is cooking at the background.

25
00:01:14.700 --> 00:01:16.200
and talk about

26
00:01:17.100 --> 00:01:20.300
activation functions first let's talk about

27
00:01:21.400 --> 00:01:24.100
Revenue, and then let's talk about softmax. So this is

28
00:01:24.100 --> 00:01:25.900
 a very simple.

29
00:01:27.300 --> 00:01:28.200
neural network

30
00:01:30.800 --> 00:01:31.700
so this

31
00:01:36.900 --> 00:01:38.600
Is this line of code here?

32
00:01:49.400 --> 00:01:52.900
now, of course for the input, we don't have a tensor

33
00:01:52.900 --> 00:01:53.500
 the input for

34
00:01:54.700 --> 00:01:56.900
this network is only two features.

35
00:02:01.400 --> 00:02:04.600
And the dense is three so we have three outputs.

36
00:02:06.400 --> 00:02:09.700
Okay, let's see. Now. We said that neural network

37
00:02:09.700 --> 00:02:11.200
 are neural networks.

38
00:02:12.600 --> 00:02:14.400
Our matrices but this is a graphic.

39
00:02:16.300 --> 00:02:16.900
representation

40
00:02:19.500 --> 00:02:22.500
I also have a matrix representation up

41
00:02:22.500 --> 00:02:22.500
 here.

42
00:02:24.900 --> 00:02:27.600
Let me see if this one has the activation. This

43
00:02:27.600 --> 00:02:28.900
 one does have the activation. Yes.

44
00:02:33.200 --> 00:02:35.000
This is actually what a neural network is doing.

45
00:02:37.200 --> 00:02:40.900
So let me show you the graph representation, then we'll look at the Matrix since

46
00:02:40.900 --> 00:02:42.700
 we've already covered, you know.

47
00:02:46.600 --> 00:02:48.200
matrix multiplication we can

48
00:02:49.400 --> 00:02:52.400
we can talk about this. Let me come up here. So let's say we

49
00:02:52.400 --> 00:02:54.000
 have I will use again the

50
00:02:56.500 --> 00:02:57.600
the real estate example

51
00:02:59.600 --> 00:03:02.500
And let's say this is a very simple.

52
00:03:06.500 --> 00:03:07.600
classification model

53
00:03:08.500 --> 00:03:08.600
so

54
00:03:10.700 --> 00:03:12.600
we want to classify a property.

55
00:03:13.600 --> 00:03:16.600
By its category. So for example, is it a warehouse?

56
00:03:17.800 --> 00:03:19.000
or is it a

57
00:03:20.600 --> 00:03:22.500
is an apartment a residential apartment?

58
00:03:23.600 --> 00:03:26.200
Or let's say commercial property like an

59
00:03:26.200 --> 00:03:29.400
 office space in a building or apartment residential apartment.

60
00:03:31.200 --> 00:03:34.700
So how are they different you can have two properties that are similar in

61
00:03:34.700 --> 00:03:34.900
 size?

62
00:03:37.000 --> 00:03:37.400
but

63
00:03:38.600 --> 00:03:41.000
with offices you have less.

64
00:03:42.800 --> 00:03:43.700
partitioning

65
00:03:44.900 --> 00:03:47.500
You have fewer doors because you don't have any rooms.

66
00:03:47.500 --> 00:03:50.500
 No kitchen. Maybe you have a kitchen you don't

67
00:03:50.500 --> 00:03:50.600
 have.

68
00:03:51.700 --> 00:03:52.400
a balcony

69
00:03:53.900 --> 00:03:55.400
and maybe it's just

70
00:03:56.700 --> 00:03:58.100
What's the word I'm looking for more open?

71
00:03:59.300 --> 00:04:02.300
Like there are no enclosing there are no partitioning essentially.

72
00:04:05.100 --> 00:04:07.600
So let's say I want is the number of

73
00:04:10.200 --> 00:04:13.500
rooms in the property and number two is the

74
00:04:13.500 --> 00:04:16.700
 size of the property exactly wrong open

75
00:04:16.700 --> 00:04:17.300
 floor plan.

76
00:04:18.800 --> 00:04:19.800
Open floor plan.

77
00:04:22.600 --> 00:04:24.000
So obviously there's more to

78
00:04:26.600 --> 00:04:29.500
There's more things that we could

79
00:04:29.500 --> 00:04:32.400
 describe to distinguish these two. But again, the point

80
00:04:32.400 --> 00:04:34.800
 here is to understand what an activation is.

81
00:04:36.100 --> 00:04:38.000
And this is the context of really.

82
00:04:39.300 --> 00:04:39.900
I want is the

83
00:04:41.300 --> 00:04:44.100
number of rooms I too is the size of the property.

84
00:04:46.600 --> 00:04:47.400
And we have three.

85
00:04:49.900 --> 00:04:52.700
Perceptrons in our one hidden layer.

86
00:04:52.700 --> 00:04:53.800
 So this is one hidden layer.

87
00:04:54.300 --> 00:04:56.100
one input one hidden one output

88
00:04:57.200 --> 00:04:59.300
What comes out of this output layer?

89
00:05:00.000 --> 00:05:00.300
is

90
00:05:03.200 --> 00:05:06.200
is the is the classification is a type 1

91
00:05:06.200 --> 00:05:09.300
 a property or the type 2 property? Okay. Let's

92
00:05:09.300 --> 00:05:09.900
 see how this is done.

93
00:05:10.800 --> 00:05:14.300
So what we do is if you look at these arrows that

94
00:05:13.300 --> 00:05:16.200
 stem from for example

95
00:05:16.200 --> 00:05:16.700
 I2.

96
00:05:18.300 --> 00:05:21.800
I too will send to every perceptron.

97
00:05:24.700 --> 00:05:24.800
its value

98
00:05:25.800 --> 00:05:26.200
however

99
00:05:28.400 --> 00:05:32.100
It is not just setting the feature. It is also sending a random

100
00:05:31.100 --> 00:05:34.600
 weight and a different way to each perceptron.

101
00:05:35.100 --> 00:05:38.700
So for example, they first perceptron might

102
00:05:38.700 --> 00:05:39.900
 get a weight of 5.

103
00:05:41.400 --> 00:05:43.700
The second perception may get a weight of one.

104
00:05:45.300 --> 00:05:47.800
And the third perception might get a weight of 10.

105
00:05:49.100 --> 00:05:53.200
So one perceptron will consider the feature to be someone important

106
00:05:52.200 --> 00:05:55.300
 on another one not so important

107
00:05:55.300 --> 00:05:56.200
 another one very important.

108
00:05:58.400 --> 00:05:59.900
And then we do the same thing with the first feature.

109
00:06:00.900 --> 00:06:04.100
We send the value

110
00:06:03.100 --> 00:06:06.400
 to all three perceptrons, but we associate it

111
00:06:06.400 --> 00:06:08.200
 with the with different weights.

112
00:06:11.400 --> 00:06:12.600
That's what the slide is about.

113
00:06:13.800 --> 00:06:14.900
So this is nothing more than

114
00:06:16.500 --> 00:06:17.900
some arithmetic

115
00:06:18.500 --> 00:06:21.600
So here we can see we have the feature multiplied by its random

116
00:06:21.600 --> 00:06:21.900
 weight.

117
00:06:23.900 --> 00:06:25.200
We have the second feature.

118
00:06:26.400 --> 00:06:27.500
and of course all of this

119
00:06:28.400 --> 00:06:31.200
everything is happening inside the crystal chapter. That's what

120
00:06:31.200 --> 00:06:33.200
 you that's why you have this summation.

121
00:06:33.800 --> 00:06:35.700
or this Sigma Sigma represents summation

122
00:06:36.600 --> 00:06:36.900
anyway

123
00:06:37.800 --> 00:06:40.000
We multiply each feature by its rather wait.

124
00:06:41.200 --> 00:06:42.800
So you only have two features here. So.

125
00:06:43.600 --> 00:06:46.300
And since this is for the first picture perceptron, we'll multiply

126
00:06:46.300 --> 00:06:49.100
 it by this way. And then we have the the sum of the products.

127
00:06:50.100 --> 00:06:50.600
So let's say

128
00:06:52.100 --> 00:06:52.400
that

129
00:06:54.600 --> 00:06:56.700
this sum is 32.

130
00:06:58.100 --> 00:07:01.000
We will then take this number 32 and pass it to the

131
00:07:01.600 --> 00:07:03.300
 activation function this Greek letter of Phi.

132
00:07:04.100 --> 00:07:05.300
represent the activation function

133
00:07:06.100 --> 00:07:08.500
which what does this activation function? Well, it depends.

134
00:07:09.400 --> 00:07:12.800
It depends on what you use for your layer.

135
00:07:13.300 --> 00:07:14.000
These are the

136
00:07:16.400 --> 00:07:18.000
activation functions you can choose

137
00:07:23.900 --> 00:07:25.700
So this is the rectified linear unit.

138
00:07:29.500 --> 00:07:32.600
For the others, I'll show you. I'll take you to the playground to talk

139
00:07:32.600 --> 00:07:32.900
 about this.

140
00:07:34.800 --> 00:07:36.100
now for the

141
00:07:37.700 --> 00:07:40.100
for any layer, except the output layer you never

142
00:07:40.100 --> 00:07:40.600
 want to use

143
00:07:41.600 --> 00:07:44.500
A linear activation function or here as it's

144
00:07:44.500 --> 00:07:45.500
 known as the identity function.

145
00:07:46.300 --> 00:07:46.700
because

146
00:07:50.800 --> 00:07:53.200
well, let me tell you about let me tell you how really works

147
00:07:53.200 --> 00:07:55.000
 and then you'll see why you don't want to use the leader function.
