WEBVTT - This file was automatically generated by VIMEO

0
00:00:00.400 --> 00:00:03.100
So for step number five and six

1
00:00:03.100 --> 00:00:06.200
 orthogonalization, I'm going to create a new notebook before we

2
00:00:06.200 --> 00:00:09.400
 do step number five one second. I will import numpy.

3
00:00:13.700 --> 00:00:14.900
And math just in case.

4
00:00:16.100 --> 00:00:18.200
So the Matrix that we see in this picture.

5
00:00:21.600 --> 00:00:24.000
Is Basis Matrix? So I'm gonna call this B.

6
00:00:25.100 --> 00:00:26.300
and P dot array

7
00:00:29.200 --> 00:00:31.000
of course, I'm using the NP array method so

8
00:00:31.900 --> 00:00:32.600
I can.

9
00:00:34.200 --> 00:00:36.800
Use nub pipe actually beats and methods.

10
00:00:37.400 --> 00:00:37.700
It's

11
00:00:39.300 --> 00:00:42.200
a vectors are 1 1 0 1 2 0

12
00:00:42.200 --> 00:00:43.600
 1 1 0.

13
00:00:47.300 --> 00:00:48.300
1 2 0

14
00:00:52.900 --> 00:00:53.900
0 1 2

15
00:00:58.100 --> 00:01:01.000
and after orthog orthogonalization

16
00:01:03.500 --> 00:01:04.000
will get

17
00:01:07.100 --> 00:01:09.100
these three vectors

18
00:01:13.100 --> 00:01:13.800
one two and three

19
00:01:16.000 --> 00:01:16.400
so

20
00:01:18.500 --> 00:01:22.900
I will call this now. Orthogonal matrices

21
00:01:22.900 --> 00:01:25.300
 are usually denoted with the uppercase letter q

22
00:01:26.400 --> 00:01:27.900
What I'm just going to call this B.

23
00:01:30.600 --> 00:01:31.500
orthogonal

24
00:01:37.500 --> 00:01:38.000
so we have

25
00:01:39.100 --> 00:01:42.100
one negative 1 over 2 1 over 2 and 0

26
00:01:42.900 --> 00:01:45.200
so that's just negative 0.5.

27
00:01:48.500 --> 00:01:51.700
0.5 and 0 and third one.

28
00:01:54.200 --> 00:01:57.400
If you multiply the scalar value by these components will get

29
00:01:57.400 --> 00:01:58.000
 zero zero two.

30
00:01:59.400 --> 00:01:59.700
zero

31
00:02:01.400 --> 00:02:02.000
zero two

32
00:02:04.100 --> 00:02:05.600
to make this orthod over you see here.

33
00:02:10.100 --> 00:02:11.000
This component is two.

34
00:02:11.700 --> 00:02:14.000
It is so this Vector is not normalized.

35
00:02:14.800 --> 00:02:16.400
These could be normalized but

36
00:02:18.500 --> 00:02:21.600
this is just by virtue of the operations, but

37
00:02:24.300 --> 00:02:25.600
Let me show you how to normalize this.

38
00:02:27.900 --> 00:02:30.200
Normalize this we must divide we must

39
00:02:30.200 --> 00:02:32.100
 find a magnitude of each factor.

40
00:02:34.900 --> 00:02:37.700
And then divide each component or we

41
00:02:37.700 --> 00:02:38.200
 can divide in.

42
00:02:39.400 --> 00:02:42.000
In vectors of matrices we can multiply it by one over the

43
00:02:42.000 --> 00:02:42.400
 norm.

44
00:02:42.900 --> 00:02:43.900
Let me show you what I mean.

45
00:02:44.400 --> 00:02:44.700
so

46
00:02:47.300 --> 00:02:49.700
I will have N Sub 1 and sub 2 and sub 3

47
00:02:50.700 --> 00:02:52.500
for these for each row.

48
00:02:53.200 --> 00:02:53.400
so

49
00:02:54.600 --> 00:02:56.100
Norm one will be equal to

50
00:02:58.200 --> 00:03:01.400
NP dot linear algebra dot

51
00:03:01.400 --> 00:03:03.500
 nor of the first

52
00:03:06.700 --> 00:03:09.100
Let's just say column. So let's imagine these are columns. They're

53
00:03:09.100 --> 00:03:11.200
 actually Rose, but let's imagine. These are colors. I'm gonna go be

54
00:03:14.400 --> 00:03:14.800
zero

55
00:03:22.900 --> 00:03:24.600
That's the norm of the first Factor.

56
00:03:25.200 --> 00:03:27.400
If I want to normalize it, I'm going to go B.

57
00:03:31.400 --> 00:03:34.100
And then multiply our multiplied by 1 over.

58
00:03:34.800 --> 00:03:35.400
the norm

59
00:03:37.400 --> 00:03:37.700
like so

60
00:03:41.900 --> 00:03:45.600
I'll give me the new Vector 0.7 0.70.

61
00:03:48.500 --> 00:03:50.700
so if I return here to this picture

62
00:03:54.600 --> 00:03:55.500
That's 0.7.

63
00:03:57.900 --> 00:04:00.100
Another way to express square root of 2, by the

64
00:04:00.100 --> 00:04:03.400
 way, in case you didn't catch this another way

65
00:04:03.400 --> 00:04:04.700
 to express square root of 2.

66
00:04:06.300 --> 00:04:07.000
in math

67
00:04:08.100 --> 00:04:09.300
So if you have square root of 2.

68
00:04:12.600 --> 00:04:13.100
down here

69
00:04:14.500 --> 00:04:16.500
That's just two raised to the power.

70
00:04:19.700 --> 00:04:20.500
0.5.

71
00:04:22.100 --> 00:04:23.000
That's what I'm doing in.

72
00:04:23.800 --> 00:04:25.800
my laptop calculator

73
00:04:27.400 --> 00:04:30.300
so the square root of 2 the square

74
00:04:30.300 --> 00:04:30.800
 root of 2.

75
00:04:35.300 --> 00:04:39.000
2 over the to the power 0.5 over 2

76
00:04:38.000 --> 00:04:40.200
 0.7.

77
00:04:42.500 --> 00:04:45.300
That's what they're trying to say here. These have been normalized. If

78
00:04:45.300 --> 00:04:48.600
 you see here what we do is we take the first Vector divided by

79
00:04:48.600 --> 00:04:49.200
 its magnitude.

80
00:04:49.800 --> 00:04:51.800
And that's exactly what we've done here.

81
00:04:53.300 --> 00:04:53.400
here

82
00:04:54.900 --> 00:04:55.600
normalized

83
00:04:59.500 --> 00:04:59.900
so then

84
00:05:00.800 --> 00:05:02.100
if we create a new Matrix.

85
00:05:05.600 --> 00:05:07.000
We orthonormal.

86
00:05:17.700 --> 00:05:18.600
then

87
00:05:19.500 --> 00:05:21.600
the First Column and B orthonormal

88
00:05:23.600 --> 00:05:24.000
would be

89
00:05:26.200 --> 00:05:26.900
this vector

90
00:05:28.500 --> 00:05:29.200
So let me run this.

91
00:05:33.700 --> 00:05:35.000
I cannot leave this up to you. Okay?

92
00:05:43.800 --> 00:05:46.300
I'm just going to put three zeros in here

93
00:05:46.300 --> 00:05:47.400
 just as placeholders.

94
00:05:51.200 --> 00:05:53.500
There's actually a method called zeros, but never mind that for now.

95
00:05:56.700 --> 00:05:57.600
one vector

96
00:05:59.600 --> 00:05:59.900
not only

97
00:06:01.900 --> 00:06:02.400
okay.

98
00:06:05.600 --> 00:06:08.900
So that's the First Column of The orthonormal Matrix.

99
00:06:10.300 --> 00:06:11.500
I'll go ahead and do the same for

100
00:06:13.500 --> 00:06:16.600
the others now just to simplify the code. I'm going to take this bit.

101
00:06:21.800 --> 00:06:22.600
It's just remember.

102
00:06:24.800 --> 00:06:26.700
This will normalize the first vector.

103
00:06:28.200 --> 00:06:31.600
And make that the First Column of the orthonormal effect Matrix.

104
00:06:32.700 --> 00:06:36.600
And I'm just going to copy paste this for the other matrices. This

105
00:06:36.600 --> 00:06:37.000
 will be one.

106
00:06:41.600 --> 00:06:42.000
one

107
00:06:47.200 --> 00:06:47.500
so

108
00:06:49.600 --> 00:06:52.700
normalize the vectors of B and

109
00:06:55.300 --> 00:06:58.700
Also, go no lines you can

110
00:06:58.700 --> 00:06:59.600
 see this picture for reference.

111
00:07:00.300 --> 00:07:01.000
see

112
00:07:01.800 --> 00:07:02.400
gram

113
00:07:03.300 --> 00:07:05.400
Schmidt algorithm here

114
00:07:07.900 --> 00:07:10.900
and then if I print p orthonormal

115
00:07:16.800 --> 00:07:19.000
I want to let me reassign I guess I could do

116
00:07:19.000 --> 00:07:19.400
 this.

117
00:07:22.900 --> 00:07:25.100
There we go. That's the that's the orthonormal Matrix now.

118
00:07:27.100 --> 00:07:29.000
You see none of it's components.

119
00:07:30.700 --> 00:07:32.600
exceed zero or go below zero

120
00:07:35.400 --> 00:07:38.300
If we were to plot these vectors, they

121
00:07:38.300 --> 00:07:41.500
 would be orthogonal and they would have they would

122
00:07:41.500 --> 00:07:43.600
 not exceed a radius of one.

123
00:07:44.700 --> 00:07:46.300
This is what an orthonormal Matrix is.

124
00:07:47.100 --> 00:07:49.300
Now, let me show you how to do this using.

125
00:07:50.600 --> 00:07:53.400
Numpy without you know manually doing

126
00:07:53.400 --> 00:07:54.200
 this calculation.

127
00:07:55.400 --> 00:07:55.500
so

128
00:07:58.200 --> 00:07:59.000
I will return here.

129
00:08:00.800 --> 00:08:02.900
to show you how to or the normalize

130
00:08:04.400 --> 00:08:05.200
ATA

131
00:08:05.800 --> 00:08:08.100
Okay, so if you remember ATA.

132
00:08:09.200 --> 00:08:11.600
Is that Matrix the orthogonalize it?

133
00:08:12.600 --> 00:08:15.000
There is a method called. Let me see what

134
00:08:15.300 --> 00:08:15.500
 it was called.

135
00:08:16.500 --> 00:08:19.400
It's called Earth. So I'm gonna go.

136
00:08:21.400 --> 00:08:24.500
NP Lin algebra

137
00:08:26.500 --> 00:08:28.200
dot horse

138
00:08:29.500 --> 00:08:30.800
This is awesome normalized, I believe.

139
00:08:34.200 --> 00:08:35.900
And I'm going to plug in.

140
00:08:40.400 --> 00:08:41.800
Let's do 88 first.

141
00:08:58.300 --> 00:08:58.700
Okay. There we go.

142
00:09:01.400 --> 00:09:03.800
So that's how you order analyze using python.

143
00:09:04.800 --> 00:09:07.600
That's the first that's so this is the Matrix. This is

144
00:09:07.600 --> 00:09:09.900
 the Matrix U, right? This is u,

145
00:09:11.100 --> 00:09:12.000
I come back here.

146
00:09:13.600 --> 00:09:14.600
That's the U Matrix.

147
00:09:17.700 --> 00:09:18.000
Okay.

148
00:09:21.400 --> 00:09:23.000
And then we have the Matrix.

149
00:09:27.300 --> 00:09:28.800
That's step number six.

150
00:09:40.900 --> 00:09:41.300
V

151
00:09:44.300 --> 00:09:47.300
So if we

152
00:09:47.300 --> 00:09:48.000
 print you.

153
00:09:52.800 --> 00:09:54.000
We print V.

154
00:09:58.800 --> 00:10:00.200
So this one?

155
00:10:02.100 --> 00:10:03.300
0.70

156
00:10:04.100 --> 00:10:06.100
so we have the same Matrix up here.

157
00:10:11.200 --> 00:10:12.400
and for s

158
00:10:14.400 --> 00:10:17.300
For us we will we have up here. Right? We took we have

159
00:10:17.300 --> 00:10:18.500
 Sigma 1 and sigma 2

160
00:10:19.200 --> 00:10:20.800
so for the Matrix as

161
00:10:25.700 --> 00:10:27.300
that would be step.

162
00:10:28.800 --> 00:10:31.100
Four step four we put into a matrix.

163
00:10:31.100 --> 00:10:31.900
 So step four.

164
00:10:33.600 --> 00:10:36.400
We have a new Matrix called S and P dot

165
00:10:36.400 --> 00:10:36.700
 array.

166
00:10:41.600 --> 00:10:42.100
which will be

167
00:10:45.200 --> 00:10:47.800
let me just reorder these this Sigma.

168
00:10:49.600 --> 00:10:52.400
So we have Sigma 1

169
00:10:52.400 --> 00:10:53.000
 and 0.

170
00:10:55.700 --> 00:10:56.300
That's the first.

171
00:10:58.700 --> 00:10:58.900
vector

172
00:11:01.300 --> 00:11:01.700
the other vector

173
00:11:02.600 --> 00:11:03.100
is zero

174
00:11:04.600 --> 00:11:05.500
Sigma 2

175
00:11:09.100 --> 00:11:09.300
Okay.

176
00:11:12.300 --> 00:11:13.500
SUV

177
00:11:17.200 --> 00:11:19.600
There's s there is U there is V.

178
00:11:20.900 --> 00:11:22.900
We put these three vectors together.

179
00:11:23.900 --> 00:11:27.000
So I'm going to go NP. This is Step. This

180
00:11:26.200 --> 00:11:29.700
 is no not this we've already done steps six at

181
00:11:29.700 --> 00:11:29.900
 this point.

182
00:11:30.800 --> 00:11:33.400
But I'm just gonna multiply all three vectors.

183
00:11:33.400 --> 00:11:36.300
 I'm going to go math multiplicate now math multiple takes

184
00:11:36.300 --> 00:11:37.500
 two arguments at a time.

185
00:11:38.500 --> 00:11:40.800
So I'm going to first add multiply the first two vectors.

186
00:11:43.700 --> 00:11:44.100
that's

187
00:11:45.800 --> 00:11:48.500
you and us so I'm gonna first multiply these

188
00:11:48.500 --> 00:11:48.700
 together.

189
00:11:50.400 --> 00:11:51.600
So I will be.

190
00:11:56.500 --> 00:11:57.600
You and this.

191
00:12:04.700 --> 00:12:07.300
And then this will give us a new Matrix which

192
00:12:07.300 --> 00:12:09.400
 I'll multiply with v.

193
00:12:10.800 --> 00:12:12.100
so NP Dot

194
00:12:14.100 --> 00:12:15.300
matrix multiplication

195
00:12:16.500 --> 00:12:18.500
this new Matrix with the

196
00:12:22.300 --> 00:12:23.000
and if I come back here.

197
00:12:24.900 --> 00:12:27.200
You can see we returned the

198
00:12:27.200 --> 00:12:29.300
 original Matrix 10 to 5 11.

199
00:12:30.400 --> 00:12:31.600
ten two five eleven

200
00:12:34.100 --> 00:12:35.000
Let me type this.

201
00:12:35.700 --> 00:12:36.200
to get

202
00:12:37.700 --> 00:12:41.100
the orthogonalized so the orthogonalized orthogonal

203
00:12:40.100 --> 00:12:42.500
 Matrix would be the Matrix.

204
00:12:45.600 --> 00:12:47.400
This isn't correct. By the way, this is s

205
00:12:48.300 --> 00:12:49.000
this is s

206
00:12:53.300 --> 00:12:54.500
The Matrix U

207
00:13:00.100 --> 00:13:01.300
The Matrix U

208
00:13:04.100 --> 00:13:04.400
is

209
00:13:06.200 --> 00:13:09.600
The gram Schmidt algorithm applied to that.

210
00:13:11.100 --> 00:13:13.900
And we would be the gramishment algorithm applied to this.

211
00:13:15.600 --> 00:13:15.900
so you

212
00:13:17.900 --> 00:13:20.700
will be the let me

213
00:13:20.700 --> 00:13:21.300
 type in text.

214
00:13:22.900 --> 00:13:24.100
Ram Schmidt

215
00:13:25.100 --> 00:13:26.400
algorithm applied to

216
00:13:29.700 --> 00:13:30.900
ATA

217
00:13:31.900 --> 00:13:33.600
and V is the same thing, but

218
00:13:34.500 --> 00:13:35.300
the other way around

219
00:13:36.200 --> 00:13:38.300
okay times a transpose.

220
00:13:39.700 --> 00:13:42.400
Okay, just keep in mind that you do not apply the

221
00:13:42.400 --> 00:13:45.300
 grams with algorithm through just a on its own you have

222
00:13:45.300 --> 00:13:48.700
 to multiply you have to apply this algorithm to

223
00:13:48.700 --> 00:13:51.300
 the product of these two matrices. This is

224
00:13:51.300 --> 00:13:52.500
 the distinction at SVD.

225
00:13:53.100 --> 00:13:55.900
Now finally if I bring you back to numpy.

226
00:13:56.700 --> 00:13:58.000
We could have done this whole thing.

227
00:13:59.200 --> 00:13:59.700
using

228
00:14:02.500 --> 00:14:05.500
the SVD algorithm from numpy. So this would be SVD.

229
00:14:06.300 --> 00:14:08.700
Let me call a manual for lack of better words.

230
00:14:09.900 --> 00:14:11.000
but if you want to do this

231
00:14:13.200 --> 00:14:15.700
There's a very nice method that does this whole thing in one go.

232
00:14:16.300 --> 00:14:18.100
So I'm gonna have here SVD.

233
00:14:23.700 --> 00:14:25.300
the SVD method from the pi

234
00:14:31.700 --> 00:14:34.200
So this will be what NP? I think

235
00:14:34.200 --> 00:14:35.300
 Lin algebra.

236
00:14:37.100 --> 00:14:40.300
Doctor SVD our plus and a

237
00:14:40.300 --> 00:14:42.200
 and this method will return.

238
00:14:45.900 --> 00:14:47.600
What it is what is return values?

239
00:14:48.400 --> 00:14:51.100
Three vectors us 3 in that

240
00:14:51.100 --> 00:14:52.300
 order, so I'm going to go.

241
00:14:53.700 --> 00:14:54.200
you

242
00:14:56.100 --> 00:14:56.400
s

243
00:14:57.400 --> 00:14:58.000
V

244
00:15:01.200 --> 00:15:03.600
If I print them all print you.

245
00:15:04.600 --> 00:15:05.600
Let's try to be.

246
00:15:11.400 --> 00:15:14.000
You see we have to say matrices.

247
00:15:14.700 --> 00:15:15.500
This is V.

248
00:15:16.900 --> 00:15:17.700
Like we have up here.

249
00:15:18.700 --> 00:15:21.600
This is the this is the eigenvector. But what

250
00:15:21.600 --> 00:15:23.300
 you would do is you would take the values.

251
00:15:24.400 --> 00:15:25.900
And put them in a square Matrix.

252
00:15:27.500 --> 00:15:28.800
And of course, that's Matrix U.

253
00:15:30.300 --> 00:15:32.300
Of course if you would multiply these together.

254
00:15:33.700 --> 00:15:35.700
So if we were to perform this operation down here.

255
00:15:38.200 --> 00:15:41.300
Oh, yeah, because this is

256
00:15:41.300 --> 00:15:44.200
 not as I need to fix. So yes see because

257
00:15:44.200 --> 00:15:45.700
 we can't just multiply this vector.

258
00:15:46.400 --> 00:15:49.100
We need s to be a matrix. So we

259
00:15:49.100 --> 00:15:51.400
 need us to be a matrix.

260
00:15:53.400 --> 00:15:56.300
Anyways, that's Matrix up here. It's exactly this one up

261
00:15:56.300 --> 00:15:56.400
 here.

262
00:15:58.300 --> 00:15:59.500
this is really redundant but

263
00:16:01.500 --> 00:16:03.700
What I'm saying is you'll get them same Matrix back.
