WEBVTT - This file was automatically generated by VIMEO

0
00:00:01.500 --> 00:00:03.600
I will import numpy.

1
00:00:07.600 --> 00:00:08.800
as MP and

2
00:00:11.600 --> 00:00:11.900
Matlab and

3
00:00:13.800 --> 00:00:14.600
math

4
00:00:15.700 --> 00:00:16.600
plot limit

5
00:00:22.600 --> 00:00:25.800
so we can see what principal components are and then

6
00:00:25.800 --> 00:00:26.900
 we can visualize them.

7
00:00:28.600 --> 00:00:28.800
now

8
00:00:31.800 --> 00:00:33.500
what I'm going to show you is a matrix.

9
00:00:40.400 --> 00:00:41.000
There is two by six.

10
00:00:44.800 --> 00:00:48.100
So it has two columns and six six rows. This

11
00:00:48.100 --> 00:00:51.500
 is a very simple Matrix and it's just and it's

12
00:00:51.500 --> 00:00:52.300
 small enough so that we can

13
00:00:55.500 --> 00:00:58.200
You know get the get the point of PCA and then of course.

14
00:00:59.800 --> 00:01:02.100
In the next example, we will look at

15
00:01:02.100 --> 00:01:02.800
 a large.

16
00:01:04.200 --> 00:01:06.100
Data set. So this one only has two dimensions.

17
00:01:07.700 --> 00:01:10.800
Ultimately, what we want to do is we want to project this two-dimensional.

18
00:01:11.900 --> 00:01:14.900
Data onto one. I want dimensional into

19
00:01:14.900 --> 00:01:16.700
 one dimension. So we want to go from

20
00:01:18.300 --> 00:01:21.300
essentially two vectors to one vector. Let me explain what

21
00:01:21.300 --> 00:01:21.500
 I mean.

22
00:01:22.900 --> 00:01:24.800
So we are going to perform SVD on this.

23
00:01:25.700 --> 00:01:28.100
Okay, and remember we said that PC is a special

24
00:01:28.100 --> 00:01:31.200
 case of SVD now we're not going to do this. We're not

25
00:01:31.200 --> 00:01:34.700
 going to use grab Schmidt and normalization. We're

26
00:01:34.700 --> 00:01:37.100
 just going to use a built-in method of

27
00:01:38.400 --> 00:01:41.500
numpy called SVD. So there's a method

28
00:01:41.500 --> 00:01:42.000
 called NP.

29
00:01:43.500 --> 00:01:46.800
It's a SVD in the object linear algebra.

30
00:01:53.300 --> 00:01:54.800
And it's returned value will be 3.

31
00:01:56.100 --> 00:01:59.500
Things and we'll start well, it will be two matrices

32
00:01:59.500 --> 00:02:00.200
 and one vector.

33
00:02:00.800 --> 00:02:02.000
But you will assign to you.

34
00:02:03.300 --> 00:02:04.100
As and V.

35
00:02:07.200 --> 00:02:10.500
So the return value of this method will be a matrix Vector Matrix

36
00:02:10.500 --> 00:02:11.400
 respectively.

37
00:02:14.100 --> 00:02:17.500
And after all and that's this SVD composition and

38
00:02:17.500 --> 00:02:18.700
 then I'll print all three.

39
00:02:20.800 --> 00:02:21.500
Variables I'll print you.

40
00:02:24.100 --> 00:02:25.300
And us and V.

41
00:02:37.800 --> 00:02:39.000
So this is the Matrix U.

42
00:02:41.300 --> 00:02:42.500
the eigenvalues

43
00:02:43.300 --> 00:02:44.600
that will be put in the

44
00:02:45.500 --> 00:02:46.000
Matrix

45
00:02:47.700 --> 00:02:49.600
SS for Sigma, okay.

46
00:02:51.800 --> 00:02:54.900
In a PCA the S is a sigma use the

47
00:02:54.900 --> 00:02:55.200
 Greek letter.

48
00:02:56.400 --> 00:02:56.600
and

49
00:02:57.600 --> 00:02:58.500
The Matrix V

50
00:03:08.700 --> 00:03:09.000
All right.

51
00:03:10.600 --> 00:03:13.400
The next thing we are going to do is I'm going

52
00:03:13.400 --> 00:03:15.200
 to put these eigenvalues.

53
00:03:18.100 --> 00:03:19.400
in an identity Matrix

54
00:03:20.200 --> 00:03:22.900
So again, you see here. This is an identity Matrix.

55
00:03:24.900 --> 00:03:27.000
But instead of once we have the argumentality, so I'm

56
00:03:27.100 --> 00:03:28.300
 going to produce this Square Matrix.

57
00:03:30.800 --> 00:03:31.500
and to do this

58
00:03:33.100 --> 00:03:33.500
first

59
00:03:35.100 --> 00:03:36.200
I will assign.

60
00:03:36.600 --> 00:03:39.500
lowercase s to uppercase s because the

61
00:03:39.500 --> 00:03:42.400
 convention you know, we want to follow linear algebra

62
00:03:42.400 --> 00:03:43.100
 convention where

63
00:03:43.700 --> 00:03:46.300
a we use the we use a lowercase letters

64
00:03:46.300 --> 00:03:49.300
 to denote the vectors uppercase that is to denote

65
00:03:49.300 --> 00:03:49.600
 matrices.

66
00:03:50.500 --> 00:03:53.100
So I'm going to change uppercase as to small

67
00:03:53.100 --> 00:03:53.200
 as

68
00:03:54.400 --> 00:03:56.600
uppercase test instead will be a matrix.

69
00:04:03.400 --> 00:04:05.200
If you see this is initial on form.

70
00:04:07.200 --> 00:04:09.000
We have ones across the principal diagonal.

71
00:04:11.300 --> 00:04:13.100
we need this to be a six by two because

72
00:04:15.800 --> 00:04:17.900
of the Matrix operation that we're about to perform.

73
00:04:18.800 --> 00:04:20.500
But this is the first eigenvalue.

74
00:04:21.500 --> 00:04:24.400
Second of a second value or if you like the first

75
00:04:24.400 --> 00:04:27.400
 singular value in the second singular Valley. Also if

76
00:04:27.400 --> 00:04:29.100
 you like the first principle component.

77
00:04:30.600 --> 00:04:31.800
And the second principle component.

78
00:04:34.500 --> 00:04:37.400
Once I start visualizing you will see how this how we're

79
00:04:37.400 --> 00:04:37.500
 able to.

80
00:04:39.600 --> 00:04:42.700
Reduce the dimensionality of our data. Now. How

81
00:04:42.700 --> 00:04:45.700
 many imagine this were an Excel sheet. We have two columns

82
00:04:45.700 --> 00:04:46.000
 of data.

83
00:04:47.700 --> 00:04:50.400
What we're about to do this example is collapsing into one column.

84
00:04:51.600 --> 00:04:54.400
So we go from a two-dimensional letter to one dimensional Theta that's

85
00:04:54.400 --> 00:04:57.200
 a lead. That's the linear transformation to go

86
00:04:57.200 --> 00:04:58.100
 from R2 to R.

87
00:04:59.400 --> 00:04:59.900
R 1

88
00:05:02.600 --> 00:05:06.100
Now I also want to do this. I want to plot this

89
00:05:05.100 --> 00:05:07.500
 Vector on its own axis.

90
00:05:08.300 --> 00:05:09.000
plot this

91
00:05:09.700 --> 00:05:11.600
on its own axis. So this will be let's see X

92
00:05:12.500 --> 00:05:13.300
and this will be y

93
00:05:17.700 --> 00:05:17.800
so

94
00:05:19.200 --> 00:05:22.200
Here, we will say performing SVD.

95
00:05:25.400 --> 00:05:26.300
principal component

96
00:05:30.300 --> 00:05:31.200
SVD

97
00:05:32.600 --> 00:05:35.500
first we need to decompose The Matrix into three matrices.

98
00:05:38.300 --> 00:05:39.700
Then we are going to visualize.

99
00:05:43.900 --> 00:05:44.200
the

100
00:05:46.500 --> 00:05:47.300
column vectors

101
00:05:48.700 --> 00:05:49.300
of a

102
00:05:51.400 --> 00:05:51.700
just so we can have a

103
00:05:52.900 --> 00:05:53.600
intuitive

104
00:05:55.300 --> 00:05:55.900
understanding

105
00:05:57.400 --> 00:06:00.600
No, I'm good to use a technique called the list comprehension. So

106
00:06:00.600 --> 00:06:03.800
 if you do not if you haven't seen this before or you

107
00:06:03.800 --> 00:06:04.300
 don't remember it.

108
00:06:07.400 --> 00:06:08.400
let me show you I'm gonna go a

109
00:06:09.800 --> 00:06:12.200
That's the Matrix and I'm going to use a square bracket. Of

110
00:06:12.200 --> 00:06:12.300
 course.

111
00:06:13.700 --> 00:06:15.200
If you plug in a number.

112
00:06:18.500 --> 00:06:21.400
And these are the indices the index the every index

113
00:06:21.400 --> 00:06:24.300
 will correspond to a particular role of a matrix

114
00:06:24.300 --> 00:06:25.400
 if I type in zero.

115
00:06:27.400 --> 00:06:30.500
This will be the first row of the original Matrix.

116
00:06:34.300 --> 00:06:37.700
And of course, we remember that we count from 0 and in programming.

117
00:06:40.800 --> 00:06:43.100
if I want the last row I go I go 5

118
00:06:45.800 --> 00:06:47.300
now if I want all of the rows

119
00:06:50.300 --> 00:06:51.400
What this colon means is that.

120
00:06:52.600 --> 00:06:55.400
What precedes the color is the starting range? And what

121
00:06:55.400 --> 00:06:59.000
 comes after is this ending range if I type this if I

122
00:06:58.000 --> 00:06:59.300
 leave?

123
00:07:00.200 --> 00:07:03.400
Both sides of the colon empty. That means give me all of

124
00:07:03.400 --> 00:07:03.900
 the rows.

125
00:07:04.600 --> 00:07:05.400
So here we can see.

126
00:07:06.300 --> 00:07:09.500
The first row is negative 3 negative 3.

127
00:07:09.500 --> 00:07:12.200
 The second was negative 2 negative 1. So if I just want the first

128
00:07:12.200 --> 00:07:14.400
 two rows I can go 0 1

129
00:07:17.800 --> 00:07:20.200
Or rather zero to that. It has

130
00:07:20.200 --> 00:07:22.000
 to be stopping index. There we go.

131
00:07:23.600 --> 00:07:24.500
Now what I actually want.

132
00:07:25.600 --> 00:07:26.700
Is all of the rows.

133
00:07:28.700 --> 00:07:31.200
But I want to only extract the first column.

134
00:07:32.900 --> 00:07:34.300
So I'm going to call this C1.

135
00:07:36.300 --> 00:07:39.100
and it will be negative 3 negative 2 1 negative 1 2 3

136
00:07:40.200 --> 00:07:43.800
So what I'm going to say, I want all of the rows all of

137
00:07:43.800 --> 00:07:44.200
 the rows.

138
00:07:45.200 --> 00:07:46.100
from the first column

139
00:07:48.700 --> 00:07:49.300
and that will give me

140
00:07:50.400 --> 00:07:52.100
these components

141
00:07:58.100 --> 00:08:00.400
Animal, I'll also do it for the second column.

142
00:08:02.100 --> 00:08:05.100
So all of the rows from the second column again, we count from

143
00:08:05.100 --> 00:08:05.300
 0.

144
00:08:06.500 --> 00:08:07.400
Which is why this is one.

145
00:08:10.100 --> 00:08:10.600
now I'm going to

146
00:08:11.400 --> 00:08:11.900
plot these

147
00:08:13.400 --> 00:08:16.200
two vectors. So C1 and C2 are both now vectors.

148
00:08:19.900 --> 00:08:22.500
Okay, however, I'm going to treat these as

149
00:08:22.500 --> 00:08:24.000
 points on the x-axis.

150
00:08:25.800 --> 00:08:28.600
And for C2 it will be points on the y-axis. Basically. We're

151
00:08:28.600 --> 00:08:29.400
 just draw two.

152
00:08:30.900 --> 00:08:33.600
one horizontal and one

153
00:08:33.600 --> 00:08:34.500
 vertical column

154
00:08:35.200 --> 00:08:38.200
and I'll see what and I'll show you why we want to do this.

155
00:08:39.500 --> 00:08:43.900
So to plot I'm going to use the PLT method PLT Dot.

156
00:08:45.100 --> 00:08:45.800
scatter

157
00:08:51.300 --> 00:08:55.200
so I want so you want to be on the x-axis. I'm

158
00:08:54.200 --> 00:08:56.000
 going to type in C1.

159
00:08:57.200 --> 00:08:58.300
for the y-axis

160
00:08:59.200 --> 00:08:59.900
we want

161
00:09:03.200 --> 00:09:04.200
I'm gonna set it to zero.

162
00:09:08.600 --> 00:09:11.300
Okay, six elements corresponding with

163
00:09:11.300 --> 00:09:13.100
 the six points in that vector.

164
00:09:17.400 --> 00:09:21.000
And then I should have will see as plts.

165
00:09:27.800 --> 00:09:29.800
Yeah, thank you, Ron. I fixed up.

166
00:09:33.700 --> 00:09:36.400
Now I also want to color code these points.

167
00:09:37.200 --> 00:09:40.300
So this will be zero negative 3, excuse me,

168
00:09:40.300 --> 00:09:42.500
 negative 3 0 negative 2 0

169
00:09:43.300 --> 00:09:46.300
Once you see there's a points right? These are the points

170
00:09:46.300 --> 00:09:49.200
 corresponding to the x-axis. These are the points corresponding on the

171
00:09:49.200 --> 00:09:49.600
 y-axis.

172
00:09:50.700 --> 00:09:53.500
I want to color code these I want to color code the X points

173
00:09:53.500 --> 00:09:53.700
 that are

174
00:09:55.700 --> 00:09:56.900
the left of the origin

175
00:09:57.600 --> 00:10:00.200
Beside it. Basically the numbers that are negative will have one

176
00:10:00.200 --> 00:10:02.300
 color the numbers that are positive will have another color.

177
00:10:04.500 --> 00:10:09.000
So I'm going to say c c is the parameter for

178
00:10:08.000 --> 00:10:09.000
 color.

179
00:10:10.700 --> 00:10:12.500
And the criteria for shooting the color.

180
00:10:14.400 --> 00:10:14.900
is

181
00:10:17.300 --> 00:10:19.000
C1 greater than 0

182
00:10:19.900 --> 00:10:22.400
so if the components see what are above

183
00:10:22.400 --> 00:10:22.500
 0

184
00:10:24.100 --> 00:10:27.000
we will get one color if they are below zero will get another color.

185
00:10:28.800 --> 00:10:30.900
and we will let me just set the

186
00:10:32.600 --> 00:10:33.900
the no never mind.

187
00:10:34.600 --> 00:10:36.500
It's Gonna Change Dimensions, let me see what this looks like.

188
00:10:41.500 --> 00:10:42.200
Okay. There we go.

189
00:10:43.800 --> 00:10:47.300
and I'll do the same for the second column

190
00:10:47.300 --> 00:10:48.300
 of Matrix a

191
00:10:49.900 --> 00:10:52.600
maybe what I should have done is typed and make this a1a2.

192
00:10:53.400 --> 00:10:54.300
Make it clear.

193
00:10:55.500 --> 00:10:56.500
Let me run this again.

194
00:11:03.800 --> 00:11:05.200
and then a two

195
00:11:13.900 --> 00:11:16.600
let's change the order of these arguments.

196
00:11:23.800 --> 00:11:25.300
So the idea is this.

197
00:11:30.400 --> 00:11:31.800
We have two dimensions of data.

198
00:11:32.700 --> 00:11:33.500
these two vectors

199
00:11:36.200 --> 00:11:39.400
and what we want to do is retain this

200
00:11:39.400 --> 00:11:40.500
 spread.

201
00:11:42.100 --> 00:11:42.900
this variation

202
00:11:44.500 --> 00:11:46.400
but in one axis in one vector

203
00:11:48.600 --> 00:11:50.200
So I'm going to retained this value.

204
00:11:52.100 --> 00:11:52.300
these

205
00:11:53.800 --> 00:11:56.600
this spread in one diagonal

206
00:11:58.200 --> 00:12:00.000
So here this is one dimension of our data.

207
00:12:00.600 --> 00:12:02.100
the second dimension of our data

208
00:12:02.900 --> 00:12:04.200
however, we want to do is use the

209
00:12:04.800 --> 00:12:05.900
principal components

210
00:12:06.500 --> 00:12:07.700
Which are the Eugene values?

211
00:12:08.800 --> 00:12:12.300
To collapse this into one axis without

212
00:12:11.300 --> 00:12:14.100
 while keeping.

213
00:12:14.800 --> 00:12:17.000
This spread as much as possible.

214
00:12:20.200 --> 00:12:21.200
So here's what I'll do next.

215
00:12:26.100 --> 00:12:27.200
I am going to take

216
00:12:42.400 --> 00:12:44.200
the first principle component

217
00:12:45.500 --> 00:12:46.400
multiplied by

218
00:12:49.100 --> 00:12:50.800
the first principle Direction

219
00:12:51.700 --> 00:12:52.500
we open this again.

220
00:12:54.900 --> 00:12:55.300
now you

221
00:13:02.200 --> 00:13:04.200
I know it has it's it's quite

222
00:13:07.400 --> 00:13:10.700
Maybe Missy but the First Column Vector

223
00:13:10.700 --> 00:13:12.600
 in U is the first principle Direction.

224
00:13:14.300 --> 00:13:15.700
What I'm going to do is I'm going to multiply.

225
00:13:17.700 --> 00:13:20.700
the first principle component by the

226
00:13:20.700 --> 00:13:22.700
 principal direction of the Matrix U

227
00:13:23.400 --> 00:13:26.400
Now the principal component is also.

228
00:13:29.400 --> 00:13:30.800
the first principle component

229
00:13:31.700 --> 00:13:34.700
Is the component that has the largest values if

230
00:13:34.700 --> 00:13:35.300
 I come back here?

231
00:13:36.300 --> 00:13:39.600
If we look at this example, this was a completely different Matrix.

232
00:13:40.600 --> 00:13:43.700
The largest singular value or large eigenvalue. This

233
00:13:43.700 --> 00:13:44.600
 Matrix is the number 14.

234
00:13:47.700 --> 00:13:50.100
This number also corresponds in the

235
00:13:50.100 --> 00:13:51.300
 context of PCA.

236
00:13:51.900 --> 00:13:52.300
to the

237
00:13:58.100 --> 00:13:59.500
variants in the data

238
00:14:00.100 --> 00:14:01.600
so the first eigenvalue

239
00:14:03.700 --> 00:14:06.800
Is the first principle component and it's also the

240
00:14:06.800 --> 00:14:10.000
 represents the largest variance

241
00:14:09.000 --> 00:14:10.300
 in the data?

242
00:14:11.200 --> 00:14:14.200
Now another step why we need to keep the variance of the data. We'll

243
00:14:14.200 --> 00:14:15.300
 have to look at a second example.

244
00:14:15.900 --> 00:14:16.300
so first

245
00:14:17.300 --> 00:14:21.100
We will focus on visualizing understanding dimensionality

246
00:14:20.100 --> 00:14:21.500
 reduction.

247
00:14:22.600 --> 00:14:25.300
And the later on we'll look another example where we have a larger

248
00:14:25.300 --> 00:14:25.800
 data set.

249
00:14:26.300 --> 00:14:29.600
And a core variance Matrix is involved this example since it's

250
00:14:29.600 --> 00:14:30.700
 only two columns is too small.

251
00:14:31.600 --> 00:14:31.700
Okay.

252
00:14:32.900 --> 00:14:33.200
so let's

253
00:14:34.900 --> 00:14:37.400
See the principle. Excuse me.

254
00:14:37.400 --> 00:14:37.800
 Let's see the

255
00:14:39.300 --> 00:14:41.200
dimensionality reduction first and then we'll

256
00:14:43.200 --> 00:14:45.200
talk about covaries and correlation matrices.

257
00:14:47.300 --> 00:14:47.700
Okay.

258
00:14:52.500 --> 00:14:55.400
in order to visualize our first

259
00:14:55.400 --> 00:14:56.900
 principle component we will take

260
00:15:04.800 --> 00:15:06.200
s if you remember s was

261
00:15:09.300 --> 00:15:12.700
the okay. I did not run the celebration.

262
00:15:16.900 --> 00:15:18.200
No, I have to run it from the top.

263
00:15:18.900 --> 00:15:19.600
on all

264
00:15:23.800 --> 00:15:24.200
yeah, so

265
00:15:25.600 --> 00:15:26.900
is the eigenvector?

266
00:15:29.700 --> 00:15:32.300
And this is the largest principle component which will

267
00:15:32.300 --> 00:15:33.500
 be the first principal component.

268
00:15:34.200 --> 00:15:37.400
So in order to get the first principle compound, we will use index 0

269
00:15:38.300 --> 00:15:39.900
We will then multiply this by.

270
00:15:42.800 --> 00:15:45.500
The First Column of the Matrix U. So

271
00:15:45.500 --> 00:15:48.200
 again if we return to here to this

272
00:15:51.500 --> 00:15:52.000
writing

273
00:15:53.300 --> 00:15:55.600
If this is the Matrix U we're going to multiply this.

274
00:15:56.800 --> 00:15:59.900
principle component by the first principle Direction

275
00:16:03.300 --> 00:16:04.900
So I'm going to multiply this by U.

276
00:16:06.300 --> 00:16:07.700
I want all of the rows.

277
00:16:08.500 --> 00:16:08.800
from

278
00:16:09.700 --> 00:16:10.500
the first column

279
00:16:15.100 --> 00:16:15.700
if I run this

280
00:16:17.300 --> 00:16:18.700
I now have a linear transformation.

281
00:16:19.700 --> 00:16:21.000
we've gone from Matrix to

282
00:16:21.900 --> 00:16:22.500
a vector

283
00:16:26.800 --> 00:16:29.600
So this is the vector corresponding to

284
00:16:29.600 --> 00:16:30.800
 the first principle component.

285
00:16:33.600 --> 00:16:36.800
I plot this now if I go PLT.

286
00:16:37.200 --> 00:16:38.500
I have to code here by the way.

287
00:16:49.300 --> 00:16:49.900
plot

288
00:16:53.400 --> 00:16:54.500
principal component

289
00:16:59.700 --> 00:17:00.100
one

290
00:17:04.600 --> 00:17:07.200
So I'm going to pass this twice.

291
00:17:08.200 --> 00:17:10.200
And let's just call this pc14 by the way.

292
00:17:11.700 --> 00:17:12.600
PC one

293
00:17:15.900 --> 00:17:18.200
so the points on the both X and Y axis

294
00:17:18.200 --> 00:17:18.800
 will be PC one.

295
00:17:25.300 --> 00:17:26.900
It's a line that will go through the origin.

296
00:17:29.800 --> 00:17:30.700
And it will be linear.

297
00:17:33.200 --> 00:17:36.300
Where peace you want the components and pc1 are greater

298
00:17:36.300 --> 00:17:36.600
 than zero.

299
00:17:39.300 --> 00:17:42.100
I'm setting the X and Y limits to negative 5 to 5 for

300
00:17:42.100 --> 00:17:45.700
 both the X and Y axis because well the components of

301
00:17:45.700 --> 00:17:46.800
 the principal components.

302
00:17:47.700 --> 00:17:50.800
Grow from negative 4 to positive 4 so we

303
00:17:50.800 --> 00:17:52.300
 just want to make room two so we can see it.

304
00:17:57.100 --> 00:17:58.100
This is the result.

305
00:17:59.900 --> 00:18:01.100
of PCA

306
00:18:02.800 --> 00:18:04.400
we have taken those two dimensions.

307
00:18:06.400 --> 00:18:07.900
Which you can see we're quite spread.

308
00:18:11.200 --> 00:18:13.000
And we have combined both dimensions.

309
00:18:14.500 --> 00:18:16.900
We have combined both vectors into one vector.

310
00:18:17.700 --> 00:18:20.700
while keeping the variance while retaining

311
00:18:22.600 --> 00:18:24.100
a significant amount of the data

312
00:18:28.500 --> 00:18:31.000
if we do the same thing for the second principle component.

313
00:18:33.500 --> 00:18:36.200
You will see that it retains data, but not

314
00:18:36.200 --> 00:18:36.900
 as much as the first one.

315
00:18:41.800 --> 00:18:42.800
This is amazing because

316
00:18:47.100 --> 00:18:51.200
if there was any correlation if there's any significance any

317
00:18:50.200 --> 00:18:52.900
 significant relationship between the two first

318
00:18:53.700 --> 00:18:55.400
columns

319
00:18:58.800 --> 00:19:02.100
Well now the r let's say merged or

320
00:19:01.100 --> 00:19:03.200
 combined into one.

321
00:19:04.300 --> 00:19:04.800
into one

322
00:19:06.300 --> 00:19:09.500
Dimension so we've gone from two Dimensions to one dimension.

323
00:19:11.500 --> 00:19:14.400
This will become incredibly powerful, especially when we have a larger

324
00:19:14.400 --> 00:19:14.900
 data sets.

325
00:19:15.900 --> 00:19:19.100
We go, for example, 20 Dimensions or 15

326
00:19:18.100 --> 00:19:21.000
 Dimensions down to one or two

327
00:19:21.300 --> 00:19:24.000
 or three principal components making the job of a machine learning model.

328
00:19:24.700 --> 00:19:25.500
a lot easier

329
00:19:28.600 --> 00:19:31.800
now there's more to our discussions. So we haven't even gotten into

330
00:19:31.800 --> 00:19:32.500
 discussion of

331
00:19:33.200 --> 00:19:35.400
The covariance Matrix yet

332
00:19:36.100 --> 00:19:38.300
But we'll do that. Let's actually leave this here.

333
00:19:39.100 --> 00:19:42.100
For later reference. Hopefully you've understood what we mean by

334
00:19:42.100 --> 00:19:43.800
 dimensionality reduction.
