WEBVTT - This file was automatically generated by VIMEO

0
00:00:00.800 --> 00:00:02.100
Okay, here we go.

1
00:00:03.400 --> 00:00:06.600
So welcome to you all welcome to Session 9. This

2
00:00:06.600 --> 00:00:09.800
 is the last session of modules two and

3
00:00:09.800 --> 00:00:09.800
 three.

4
00:00:10.800 --> 00:00:11.500
and

5
00:00:14.400 --> 00:00:17.400
this is the last session before we get into neural networks on

6
00:00:17.400 --> 00:00:17.600
 Monday.

7
00:00:20.200 --> 00:00:22.000
in this session, our focus is going to be

8
00:00:24.600 --> 00:00:26.500
singular value decomposition

9
00:00:29.200 --> 00:00:31.400
Which according to one book?

10
00:00:33.800 --> 00:00:36.500
Some mathematicians call the jewel.

11
00:00:37.100 --> 00:00:39.800
of the linear algebra So today we're going to

12
00:00:44.900 --> 00:00:46.700
employ all of the well

13
00:00:48.200 --> 00:00:52.000
a lot of the linear algebra technique we've seen so far to

14
00:00:53.700 --> 00:00:55.900
perform this decomposition of a matrix.

15
00:00:57.400 --> 00:00:58.900
Let me write down the agenda.

16
00:01:00.600 --> 00:01:04.500
So today is the 16th. Yes of July 2022.

17
00:01:05.500 --> 00:01:06.500
before I continue

18
00:01:07.200 --> 00:01:08.600
the assignments

19
00:01:10.300 --> 00:01:13.700
for more there will be to us because we have two modules two and

20
00:01:13.700 --> 00:01:16.400
 three there will be two assignments for each module. These will

21
00:01:16.400 --> 00:01:18.700
 be posted on Monday.

22
00:01:19.500 --> 00:01:20.400
And they will be due.

23
00:01:23.500 --> 00:01:25.700
At the end of the third month the fourth module.

24
00:01:27.600 --> 00:01:30.500
And for the fourth module the assignment

25
00:01:30.500 --> 00:01:32.200
 will be due at the end of that module.

26
00:01:33.300 --> 00:01:34.500
If I pull up my calendar.

27
00:01:37.500 --> 00:01:39.600
Assignments two and three will be due.

28
00:01:44.100 --> 00:01:44.700
on Monday

29
00:01:46.100 --> 00:01:46.900
at 25th

30
00:01:49.500 --> 00:01:51.800
So the at the end of fourth module.

31
00:01:52.400 --> 00:01:54.000
and for module 4

32
00:01:55.900 --> 00:01:56.800
It will be.

33
00:01:58.400 --> 00:01:59.700
the first of August

34
00:02:02.200 --> 00:02:02.400
Okay.

35
00:02:03.300 --> 00:02:05.500
so you will have time to work on both these just

36
00:02:06.800 --> 00:02:08.100
If you asked like you'll be notified.

37
00:02:17.100 --> 00:02:17.400
Okay.

38
00:02:19.300 --> 00:02:21.500
Now, what are we doing today? Today? We are going to

39
00:02:23.500 --> 00:02:25.300
Put all our attention to SVD.

40
00:02:27.700 --> 00:02:28.500
so I'm going to

41
00:02:33.800 --> 00:02:35.800
start with a formulation for SVD.

42
00:02:37.700 --> 00:02:39.600
And then we're going to look at a full example.

43
00:02:42.100 --> 00:02:44.200
of singular value decompetition

44
00:02:45.400 --> 00:02:46.300
of some Matrix

45
00:02:50.600 --> 00:02:52.500
first we will do this with math.

46
00:02:54.200 --> 00:02:55.800
You know, like I always do in markdown.

47
00:02:56.700 --> 00:02:58.700
And then we will turn to do this with python.

48
00:03:05.700 --> 00:03:08.300
Well Done by to be specific now numpy

49
00:03:09.900 --> 00:03:10.100
has a

50
00:03:11.200 --> 00:03:13.100
method called SVD

51
00:03:14.100 --> 00:03:17.300
But before without just before we do that, we

52
00:03:17.300 --> 00:03:20.200
 want to see how the SVD method works. So

53
00:03:20.200 --> 00:03:22.500
 we will look at the implementation of

54
00:03:25.800 --> 00:03:28.100
SVD without using that method so

55
00:03:30.100 --> 00:03:32.300
You know not by has some other built-in methods that we will use.

56
00:03:33.400 --> 00:03:35.600
To replicate what the SVD method doesn't buy.

57
00:03:37.200 --> 00:03:39.900
Because we want to understand how it works before we just use it.

58
00:03:40.800 --> 00:03:41.600
out of the box

59
00:03:45.900 --> 00:03:48.400
I also want us to do an exercise on SVD. We

60
00:03:48.400 --> 00:03:49.700
 haven't really had the

61
00:03:51.100 --> 00:03:54.800
time to do exercises in the few

62
00:03:54.800 --> 00:03:56.600
 past few sessions because of just how much

63
00:03:57.500 --> 00:03:58.500
the content there is to cover.

64
00:03:59.800 --> 00:04:02.300
but we should be able to do this after we've covered items

65
00:04:02.300 --> 00:04:04.600
 to items wanted to

66
00:04:10.400 --> 00:04:12.200
and then I want to show you an application.

67
00:04:15.600 --> 00:04:16.600
of SVD

68
00:04:18.300 --> 00:04:18.400
so

69
00:04:20.100 --> 00:04:21.400
for PCA

70
00:04:22.900 --> 00:04:25.800
if we have time we can also talk about as PC but

71
00:04:25.800 --> 00:04:26.200
 next week.

72
00:04:28.400 --> 00:04:31.900
Or we start our session on new networks. We've

73
00:04:31.900 --> 00:04:35.200
 also talk about PCA because what

74
00:04:34.200 --> 00:04:37.600
 we're going to do is work on we will

75
00:04:37.600 --> 00:04:40.500
 import a data set. I'll give you data set that you will import into

76
00:04:40.500 --> 00:04:42.100
 your jupyter notebook.

77
00:04:42.900 --> 00:04:44.600
And then we will construct a neural network.

78
00:04:46.600 --> 00:04:47.300
that will

79
00:04:48.700 --> 00:04:49.200
learn

80
00:04:51.800 --> 00:04:51.800
the

81
00:04:53.800 --> 00:04:56.200
we call them the weights or the parameters of the data.

82
00:04:56.200 --> 00:04:59.200
 See if you have the data you learn the parameters you can

83
00:04:59.200 --> 00:05:00.100
 then make predictions.

84
00:05:01.300 --> 00:05:04.100
For future data, if you remember I give

85
00:05:04.100 --> 00:05:05.300
 you the example of Real Estate.

86
00:05:05.800 --> 00:05:08.200
So for example to show the machine learning model

87
00:05:08.200 --> 00:05:09.800
 700 properties.

88
00:05:10.600 --> 00:05:13.500
And they will learn the parameters the significance.

89
00:05:14.700 --> 00:05:15.000
of

90
00:05:15.800 --> 00:05:18.300
The factors that would cause a property

91
00:05:18.300 --> 00:05:20.300
 to be expensive or not expensive.

92
00:05:21.500 --> 00:05:24.800
And once it has learned the parameters what once

93
00:05:24.800 --> 00:05:25.600
 it has learned a pattern.

94
00:05:27.100 --> 00:05:30.100
The next time we will present to it a property it will be able

95
00:05:30.100 --> 00:05:30.600
 to estimate.

96
00:05:31.800 --> 00:05:35.400
Okay, and we want to build the

97
00:05:35.400 --> 00:05:38.600
 model in such a way that the prediction is also very accurate. Remember?

98
00:05:39.900 --> 00:05:40.900
on our session on

99
00:05:42.300 --> 00:05:46.100
Wednesday we said that there are four forecasting a

100
00:05:45.100 --> 00:05:46.300
 price.

101
00:05:47.200 --> 00:05:50.300
For this particular example, there are two metrics that

102
00:05:50.300 --> 00:05:53.100
 we want to look at errors, which you want to converge to

103
00:05:53.100 --> 00:05:53.300
 0.

104
00:05:54.200 --> 00:05:56.500
And something called r squared what you wanted to converge to 1.

105
00:06:00.000 --> 00:06:00.800
so

106
00:06:02.500 --> 00:06:05.200
that's the kind of model. We want to create a model that will have

107
00:06:05.200 --> 00:06:08.500
 a very small error close to zero and a high

108
00:06:08.500 --> 00:06:09.100
 r squared.

109
00:06:10.900 --> 00:06:13.100
That will be the first instance in the next instance. We will

110
00:06:13.100 --> 00:06:14.500
 look at a data that's going to be very large.

111
00:06:15.400 --> 00:06:18.200
And for that large that we will use PCA and I'll give

112
00:06:18.200 --> 00:06:19.500
 you one example for finance.

113
00:06:20.300 --> 00:06:23.400
For SVD if we don't if I don't manage to

114
00:06:23.400 --> 00:06:23.800
 do it.

115
00:06:25.500 --> 00:06:28.800
Today because there are still something about techniques

116
00:06:28.800 --> 00:06:31.400
 we haven't talked about. So if I don't manage to do that today, I

117
00:06:31.400 --> 00:06:32.300
 will give you a notebook.

118
00:06:32.900 --> 00:06:33.000
for

119
00:06:34.600 --> 00:06:36.300
image compression

120
00:06:38.200 --> 00:06:42.100
if you remember the slides, I I mentioned at least three applications

121
00:06:41.100 --> 00:06:42.300
 of

122
00:06:43.100 --> 00:06:46.000
PCA which is a special type of SVD.

123
00:06:46.900 --> 00:06:49.300
Specific case of SVD and that was computer vision

124
00:06:49.300 --> 00:06:51.700
 image compression falls on the computer version.

125
00:06:52.400 --> 00:06:54.500
there was dimensional reduction and there was

126
00:06:55.700 --> 00:06:58.500
stock protection. So we're going to look at all three of these examples.

127
00:06:59.600 --> 00:07:02.100
Next week not a decision. So this

128
00:07:02.100 --> 00:07:05.200
 these two modules out we've gone

129
00:07:05.200 --> 00:07:06.900
 through was all about the mathematics.

130
00:07:07.800 --> 00:07:10.900
Of these techniques and of course,

131
00:07:10.900 --> 00:07:14.400
 we also looked at pythonoplepitations, but

132
00:07:13.400 --> 00:07:15.200
 actually it's going to be all.

133
00:07:16.300 --> 00:07:19.800
It's gonna be primarily python next week. So tensorflow

134
00:07:19.800 --> 00:07:20.800
 numpy.

135
00:07:24.700 --> 00:07:25.800
pandas

136
00:07:27.400 --> 00:07:30.600
we might use psychic learn but for

137
00:07:31.900 --> 00:07:34.900
The statistical Parts. But anyway, we'll

138
00:07:34.900 --> 00:07:36.400
 talk about people talk about that on Monday.

139
00:07:38.300 --> 00:07:39.600
What was number five?

140
00:07:40.600 --> 00:07:43.100
Yes, and we make a reference to PCA.

141
00:07:45.200 --> 00:07:47.000
Okay time allows it. Very good.

142
00:07:50.500 --> 00:07:53.800
So I'm going to create a new markdown file.

143
00:08:02.300 --> 00:08:04.700
Which you will call 15.

144
00:08:08.600 --> 00:08:10.200
so math tutorial 15

145
00:08:11.300 --> 00:08:13.700
or singular value decomposition

146
00:08:23.100 --> 00:08:26.300
I'm going to zoom out so you can see everything on the right panically.

147
00:08:28.800 --> 00:08:30.700
and we're gonna have to put on my glasses because

148
00:08:32.900 --> 00:08:35.100
I want this too small, but and we

149
00:08:35.100 --> 00:08:36.400
 need I need the space here.

150
00:08:37.300 --> 00:08:37.800
All right.

151
00:08:38.800 --> 00:08:39.000
now

152
00:08:41.500 --> 00:08:42.800
the example I'm going to give you.

153
00:08:45.300 --> 00:08:46.100
Is based on?

154
00:08:50.200 --> 00:08:50.500
at least

155
00:08:51.900 --> 00:08:54.200
three books because I could not

156
00:08:54.200 --> 00:08:57.900
 find one book though clearly explain SVD

157
00:08:58.500 --> 00:09:00.100
with all of the techniques required

158
00:09:01.700 --> 00:09:04.400
I'll give you the references of course, but let's begin with

159
00:09:04.400 --> 00:09:06.300
 a simple two by two Matrix.

160
00:09:07.300 --> 00:09:10.300
And the simple two by two Matrix is this one?

161
00:09:13.700 --> 00:09:16.200
This is one of the books that are that I'll

162
00:09:16.200 --> 00:09:17.800
 be referencing. This is It's called.

163
00:09:18.600 --> 00:09:20.500
linear algebra for the 21st century

164
00:09:21.800 --> 00:09:24.400
If you can see it anyway, the references will be in the file.

165
00:09:24.400 --> 00:09:27.600
 I'll share with you and SVD is a major component.

166
00:09:27.600 --> 00:09:29.700
 Like it's a central piece of this book.

167
00:09:31.100 --> 00:09:34.600
But the book doesn't go into the prerequisite enough.

168
00:09:34.600 --> 00:09:37.400
 So you cannot learn from this book anyway.

169
00:09:40.200 --> 00:09:44.300
You can look at this book later on after this Workshop. So let's

170
00:09:43.300 --> 00:09:45.500
 say we have this Matrix.

171
00:09:51.100 --> 00:09:52.600
a simple two by two Matrix

172
00:09:54.700 --> 00:09:57.200
we have a and then we also pull up my notes so

173
00:09:57.200 --> 00:09:58.300
 we can I can copy paste.

174
00:09:59.500 --> 00:10:01.000
latex

175
00:10:02.300 --> 00:10:03.100
Very quickly.

176
00:10:09.800 --> 00:10:10.400
We have a

177
00:10:13.100 --> 00:10:14.200
2 by 2 Matrix

178
00:10:17.100 --> 00:10:18.100
which we will call a

179
00:10:19.900 --> 00:10:20.100
and

180
00:10:29.200 --> 00:10:30.700
let me construct The Matrix.

181
00:10:32.600 --> 00:10:33.100
Here we go.

182
00:10:56.700 --> 00:10:59.500
This will be equal to 10 to 5

183
00:10:59.500 --> 00:10:59.700
 11.

184
00:11:01.500 --> 00:11:02.200
10 2

185
00:11:03.200 --> 00:11:03.600
5

186
00:11:05.000 --> 00:11:05.400
11

187
00:11:06.800 --> 00:11:06.900
now

188
00:11:09.200 --> 00:11:12.600
to decompose this Matrix is to create

189
00:11:12.600 --> 00:11:14.800
 three matrices that look like so

190
00:11:17.700 --> 00:11:18.500
so a

191
00:11:20.400 --> 00:11:22.500
will be factored into three matrices.

192
00:11:24.200 --> 00:11:24.900
There will be a

193
00:11:27.400 --> 00:11:28.000
there will be

194
00:11:29.300 --> 00:11:30.400
us and V

195
00:11:32.400 --> 00:11:33.400
you snv

196
00:11:35.800 --> 00:11:36.800
so we have you.

197
00:11:38.400 --> 00:11:39.600
times s

198
00:11:40.700 --> 00:11:43.100
times V which is transposed

199
00:11:46.400 --> 00:11:47.400
What are these matrices?

200
00:11:50.600 --> 00:11:53.800
you

201
00:12:02.400 --> 00:12:03.600
Is an M by m?

202
00:12:06.200 --> 00:12:09.400
Diagonal matrix orthogonal Matrix now I

203
00:12:09.400 --> 00:12:13.400
 will need to clarify what orthogonalism

204
00:12:12.400 --> 00:12:16.100
 north orthonormalists towards uniform

205
00:12:15.100 --> 00:12:16.600
 my last session.

206
00:12:17.400 --> 00:12:19.800
When I looked up of the normal on Google.

207
00:12:22.100 --> 00:12:22.700
the first

208
00:12:24.800 --> 00:12:27.300
couple of search results said that they are

209
00:12:27.300 --> 00:12:27.600
 synonymous.

210
00:12:29.200 --> 00:12:30.700
I suspected they were not but I

211
00:12:31.400 --> 00:12:34.300
mmm changed my change my agenda here.

212
00:12:35.100 --> 00:12:37.100
To make it as if they're the same they are not the same.

213
00:12:38.200 --> 00:12:41.300
okay, there's a reason why they have different names, so I'm

214
00:12:41.300 --> 00:12:41.500
 going to

215
00:12:42.600 --> 00:12:45.600
In a moment go over orthogonal Matrix

216
00:12:45.600 --> 00:12:48.200
 and then tell you how it's distinct from

217
00:12:48.200 --> 00:12:49.200
 Ocean normal Matrix.

218
00:12:50.700 --> 00:12:53.100
I said in the past, you know not

219
00:12:53.100 --> 00:12:54.600
 to use Google for technical reference.

220
00:12:55.800 --> 00:12:56.800
and once again

221
00:13:00.200 --> 00:13:03.000
You know, I found that what was online is incorrect.

222
00:13:04.200 --> 00:13:08.400
So I shouldn't have checked that anyway, so you is

223
00:13:07.400 --> 00:13:10.200
 a is an orthogonal Matrix.

224
00:13:11.800 --> 00:13:14.300
Now this book called the orthogonal.

225
00:13:16.000 --> 00:13:16.200
but

226
00:13:17.700 --> 00:13:21.000
you see the problem is some mathematical literature use

227
00:13:20.800 --> 00:13:23.900
 orthogonal and orthonormal synonymously or

228
00:13:23.900 --> 00:13:26.100
 as they're not the same thing. So I'm going to call this.

229
00:13:28.600 --> 00:13:31.100
If I remember collected correctly, this should be

230
00:13:31.100 --> 00:13:32.100
 an orthonormal.

231
00:13:34.600 --> 00:13:35.800
normal, okay, but

232
00:13:37.200 --> 00:13:38.800
This is called orthogonal because I don't want to.

233
00:13:39.700 --> 00:13:42.200
Make any mistakes here. This would be consistent

234
00:13:42.200 --> 00:13:42.500
 and then

235
00:13:46.500 --> 00:13:49.100
if it turns out to be orthograph of the normal and this example,

236
00:13:49.100 --> 00:13:50.800
 I will change it here.

237
00:13:51.500 --> 00:13:52.200
Then we have S.

238
00:13:57.400 --> 00:14:00.300
S is a matrix containing is a

239
00:14:00.300 --> 00:14:01.000
 diagonal matrix.

240
00:14:02.100 --> 00:14:03.600
Is a diagonal matrix?

241
00:14:06.300 --> 00:14:08.400
containing singular values

242
00:14:10.500 --> 00:14:11.800
the singular values of

243
00:14:12.700 --> 00:14:12.900
a

244
00:14:14.100 --> 00:14:16.000
matrix which is not denoted here.

245
00:14:17.300 --> 00:14:18.500
We will see that in a minute.

246
00:14:19.200 --> 00:14:22.400
And the diagonal matrix containing or of the singular

247
00:14:22.400 --> 00:14:22.800
 values.

248
00:14:23.600 --> 00:14:26.400
By singular values, we mean the eigenvalues.

249
00:14:31.300 --> 00:14:33.700
And then the V Matrix or V transpose?

250
00:14:39.900 --> 00:14:42.000
Is also an orthogonal Matrix or I should

251
00:14:42.100 --> 00:14:42.600
 say V here?

252
00:14:43.400 --> 00:14:45.900
V transpose is also an orthogonal Matrix.

253
00:14:50.100 --> 00:14:52.600
The first one is actually M and by m

254
00:14:55.800 --> 00:14:57.300
and the other one is n by n

255
00:15:07.400 --> 00:15:08.500
and a itself

256
00:15:21.600 --> 00:15:24.200
Is an Empire is an M by n Matrix, so

257
00:15:24.200 --> 00:15:27.100
 it doesn't have to be square in this example a is a square

258
00:15:27.100 --> 00:15:31.700
 Matrix, but you can perform SVD on Rick on

259
00:15:31.700 --> 00:15:32.700
 any rectangular Matrix.

260
00:15:33.600 --> 00:15:34.100
is

261
00:15:36.700 --> 00:15:37.600
and then buy it.

262
00:15:38.400 --> 00:15:39.000
Matrix

263
00:15:41.600 --> 00:15:42.000
Okay.

264
00:15:46.400 --> 00:15:49.000
So I would be the number of rows and would be the number of columns.

265
00:15:51.600 --> 00:15:55.000
We want to see how we can decompose this now to

266
00:15:54.500 --> 00:15:58.000
 decompose this if we have a free perform SVD

267
00:15:57.200 --> 00:15:58.600
 on this Matrix.

268
00:15:59.300 --> 00:15:59.900
We would get.

269
00:16:01.500 --> 00:16:02.900
u s v

270
00:16:04.100 --> 00:16:04.900
Which will be equal to?

271
00:16:06.500 --> 00:16:07.100
the following

272
00:16:08.700 --> 00:16:11.500
so you would be let me copy this

273
00:16:11.500 --> 00:16:11.900
 snippet.

274
00:16:22.800 --> 00:16:25.600
Three over five I'll use decimal notation.

275
00:16:25.600 --> 00:16:27.200
 So three or five is 0.6.

276
00:16:28.900 --> 00:16:29.500
This would be

277
00:16:31.400 --> 00:16:32.400
negative 0.8

278
00:16:34.700 --> 00:16:37.800
0.8 and zero point

279
00:16:38.800 --> 00:16:39.000
six

280
00:16:40.400 --> 00:16:41.400
That's the Matrix U.

281
00:16:42.300 --> 00:16:45.200
Then we have the Matrix S which will contain

282
00:16:45.200 --> 00:16:47.400
 the singular values or eigenvalues?

283
00:16:49.200 --> 00:16:50.600
So this is 10 times.

284
00:16:51.700 --> 00:16:54.500
The square root of 2 what is 10 times square the

285
00:16:54.500 --> 00:16:55.100
 square root of 2?

286
00:16:56.100 --> 00:16:57.900
10 times the square root of

287
00:16:59.200 --> 00:17:00.400
2 so that's 2 to the power.

288
00:17:01.900 --> 00:17:04.400
0.5 14

289
00:17:09.400 --> 00:17:10.100
okay, I'm just going to

290
00:17:13.800 --> 00:17:16.000
on the up to the two decimal places

291
00:17:16.800 --> 00:17:19.200
then we have zero and then zero.

292
00:17:20.200 --> 00:17:23.500
And then five times the power square root

293
00:17:23.500 --> 00:17:23.700
 of 2.

294
00:17:24.200 --> 00:17:25.300
so 5 times

295
00:17:26.900 --> 00:17:28.500
the square root of 2

296
00:17:31.100 --> 00:17:33.700
So 7 7.077 point?

297
00:17:34.800 --> 00:17:35.400
zero seven

298
00:17:37.100 --> 00:17:39.600
That's the Matrix S. So these are the singular values.

299
00:17:41.700 --> 00:17:41.900
Okay.

300
00:17:42.900 --> 00:17:45.600
Now we'll talk about why this particular metric

301
00:17:45.600 --> 00:17:46.600
 is so important.

302
00:17:48.200 --> 00:17:50.900
And then we have V transpose, which is in this case.

303
00:17:56.200 --> 00:17:57.700
One over the square root of two.

304
00:17:59.400 --> 00:18:00.100
so one over

305
00:18:02.500 --> 00:18:03.600
two to the power

306
00:18:04.300 --> 00:18:06.400
0.70

307
00:18:08.300 --> 00:18:08.900
for all of that

308
00:18:18.100 --> 00:18:19.000
This one is negative.

309
00:18:28.500 --> 00:18:31.000
Has anyone looked up SVD before

310
00:18:31.700 --> 00:18:31.800
 this session?

311
00:18:35.300 --> 00:18:38.600
If you've already had a look at it, if you try to read about

312
00:18:38.600 --> 00:18:41.100
 it beforehand just talked a little while in the chat. Why

313
00:18:41.100 --> 00:18:42.500
 for? Yes, otherwise type in Inferno.

314
00:18:51.600 --> 00:18:53.500
How about you rest in Cuba?

315
00:18:54.400 --> 00:18:56.600
Have you looked at look into SPD before this session?

316
00:19:10.600 --> 00:19:11.200
Yes or no?

317
00:19:17.100 --> 00:19:18.000
Okay, no response.

318
00:19:20.700 --> 00:19:23.400
the name of the book the name of the book see if

319
00:19:23.400 --> 00:19:24.100
 I pull up the

320
00:19:25.700 --> 00:19:26.500
the references

321
00:19:28.500 --> 00:19:29.400
these are the books.

322
00:19:38.800 --> 00:19:41.100
Rancis is in theory. Okay. So these are

323
00:19:41.100 --> 00:19:45.400
 the books that I've referenced.

324
00:19:49.700 --> 00:19:52.200
so this one that we're talking about is

325
00:19:52.200 --> 00:19:52.800
 actually

326
00:19:54.300 --> 00:19:54.700
eight

327
00:19:56.200 --> 00:19:59.600
I need to see which page it is exactly, but it's

328
00:19:59.600 --> 00:20:00.100
 chapter 7.

329
00:20:01.700 --> 00:20:04.600
But not exactly because I am not just a copy

330
00:20:04.600 --> 00:20:07.500
 pasting the material. I'm

331
00:20:07.500 --> 00:20:10.000
 adding more comments. I'm expanding on it. So this is

332
00:20:10.200 --> 00:20:13.200
 actually two things. It's a book number eight.

333
00:20:13.900 --> 00:20:15.200
Which is the one from Strang?

334
00:20:16.100 --> 00:20:16.300
and

335
00:20:18.300 --> 00:20:19.600
the other one which is

336
00:20:22.300 --> 00:20:25.300
which is that which is a program copying this example AJ Roberts.

337
00:20:26.500 --> 00:20:27.000
a

338
00:20:28.200 --> 00:20:29.000
Dr. Roberts

339
00:20:35.400 --> 00:20:38.200
Leaning algebra for the 21st century linear algebra.

340
00:20:47.200 --> 00:20:50.700
And these dot dots I put here because I need to properly format the

341
00:20:50.700 --> 00:20:51.300
 references.

342
00:20:52.100 --> 00:20:55.300
Include, you know to include a public publisher name

343
00:20:55.300 --> 00:20:56.800
 and addition number.

344
00:20:57.400 --> 00:21:00.300
Number six I think was an online Source. That's why I haven't tapped it.

345
00:21:00.900 --> 00:21:02.300
But you'll have access to all of these.

346
00:21:03.300 --> 00:21:06.000
the thing is you cannot learn from one book only you need to

347
00:21:10.200 --> 00:21:13.600
you might see one term or one Concept in one book, but it

348
00:21:13.600 --> 00:21:15.400
 doesn't go into details. I have to look into another book.

349
00:21:16.700 --> 00:21:18.400
This one was very important the third one.

350
00:21:19.400 --> 00:21:22.100
This is a

351
00:21:22.100 --> 00:21:25.800
 very intuitive approach to teaching linear

352
00:21:25.800 --> 00:21:28.800
 algebra. So if you want a good foundation.

353
00:21:30.300 --> 00:21:33.300
In linear algebra, I highly recommend you getting this book.

354
00:21:35.300 --> 00:21:38.000
Hey, we just search those terms. You will find it on Amazon.

355
00:21:39.200 --> 00:21:39.900
Okay, let's return here.

356
00:21:40.900 --> 00:21:43.600
So this is based on a book number eight and book

357
00:21:43.600 --> 00:21:44.100
 number nine.

358
00:21:45.700 --> 00:21:46.600
Which is on page?

359
00:21:48.500 --> 00:21:49.300
193

360
00:21:51.300 --> 00:21:51.600
okay.

361
00:21:58.400 --> 00:21:59.900
So let me break down the steps for you.

362
00:22:00.900 --> 00:22:02.400
How we can go from this?

363
00:22:03.700 --> 00:22:06.500
To that. There's quite

364
00:22:06.500 --> 00:22:08.300
 a bit of work involved here.

365
00:22:09.500 --> 00:22:12.100
But then once we understand the steps, we can

366
00:22:12.100 --> 00:22:13.400
 apply these steps to any.

367
00:22:14.300 --> 00:22:15.000
Matrix

368
00:22:16.300 --> 00:22:17.600
and then we could

369
00:22:18.400 --> 00:22:20.700
Do image compression we could extract?

370
00:22:27.900 --> 00:22:30.500
You know, if you remember we talked about PC that

371
00:22:30.500 --> 00:22:31.700
 the principal components.

372
00:22:32.600 --> 00:22:34.600
for dimensional reduction, so

373
00:22:36.300 --> 00:22:38.500
all of the applications of SVD would be

374
00:22:39.100 --> 00:22:40.000
available to us

375
00:22:42.500 --> 00:22:45.300
let me show you one example just to keep just make it interesting

376
00:22:45.300 --> 00:22:46.400
 before we jump into the

377
00:22:49.500 --> 00:22:52.300
the work of it decomposing. I'm gonna type

378
00:22:52.300 --> 00:22:53.600
 an SVD image.

379
00:22:54.300 --> 00:22:55.000
compression

380
00:22:58.100 --> 00:23:01.300
Just let me show you the images. So there is

381
00:23:01.300 --> 00:23:03.400
 something called a rank of a matrix and I'll show you how to.

382
00:23:04.700 --> 00:23:05.800
a rank of Matrix

383
00:23:07.700 --> 00:23:08.400
but you can

384
00:23:13.500 --> 00:23:14.500
compress an image

385
00:23:16.300 --> 00:23:20.900
to compress an image means to retain the important qualities of

386
00:23:20.900 --> 00:23:21.400
 a picture.

387
00:23:22.300 --> 00:23:25.100
And discard the qualities that are rest relevant so that

388
00:23:25.100 --> 00:23:29.300
 you can reduce the size of the file without losing

389
00:23:28.300 --> 00:23:31.100
 the entropy entropy means the

390
00:23:31.100 --> 00:23:34.000
 quality or the the value of

391
00:23:34.100 --> 00:23:34.400
 the message.

392
00:23:35.500 --> 00:23:38.500
Now with an SVD algorithm which will I'll show

393
00:23:38.500 --> 00:23:41.200
 you in one I will show you SVD adapted for image

394
00:23:41.200 --> 00:23:44.400
 compression you can choose the rank the higher the

395
00:23:44.400 --> 00:23:46.600
 rank the closer the

396
00:23:47.400 --> 00:23:48.900
compressed images to the original

397
00:23:51.600 --> 00:23:52.600
let's take another example.

398
00:23:54.300 --> 00:23:56.100
Let's say this one.

399
00:24:08.200 --> 00:24:14.700
Where is

400
00:24:14.700 --> 00:24:14.900
 that picture?

401
00:24:17.300 --> 00:24:18.600
It's not clear enough.

402
00:24:19.700 --> 00:24:22.700
I think you already get the idea but let's here's another

403
00:24:22.700 --> 00:24:24.000
 example right you have an image.

404
00:24:25.200 --> 00:24:26.500
That is 40k.

405
00:24:30.100 --> 00:24:33.700
Now you can compress it. Now. This is not a high

406
00:24:33.700 --> 00:24:36.400
 quality compression, but you can increase or

407
00:24:36.400 --> 00:24:39.700
 decrease the rank. You can choose to keep more or

408
00:24:39.700 --> 00:24:41.100
 less of the singular values.

409
00:24:42.400 --> 00:24:42.800
and

410
00:24:44.200 --> 00:24:46.200
You know, I can adjust it accordingly. So if you want.

411
00:24:46.900 --> 00:24:48.100
very high compression

412
00:24:51.600 --> 00:24:54.300
So if you have a picture that doesn't have that has

413
00:24:54.300 --> 00:24:56.100
 a lot of contrast and not much gradient.

414
00:24:56.900 --> 00:24:59.400
And there are the outlines are very clear. You can

415
00:24:59.400 --> 00:25:02.400
 use very high compression so you can significantly reduce

416
00:25:02.400 --> 00:25:03.100
 image size.

417
00:25:04.100 --> 00:25:07.200
In cases like this where you do have a lot of different Shades of Gray a lot

418
00:25:07.200 --> 00:25:08.600
 of gradient. You may need a more.

419
00:25:09.200 --> 00:25:12.600
A higher ranked compressed Matrix. Well, my

420
00:25:12.600 --> 00:25:15.900
 point is you can accomplish this so we can actually compress images and

421
00:25:15.900 --> 00:25:17.100
 retain much of the value.

422
00:25:18.600 --> 00:25:21.200
One example where this

423
00:25:21.200 --> 00:25:23.800
 is is relevant isn't computer vision.

424
00:25:24.400 --> 00:25:26.500
If you want to training machine learning model to detect.

425
00:25:27.300 --> 00:25:27.900
footage

426
00:25:28.500 --> 00:25:31.300
or detect the contents in

427
00:25:31.300 --> 00:25:33.400
 a computer in a picture or a video.

428
00:25:35.700 --> 00:25:37.500
Well a video is a sequence of pictures.

429
00:25:38.300 --> 00:25:40.300
If the video side is very large then.

430
00:25:41.400 --> 00:25:44.000
It will take a long time for the model to predict.

431
00:25:46.600 --> 00:25:49.300
What's going on that picture whereas if you compress the image?

432
00:25:50.600 --> 00:25:53.100
The data is a lot smaller. And that means

433
00:25:53.100 --> 00:25:56.000
 the model will be a lot quicker to detect what's inside the picture.

434
00:25:58.200 --> 00:26:00.200
So it has applications in storage.

435
00:26:01.200 --> 00:26:05.600
It also has a applications and live prediction

436
00:26:04.600 --> 00:26:07.800
 like in the case of autonomous car.

437
00:26:08.600 --> 00:26:11.400
Autonomous vehicles need to are getting

438
00:26:11.400 --> 00:26:14.600
 fed data from the cameras and they need to make decisions quickly.

439
00:26:15.500 --> 00:26:15.700
So

440
00:26:16.800 --> 00:26:18.600
this is what example where it might be very helpful.

441
00:26:21.400 --> 00:26:21.700
All right.

442
00:26:22.800 --> 00:26:25.200
But let's see how this is done. Let's look at the mathematics and we

443
00:26:25.200 --> 00:26:26.000
 will return to the application.

444
00:26:27.600 --> 00:26:30.200
So step one. Let me first write down the steps and

445
00:26:30.200 --> 00:26:32.400
 then we'll perform the mathematics.

446
00:26:33.100 --> 00:26:34.400
and for this I will return to

447
00:26:35.600 --> 00:26:36.900
Gilbert strang's book

448
00:26:39.400 --> 00:26:41.300
Now this is chapter 7.

449
00:26:44.700 --> 00:26:46.200
and specifically page

450
00:26:47.100 --> 00:26:47.800
383

451
00:26:55.300 --> 00:26:55.400
3

452
00:26:57.400 --> 00:26:58.700
So step one.

453
00:27:17.200 --> 00:27:19.800
For step one we need to take the product.

454
00:27:21.100 --> 00:27:22.600
of a and its transpose

455
00:27:26.300 --> 00:27:26.800
so product

456
00:27:28.100 --> 00:27:28.500
of

457
00:27:36.900 --> 00:27:38.400
a and its transpose

458
00:27:43.800 --> 00:27:44.900
so that's a times.

459
00:27:53.200 --> 00:27:54.500
transpose of a times a

460
00:27:56.600 --> 00:27:57.700
transpose of a

461
00:27:59.100 --> 00:28:01.300
transpose of a times a

462
00:28:06.400 --> 00:28:07.300
and then we do this again.

463
00:28:11.300 --> 00:28:14.200
for a times the trans the transpose of a

464
00:28:24.800 --> 00:28:27.600
Why do you do this? Because once we have these two matrices

465
00:28:27.600 --> 00:28:31.900
 who will then be able to extract the eigenvalues, but

466
00:28:31.900 --> 00:28:33.900
 when we do extract the eigenvalues?

467
00:28:35.700 --> 00:28:38.000
We need to take the square root. So step three.

468
00:28:40.400 --> 00:28:41.200
We want to calculate.

469
00:28:46.900 --> 00:28:50.400
The eigenvalues if you like the single the singular values singular.

470
00:28:52.800 --> 00:28:54.200
values for

471
00:28:55.300 --> 00:28:56.300
steps one and two

472
00:28:59.600 --> 00:29:02.500
four steps one and to order matrices

473
00:29:03.200 --> 00:29:05.100
we generate in steps 1 and 2.

474
00:29:07.500 --> 00:29:10.400
Once you have those singular values, we need to take the

475
00:29:10.400 --> 00:29:13.400
 square root of those angular of those singular values.

476
00:29:14.300 --> 00:29:16.400
Okay, so calculate square root.

477
00:29:19.400 --> 00:29:20.600
of singular values

478
00:29:24.400 --> 00:29:27.400
once we have done this we have then we will have then created

479
00:29:27.400 --> 00:29:28.300
 the

480
00:29:30.500 --> 00:29:31.000
Matrix S

481
00:29:34.400 --> 00:29:35.300
And what about Matrix?

482
00:29:36.900 --> 00:29:38.900
You and V transpose.

483
00:29:39.700 --> 00:29:43.400
to calculate or Define this Matrix we

484
00:29:42.400 --> 00:29:43.800
 need to

485
00:29:47.500 --> 00:29:48.700
orthogonalize

486
00:29:51.700 --> 00:29:52.700
this Matrix

487
00:29:54.900 --> 00:29:57.600
and then orthogonalize that Matrix.

488
00:29:59.300 --> 00:30:00.600
or the transpose

489
00:30:01.400 --> 00:30:04.300
so this we will orthogonalize it and what is

490
00:30:04.300 --> 00:30:06.000
 orthogonalized real content one in a moment?

491
00:30:06.500 --> 00:30:09.100
We need to orthogonize orthogonalize this to get

492
00:30:09.100 --> 00:30:10.100
 that Matrix.

493
00:30:11.700 --> 00:30:14.600
And then orthogonize this Matrix to get that

494
00:30:14.600 --> 00:30:15.200
 Matrix.

495
00:30:16.300 --> 00:30:19.700
Now there are different algorithms for orthogonalization.

496
00:30:21.500 --> 00:30:24.200
Okay, I'll tell you I'll describe to you the

497
00:30:24.200 --> 00:30:26.200
 problems of an orthogonal and orthonormal Matrix.

498
00:30:27.200 --> 00:30:31.300
But there are different algorithms for orthogonalizing making

499
00:30:30.300 --> 00:30:32.400
 whatever this Matrix is.

500
00:30:33.800 --> 00:30:36.400
The one we're going to look at is going to is called a

501
00:30:36.400 --> 00:30:37.100
 gram Schmidt.

502
00:30:37.600 --> 00:30:38.300
algorithm

503
00:30:40.300 --> 00:30:43.500
which is also supported by numpy and

504
00:30:43.500 --> 00:30:43.700
 even

505
00:30:45.100 --> 00:30:48.500
well, not that algorithm specifically, I think the ones

506
00:30:48.500 --> 00:30:51.600
 numpy and Matlab support are

507
00:30:51.600 --> 00:30:54.600
 called a QR but these are both similar.

508
00:30:55.600 --> 00:30:56.200
In what they do.

509
00:30:56.800 --> 00:30:57.600
They both produce.

510
00:30:58.400 --> 00:30:59.500
an orthogonal Matrix

511
00:31:00.500 --> 00:31:02.300
now before let me just write down the steps.

512
00:31:05.800 --> 00:31:07.500
and once we get to that step we will

513
00:31:08.500 --> 00:31:11.400
We'll talk about orthogonal matrices. So step

514
00:31:11.400 --> 00:31:11.600
 5.

515
00:31:14.200 --> 00:31:15.600
We will also.

516
00:31:16.800 --> 00:31:19.100
Gonna lies make sure

517
00:31:19.100 --> 00:31:21.300
 God is very much thought. Oh, no.

518
00:31:22.300 --> 00:31:22.900
nice

519
00:31:25.300 --> 00:31:26.000
Matrix

520
00:31:28.500 --> 00:31:29.300
Matrix

521
00:31:30.600 --> 00:31:31.300
in Step One

522
00:31:36.900 --> 00:31:39.200
orthoglas The Matrix and step one

523
00:31:45.500 --> 00:31:46.200
well, let me just

524
00:31:47.800 --> 00:31:48.400
write down.

525
00:31:50.500 --> 00:31:50.900
the product

526
00:31:55.900 --> 00:31:57.200
so you'll orthogonalize this.

527
00:32:03.500 --> 00:32:05.900
And we'll do the same four step number six.

528
00:32:21.600 --> 00:32:24.200
Now these steps are not written anywhere. I am basically going over

529
00:32:24.200 --> 00:32:26.100
 the book here.

530
00:32:27.100 --> 00:32:27.900
This is the book.

531
00:32:30.100 --> 00:32:32.600
So I'm breaking down the steps by looking at the steps here.

532
00:32:34.400 --> 00:32:36.500
Okay. I'm trying to simplify for you.

533
00:32:39.400 --> 00:32:41.600
We're not doing this Matrix. We're doing the one here.

534
00:32:42.400 --> 00:32:43.500
This we can do as an exercise.

535
00:32:47.100 --> 00:32:47.900
Let me come back here.

536
00:32:50.900 --> 00:32:52.900
then once we have done this

537
00:32:54.300 --> 00:32:57.500
Yeah, we would have been we have we would have had a produced SVD.

538
00:32:59.000 --> 00:32:59.600
Okay.

539
00:33:01.500 --> 00:33:04.000
What we haven't covered yet is orthogonalization.

540
00:33:08.900 --> 00:33:11.700
And some terms associated

541
00:33:11.700 --> 00:33:13.700
 with this technique like the rank of a matrix.

542
00:33:14.400 --> 00:33:17.600
But let's talk about that once we get to step step 5

543
00:33:17.600 --> 00:33:18.000
 and 6.

544
00:33:23.800 --> 00:33:26.000
so the product of ATA

545
00:33:28.200 --> 00:33:29.600
that's where you multiply

546
00:33:30.900 --> 00:33:33.400
This Matrix Ms. Transpose. You remember

547
00:33:33.400 --> 00:33:37.000
 what a transposes a transpose is. When where The

548
00:33:36.300 --> 00:33:38.400
 Columns of The Matrix?

549
00:33:39.200 --> 00:33:42.400
Become the rows of the Matrix. So here

550
00:33:42.400 --> 00:33:45.200
 a if we were if I were to copy this.

551
00:33:49.300 --> 00:33:52.100
That would give us the original Matrix we have up here.

552
00:34:00.500 --> 00:34:00.900
times

553
00:34:02.500 --> 00:34:05.600
The same Matrix but it's rows and columns have been swapped.

554
00:34:05.600 --> 00:34:06.600
 So this will be 10 5.

555
00:34:07.800 --> 00:34:09.400
And then two 11 so 10 5.

556
00:34:11.700 --> 00:34:12.300
and 2

557
00:34:13.400 --> 00:34:13.900
11

558
00:34:16.600 --> 00:34:16.800
okay.

559
00:34:20.100 --> 00:34:22.500
Now to multiply these out.

560
00:34:23.200 --> 00:34:25.600
I'm actually going to use numpy because I don't want to.

561
00:34:26.400 --> 00:34:27.300
Do this by hand?

562
00:34:28.100 --> 00:34:29.100
So I will come to.

563
00:34:30.800 --> 00:34:31.700
I'll go to colab.

564
00:34:39.300 --> 00:34:40.400
I will create.

565
00:34:43.400 --> 00:34:44.400
a new notebook

566
00:34:57.300 --> 00:34:58.500
SVD

567
00:35:00.800 --> 00:35:02.800
or actually Pi 2 pi tutorial.

568
00:35:05.500 --> 00:35:06.900
15 for SVD

569
00:35:08.700 --> 00:35:10.000
I'm going to bring a numpy.

570
00:35:10.600 --> 00:35:11.500
as NP

571
00:35:14.100 --> 00:35:15.100
and so we have a

572
00:35:22.500 --> 00:35:24.500
over the elements in this Matrix we have

573
00:35:27.600 --> 00:35:28.800
10 2 5 11

574
00:35:30.400 --> 00:35:33.400
10 2 5 11

575
00:35:36.700 --> 00:35:40.000
so I'm going to print a and I'm going to print a

576
00:35:40.900 --> 00:35:43.200
DOT T. If you want to transpose The

577
00:35:43.200 --> 00:35:45.400
 Matrix use the T attribute from numpy.

578
00:35:46.600 --> 00:35:47.500
So let me run this.

579
00:35:58.200 --> 00:36:00.600
And let me run that.

580
00:36:03.300 --> 00:36:03.500
Okay.

581
00:36:04.300 --> 00:36:05.500
So just like we saw in.

582
00:36:06.300 --> 00:36:07.300
vs code

583
00:36:08.200 --> 00:36:12.300
Now I'm going to multiply this. I'm going to go NP dot matte multiply.

584
00:36:13.900 --> 00:36:15.000
and I am going to get

585
00:36:16.100 --> 00:36:17.700
a DOT t and a

586
00:36:18.800 --> 00:36:20.400
which will give us the Matrix.

587
00:36:23.200 --> 00:36:26.700
One two five seven. Okay, this one exactly. So we'll get

588
00:36:26.700 --> 00:36:27.400
 a third Matrix.

589
00:36:34.600 --> 00:36:38.200
one to five 75 1 2

590
00:36:37.200 --> 00:36:38.300
 5

591
00:36:40.200 --> 00:36:41.300
75

592
00:36:42.500 --> 00:36:43.500
75

593
00:36:44.400 --> 00:36:45.300
125

594
00:36:48.600 --> 00:36:52.200
and that may copy the copy paste this because this double

595
00:36:51.200 --> 00:36:54.200
 it's very similar for Step 2 for step

596
00:36:54.200 --> 00:36:54.800
 two it will be

597
00:36:58.300 --> 00:37:00.800
Well the same thing but the order will be reversed.

598
00:37:02.800 --> 00:37:03.100
So

599
00:37:05.200 --> 00:37:07.100
The Matrix on the Right comes here

600
00:37:10.400 --> 00:37:13.200
Okay, it's actually this one that needs to be reversed. It's

601
00:37:13.200 --> 00:37:15.100
 this one that needs to be reversed. So I'm going to

602
00:37:16.200 --> 00:37:17.500
reverse

603
00:37:18.400 --> 00:37:19.600
the order so

604
00:37:23.800 --> 00:37:24.100
that

605
00:37:28.500 --> 00:37:31.400
Okay, because it's transpose multiplied by the original

606
00:37:31.400 --> 00:37:32.200
 and this is the original.

607
00:37:33.200 --> 00:37:35.500
Multiplier about the transports. Let me change that here.

608
00:37:37.700 --> 00:37:38.200
like so

609
00:37:43.900 --> 00:37:44.100
okay.

610
00:37:46.800 --> 00:37:48.600
That's a time is transpose.

611
00:37:50.400 --> 00:37:51.700
Up here to transpose.

612
00:37:52.800 --> 00:37:53.400
times a

613
00:37:54.700 --> 00:37:56.800
and here I just need to reverse the order.

614
00:38:01.500 --> 00:38:04.800
I'm going to get this Matrix. So one of four one four

615
00:38:04.800 --> 00:38:04.900
 six.

616
00:38:06.400 --> 00:38:06.600
so

617
00:38:11.500 --> 00:38:12.700
one or four

618
00:38:15.700 --> 00:38:16.900
one four six

619
00:38:19.900 --> 00:38:21.300
72 72

620
00:38:22.700 --> 00:38:24.700
72 72

621
00:38:28.400 --> 00:38:28.700
Okay.

622
00:38:31.100 --> 00:38:33.700
So I see this these two steps are are missing from this.

623
00:38:34.400 --> 00:38:35.500
this formulation

624
00:38:37.700 --> 00:38:37.900
Okay.

625
00:38:38.800 --> 00:38:41.400
Now we need to calculate the singular values and

626
00:38:41.400 --> 00:38:42.700
 that's just eigen.

627
00:38:45.100 --> 00:38:48.700
If you remember how we find the eigenvalues of

628
00:38:48.700 --> 00:38:50.500
 The Matrix.

629
00:38:51.300 --> 00:38:54.000
First we use the determinant function.

630
00:38:55.200 --> 00:38:58.200
Then we get the characteristic polynomial. Let me pull up

631
00:38:58.200 --> 00:39:00.200
 the previous tutorials just to refresh your memory.

632
00:39:00.900 --> 00:39:03.000
Okay. So for step three, there's a sequence of

633
00:39:03.300 --> 00:39:06.700
 steps where we're just gonna since we've already looked at that we're gonna skip right

634
00:39:06.700 --> 00:39:08.300
 to the value, but let me refresh your memory.

635
00:39:13.400 --> 00:39:15.400
Number 13 was it?

636
00:39:18.600 --> 00:39:18.800
Yeah.

637
00:39:20.800 --> 00:39:24.000
Here's how you calculate the eigen values of

638
00:39:24.300 --> 00:39:25.300
 Matrix. So let's say this is our Matrix.

639
00:39:27.700 --> 00:39:29.400
We take the identity Matrix.

640
00:39:30.200 --> 00:39:33.600
You know, that's just one across diagonal multiplied by

641
00:39:33.600 --> 00:39:36.100
 Lambda. This is just this is

642
00:39:36.100 --> 00:39:36.300
 the

643
00:39:37.400 --> 00:39:38.900
the thing that is meant to be determined.

644
00:39:41.100 --> 00:39:44.300
This is the indeterminate and we want to determine what the values

645
00:39:44.300 --> 00:39:47.700
 of Lambda are. So we multiply the scalar value by this identity

646
00:39:47.700 --> 00:39:48.800
 Matrix we get lambdo.

647
00:39:49.300 --> 00:39:50.300
across the angle

648
00:39:53.900 --> 00:39:56.300
Then we take the difference of Matrix a

649
00:39:56.300 --> 00:39:57.700
 minus this new Matrix.

650
00:40:02.800 --> 00:40:05.100
And I give this characteristic polynomial and

651
00:40:05.100 --> 00:40:08.300
 then we solve for Lambda we get two roots.

652
00:40:12.700 --> 00:40:15.200
We plug in these roots inside the eigenvector.

653
00:40:16.700 --> 00:40:19.200
Or the values or excuse me, what we

654
00:40:19.200 --> 00:40:23.400
 do is we plug in we we put axis for our eigenvector.

655
00:40:25.800 --> 00:40:28.100
And then we solve for the roots.

656
00:40:32.600 --> 00:40:36.600
And these would be and these will be the values for our eigen

657
00:40:35.600 --> 00:40:36.800
 back here.

658
00:40:41.000 --> 00:40:41.200
Okay.

659
00:40:50.600 --> 00:40:53.400
Just double checking make sure I did not leave any steps in

660
00:40:53.400 --> 00:40:54.100
 this example.

661
00:41:02.700 --> 00:41:03.000
Yeah.

662
00:41:08.400 --> 00:41:09.400
Yeah, so this Matrix.

663
00:41:10.500 --> 00:41:13.300
Is that Matrix after we plug

664
00:41:13.300 --> 00:41:14.700
 in one of these eigenvalues?

665
00:41:15.500 --> 00:41:18.300
So for this Matrix, we chose one so you

666
00:41:18.300 --> 00:41:21.100
 plug in one inside the as we plug in

667
00:41:21.100 --> 00:41:22.500
 one for Lambda.

668
00:41:24.300 --> 00:41:26.800
And this Matrix will be changed that Matrix.

669
00:41:27.900 --> 00:41:29.200
So we'll get the eigenvector.

670
00:41:30.200 --> 00:41:31.400
When we solve this system.

671
00:41:33.400 --> 00:41:35.000
Okay, so I'm going to skip this whole step.

672
00:41:35.700 --> 00:41:39.700
And just give you the the the eigenvalues.

673
00:41:40.400 --> 00:41:40.600
for

674
00:41:48.400 --> 00:41:49.300
these two matrices

675
00:41:51.300 --> 00:41:52.500
it transpose times a

676
00:41:53.700 --> 00:41:56.100
a times a transpose the eigenvalues for

677
00:41:56.100 --> 00:41:56.400
 these two.

678
00:41:58.100 --> 00:41:58.300
All right.

679
00:42:01.300 --> 00:42:01.500
so

680
00:42:06.700 --> 00:42:08.200
I am going to return.

681
00:42:12.800 --> 00:42:12.900
two

682
00:42:16.700 --> 00:42:17.800
collab, this is Step. Number one.

683
00:42:28.300 --> 00:42:29.100
This is the number one.

684
00:42:36.600 --> 00:42:37.900
step number two was this

685
00:42:41.900 --> 00:42:42.100
Okay.

686
00:42:43.100 --> 00:42:43.900
step number three

687
00:42:50.600 --> 00:42:51.500
the eigenvalues

688
00:42:52.100 --> 00:42:54.900
so I'm going to denote this as

689
00:42:56.100 --> 00:42:57.400
a t a

690
00:42:58.400 --> 00:42:59.900
and this one aat

691
00:43:01.900 --> 00:43:02.600
run that again.

692
00:43:04.800 --> 00:43:05.100
this

693
00:43:08.300 --> 00:43:11.200
Now if you want to calculate the eigenvalues there is

694
00:43:11.200 --> 00:43:15.000
 an attribute or I should say object in numpy called

695
00:43:14.500 --> 00:43:18.300
 linear algebra. So I'm going to go NP the

696
00:43:17.300 --> 00:43:21.100
 linear algebra and I valves

697
00:43:20.100 --> 00:43:22.300
 I can values.

698
00:43:23.200 --> 00:43:25.600
So let's extract the eigenvalues for the first Matrix.

699
00:43:30.200 --> 00:43:32.000
This will give us 50 and 200.

700
00:43:33.600 --> 00:43:35.200
I do the same for the other one.

701
00:43:39.100 --> 00:43:42.500
Yeah, so step three is eigenvalues for both matrices. I'm

702
00:43:42.500 --> 00:43:42.800
 going to print.

703
00:43:44.300 --> 00:43:44.600
this one

704
00:43:46.600 --> 00:43:48.400
and I'm going to print this one.

705
00:43:55.300 --> 00:43:58.300
And so the eigenvalues are 50 and 200.

706
00:43:58.800 --> 00:44:01.500
But what we do is we take the square roots of

707
00:44:01.500 --> 00:44:01.700
 these.

708
00:44:02.700 --> 00:44:04.000
So the square root of 200.

709
00:44:06.300 --> 00:44:08.500
The square root of 200 is what 200?

710
00:44:11.300 --> 00:44:13.400
times out the powers 0.5

711
00:44:18.300 --> 00:44:19.100
It's 14.4.

712
00:44:20.400 --> 00:44:21.100
Just like we have here.

713
00:44:23.500 --> 00:44:24.300
14.4

714
00:44:26.200 --> 00:44:30.100
And the square root of 50.

715
00:44:31.300 --> 00:44:32.100
would be

716
00:44:33.100 --> 00:44:34.700
7.07 Okay, so we've

717
00:44:35.500 --> 00:44:36.300
we have found.

718
00:44:37.000 --> 00:44:38.400
The Matrix

719
00:44:39.600 --> 00:44:39.800
S

720
00:44:40.900 --> 00:44:43.500
The Matrix contain the singular value so the

721
00:44:43.500 --> 00:44:46.100
 square root of these values are the singular value

722
00:44:48.200 --> 00:44:51.700
Which I will denote a sigma so Sigma sub 1

723
00:44:51.700 --> 00:44:52.500
 will be.

724
00:44:56.800 --> 00:44:58.000
Let's just the first one.

725
00:44:59.100 --> 00:44:59.800
at zero

726
00:45:01.500 --> 00:45:04.700
But then I need to take the square roots. I have to import the mat.

727
00:45:05.500 --> 00:45:07.700
The math library is so important math.

728
00:45:08.500 --> 00:45:09.800
And then I'm going to go math.

729
00:45:11.800 --> 00:45:13.000
That sqrt.

730
00:45:16.200 --> 00:45:17.500
And the same thing for Sigma.

731
00:45:18.400 --> 00:45:18.500
2

732
00:45:26.500 --> 00:45:27.300
I'm going to print these.

733
00:45:28.400 --> 00:45:29.300
Sigma 1

734
00:45:31.200 --> 00:45:32.900
Okay 14.

735
00:45:34.700 --> 00:45:37.100
And this would be seven.

736
00:45:38.100 --> 00:45:39.100
point seven

737
00:45:53.300 --> 00:45:53.500
Okay.

738
00:45:54.500 --> 00:45:55.500
so

739
00:45:59.300 --> 00:46:00.800
we get this Matrix.

740
00:46:08.200 --> 00:46:09.100
four step three

741
00:46:16.700 --> 00:46:18.400
The 14th.

742
00:46:20.900 --> 00:46:21.800
point 14

743
00:46:28.600 --> 00:46:31.100
and 7.4. Was it

744
00:46:31.100 --> 00:46:31.900
 0.7?

745
00:46:32.700 --> 00:46:35.100
So this is now the Matrix U. This is

746
00:46:35.100 --> 00:46:35.500
 now.

747
00:46:37.800 --> 00:46:38.800
The Matrix you

748
00:46:48.000 --> 00:46:48.600
well

749
00:46:50.200 --> 00:46:53.100
this is actually step 4 right step three is just

750
00:46:56.600 --> 00:46:58.600
Sigma 1 and sigma 2 so Sigma

751
00:47:00.900 --> 00:47:02.900
1 we said was equal to 200.

752
00:47:04.800 --> 00:47:05.600
Sigma

753
00:47:06.800 --> 00:47:08.100
2 was equal to 50.

754
00:47:09.900 --> 00:47:10.300
then

755
00:47:14.500 --> 00:47:17.200
Or number four. We just take square root of those Sigma. So

756
00:47:17.200 --> 00:47:18.400
 let me just add another Matrix.

757
00:47:22.400 --> 00:47:25.900
This will be the square root this qrt.

758
00:47:28.400 --> 00:47:29.300
skew

759
00:47:33.900 --> 00:47:34.900
Sigma 1

760
00:47:43.700 --> 00:47:43.800
Sigma 2

761
00:47:52.300 --> 00:47:52.600
now

762
00:47:53.500 --> 00:47:54.200
How do we get?

763
00:47:56.500 --> 00:47:57.200
you

764
00:47:58.200 --> 00:47:59.400
and V transpose

765
00:48:01.200 --> 00:48:02.700
so for that we need to talk about the

766
00:48:05.300 --> 00:48:08.900
first of all the definition of an orthogonal Matrix the distinction

767
00:48:08.900 --> 00:48:11.300
 of orthogonal and also normal and then

768
00:48:11.300 --> 00:48:12.700
 we will switch and talk about the

769
00:48:14.300 --> 00:48:17.400
The gram Schmidt algorithm one

770
00:48:17.400 --> 00:48:19.000
 of the algorithms with which you can.

771
00:48:20.300 --> 00:48:21.100
Or talk in the lives.

772
00:48:22.900 --> 00:48:25.100
Is it clear up this point what we have done you have any

773
00:48:25.100 --> 00:48:27.300
 questions before we proceed to step five and six?

774
00:48:28.300 --> 00:48:30.500
if it's clear at this point type the letter c

775
00:48:33.400 --> 00:48:35.200
And then otherwise, let me know if you have any questions.

776
00:48:43.800 --> 00:48:44.400
No questions.

777
00:48:47.200 --> 00:48:49.000
Okay, if you have any questions, I will see them in that chat.

778
00:48:49.400 --> 00:48:51.100
but yes, let's talk about

779
00:48:53.900 --> 00:48:55.400
orthogonalization

780
00:49:00.400 --> 00:49:00.700
so

781
00:49:21.600 --> 00:49:22.200
this is the

782
00:49:23.200 --> 00:49:25.900
A tutorial from week one which I have updated.

783
00:49:27.600 --> 00:49:30.300
Okay, when you go to the dashboard this will be updated. So

784
00:49:30.300 --> 00:49:30.500
 this is

785
00:49:35.100 --> 00:49:38.100
A PDF or HTML file from week one,

786
00:49:38.100 --> 00:49:38.400
 which I have.

787
00:49:40.100 --> 00:49:43.400
With whichever appended definitions for orthogonal Matrix.

788
00:49:43.400 --> 00:49:44.500
 So let's look at it.

789
00:49:51.300 --> 00:49:53.300
an orthogonal Matrix

790
00:49:54.300 --> 00:49:55.600
sometimes used

791
00:49:57.800 --> 00:50:01.600
Sonata or sometimes synonymously called

792
00:50:01.600 --> 00:50:02.300
 orthonormal

793
00:50:03.400 --> 00:50:05.300
is a matrix that is

794
00:50:05.900 --> 00:50:06.900
whose vectors?

795
00:50:10.800 --> 00:50:13.500
In the column space imagine you

796
00:50:13.500 --> 00:50:14.000
 have a matrix.

797
00:50:16.200 --> 00:50:17.800
If you take the columns as vectors.

798
00:50:19.600 --> 00:50:21.900
And you take the product? Excuse me?

799
00:50:22.700 --> 00:50:23.600
the Dutch product

800
00:50:25.500 --> 00:50:27.100
also known as the inner product.

801
00:50:28.600 --> 00:50:31.300
So we take the dot product of two columns and that Matrix.

802
00:50:33.700 --> 00:50:36.500
And their value and the value of this product becomes zero.

803
00:50:37.700 --> 00:50:40.500
Then we say that The Columns of this Matrix

804
00:50:40.500 --> 00:50:42.000
 are pairwise orthogonal.

805
00:50:43.600 --> 00:50:46.300
What does it mean for the dot product of two

806
00:50:46.300 --> 00:50:49.200
 vectors to be 0 does anybody know like if you were to

807
00:50:49.200 --> 00:50:49.800
 plot these two vectors?

808
00:50:50.700 --> 00:50:53.200
And their product is zero. What would those

809
00:50:53.200 --> 00:50:53.900
 two vectors look like?

810
00:51:03.500 --> 00:51:04.500
any answers

811
00:51:06.400 --> 00:51:08.500
Precisely they would be perpendicular.

812
00:51:09.200 --> 00:51:12.800
Just like we saw in that cosine similarity example you

813
00:51:12.800 --> 00:51:13.200
 would get this.

814
00:51:14.600 --> 00:51:17.400
remember when we when we took the cosine

815
00:51:17.400 --> 00:51:18.200
 similarity of

816
00:51:18.500 --> 00:51:20.000
all the time dog in the building

817
00:51:20.600 --> 00:51:23.700
like they had nothing to do each other. They were completely or no.

818
00:51:23.700 --> 00:51:25.600
 No those two were not completely orthogonal.

819
00:51:28.700 --> 00:51:31.300
That was that was something else but they were quite the angle

820
00:51:31.300 --> 00:51:31.700
 was quite big.

821
00:51:32.800 --> 00:51:35.400
but anyway for two vectors to be

822
00:51:35.400 --> 00:51:36.200
 orthograph means that they have

823
00:51:37.500 --> 00:51:38.600
well, they're perpendicular.

824
00:51:40.300 --> 00:51:43.400
If this was cosine similar, this would be they have you know.

825
00:51:44.500 --> 00:51:45.300
Little to nothing to do with each other.

826
00:51:47.100 --> 00:51:47.300
That's

827
00:51:48.300 --> 00:51:52.000
that's an orthogical matrix. It's column vectors. We

828
00:51:51.200 --> 00:51:54.000
 all be orthogonal to each other perpendicular.

829
00:51:58.000 --> 00:51:58.200
now

830
00:51:59.900 --> 00:52:02.600
in some literature if you see here in some literature

831
00:52:02.600 --> 00:52:05.300
 an orthogonal Matrix is a matrix to

832
00:52:05.300 --> 00:52:07.000
 which only the first condition applies.

833
00:52:09.500 --> 00:52:12.300
So nartholog Matrix is only a matrix

834
00:52:12.300 --> 00:52:14.200
 whose color vectors are perpendicular.

835
00:52:15.800 --> 00:52:17.300
an orthonormal Matrix

836
00:52:18.500 --> 00:52:21.500
Is a matrix to which both conditions wanted to

837
00:52:21.500 --> 00:52:22.400
 apply what is conditioned to?

838
00:52:23.900 --> 00:52:26.700
condition two says that the magnitude

839
00:52:27.400 --> 00:52:29.600
of each column Vector is zero.

840
00:52:34.100 --> 00:52:37.400
How do we calculate the magnitude we've seen this before in one

841
00:52:37.400 --> 00:52:38.300
 of the previous sessions?

842
00:52:39.200 --> 00:52:42.800
You see if I can put up the relevant document.

843
00:52:44.000 --> 00:52:44.800
magazine

844
00:52:47.500 --> 00:52:47.600
Here we go.

845
00:52:49.100 --> 00:52:51.500
It's actually this file I scroll up.

846
00:52:56.700 --> 00:52:58.500
Oh, it's not here. Okay.

847
00:53:23.900 --> 00:53:26.200
It's an another file.

848
00:53:27.300 --> 00:53:28.600
Let me show you magnitude.

849
00:53:31.100 --> 00:53:32.600
magnetude

850
00:53:34.400 --> 00:53:35.600
magni

851
00:53:37.100 --> 00:53:37.900
toot

852
00:53:39.100 --> 00:53:40.700
It will be this file.

853
00:53:42.100 --> 00:53:42.700
There we go.

854
00:53:54.700 --> 00:53:57.500
This is the magnitude and you know

855
00:53:57.500 --> 00:53:59.300
 also it's known as a norm.

856
00:54:00.800 --> 00:54:01.800
easier synonyms

857
00:54:03.300 --> 00:54:07.000
Typically you want to use double the two vertical bars.

858
00:54:06.100 --> 00:54:09.400
 Sometimes you will see single bars,

859
00:54:09.400 --> 00:54:12.400
 but this is not good practice because single bars also

860
00:54:12.400 --> 00:54:13.500
 used for the absolute value.

861
00:54:14.800 --> 00:54:17.700
Anyway, the week calculate the magnitude of

862
00:54:17.700 --> 00:54:18.500
 a vector is to take

863
00:54:19.700 --> 00:54:23.100
its components. Let's say this is a vector v

864
00:54:23.100 --> 00:54:25.600
 over R4 so four dimensional vector.

865
00:54:26.400 --> 00:54:28.500
You take all four of its components Square them.

866
00:54:29.800 --> 00:54:33.100
And then add the add up

867
00:54:32.100 --> 00:54:34.600
 the sum and then take the square root of that. Sum.

868
00:54:35.100 --> 00:54:36.200
If that becomes zero.

869
00:54:38.300 --> 00:54:41.200
Or if it becomes one that then you have a unit vector.

870
00:54:42.900 --> 00:54:44.500
essentially unit Vector is one who's

871
00:54:45.300 --> 00:54:46.400
radius is 1

872
00:54:47.200 --> 00:54:47.400
so

873
00:54:51.100 --> 00:54:52.200
Here if I return to.

874
00:55:02.300 --> 00:55:03.100
as other file

875
00:55:07.700 --> 00:55:09.200
it's called orthonormal.

876
00:55:09.700 --> 00:55:11.500
Because it's magnitude is zero.

877
00:55:13.000 --> 00:55:13.300
and

878
00:55:15.300 --> 00:55:16.800
there's a word called normalize.

879
00:55:18.300 --> 00:55:19.300
normalize is a

880
00:55:20.700 --> 00:55:22.000
normalization is where

881
00:55:23.100 --> 00:55:26.300
the largest component in a vector is one

882
00:55:26.300 --> 00:55:29.400
 and the smallest component is in a vectors 0 this

883
00:55:29.400 --> 00:55:30.300
 is after normalization.

884
00:55:31.200 --> 00:55:32.500
I'll show you how that's done in a moment.

885
00:55:33.800 --> 00:55:37.000
Okay, but I just thought maybe you've heard of this word normalization

886
00:55:36.000 --> 00:55:37.200
 before.

887
00:55:38.600 --> 00:55:38.800
so

888
00:55:40.100 --> 00:55:41.500
if you return to our tutorial.

889
00:55:44.300 --> 00:55:46.300
We now need to orthogonalize.

890
00:55:48.100 --> 00:55:51.900
Ta so we need to make an orthogonal Matrix.

891
00:55:53.600 --> 00:55:56.100
I think is this orthonormal orthogonal. I think

892
00:55:56.100 --> 00:55:58.500
 this one is actually this is actually orthonormal.

893
00:56:02.400 --> 00:56:04.200
But I'll have to double check.

894
00:56:04.900 --> 00:56:06.600
Because this book I don't think it makes a distinction.

895
00:56:08.100 --> 00:56:11.200
Either way, there are this is there there are

896
00:56:11.200 --> 00:56:14.800
 a few algorithms with which we can orthogenize or even orthonormalize a

897
00:56:14.800 --> 00:56:16.200
 matrix this Matrix in particular.

898
00:56:17.200 --> 00:56:18.700
And that is called a gram Schmidt.

899
00:56:19.100 --> 00:56:21.500
Algorithm, so let me show you the gram Schmidt algorithm.

900
00:56:30.900 --> 00:56:32.700
It will be faster if I show you a picture.

901
00:56:33.900 --> 00:56:34.600
in Google Images

902
00:56:55.400 --> 00:56:56.100
Yeah, this is good.

903
00:57:00.800 --> 00:57:03.600
Let me add one thing before I return here.

904
00:57:05.600 --> 00:57:06.000
or

905
00:57:07.200 --> 00:57:08.100
matrices

906
00:57:10.400 --> 00:57:12.700
we're talking about the dot product, right?

907
00:57:14.900 --> 00:57:16.700
Where was the file for DOT product?

908
00:57:33.200 --> 00:57:33.900
dot product

909
00:57:50.700 --> 00:57:51.500
here

910
00:58:03.200 --> 00:58:06.200
So this is the this is how you denote?

911
00:58:08.700 --> 00:58:11.400
Where is it the dot product? This is

912
00:58:11.400 --> 00:58:12.500
 one way to do it.

913
00:58:13.300 --> 00:58:14.100
Let's start here.

914
00:58:15.100 --> 00:58:18.400
Another way to denoted is like so to use

915
00:58:18.400 --> 00:58:19.200
 the vertical brackets.

916
00:58:20.500 --> 00:58:21.900
So either this one or

917
00:58:23.600 --> 00:58:25.100
to do this

918
00:58:38.600 --> 00:58:40.200
two if you see this notation.

919
00:58:40.900 --> 00:58:43.000
that's the same thing as that that

920
00:58:44.300 --> 00:58:45.100
both of these are

921
00:58:49.300 --> 00:58:49.900
you know dot product.

922
00:58:50.900 --> 00:58:53.100
You call it can call this dot product because of the dot

923
00:58:53.100 --> 00:58:54.500
 in here. You can call this inner product because well.

924
00:58:55.700 --> 00:58:57.000
They're inside the brackets.

925
00:58:59.400 --> 00:59:00.200
I come here you will see.

926
00:59:00.900 --> 00:59:01.200
that

927
00:59:03.600 --> 00:59:05.700
in in other examples they used.

928
00:59:07.800 --> 00:59:08.400
the brackets

929
00:59:15.700 --> 00:59:17.700
Anyway, let's see what's going on in here.

930
00:59:20.800 --> 00:59:22.100
say you have

931
00:59:22.900 --> 00:59:23.600
a basis

932
00:59:24.500 --> 00:59:27.500
Do you remember we said well we said about basis. We said that our

933
00:59:27.500 --> 00:59:28.400
 basis is a matrix.

934
00:59:29.400 --> 00:59:31.600
whose vectors are

935
00:59:33.700 --> 00:59:36.300
Over the two conditions by they will it's actually revisit that

936
00:59:36.300 --> 00:59:39.100
 let's make sure we remember what a we're actually if I should

937
00:59:39.100 --> 00:59:40.100
 remember what a basis is.

938
00:59:40.800 --> 00:59:43.200
Basis we said bases.

939
00:59:44.200 --> 00:59:45.000
as two conditions

940
00:59:50.200 --> 00:59:51.000
bases

941
00:59:51.800 --> 00:59:53.600
As they may is a set.

942
00:59:56.500 --> 00:59:56.900
first of all

943
00:59:58.400 --> 01:00:01.400
So this is this is this is the basis. This is a set.

944
01:00:02.200 --> 01:00:04.800
It has vectors V1 V2 VN.

945
01:00:06.500 --> 01:00:09.300
All three vectors must span the Subspace. What's

946
01:00:09.300 --> 01:00:10.500
 the Subspace RN?

947
01:00:11.100 --> 01:00:13.300
So let's say we talk about a three-dimensional space.

948
01:00:14.900 --> 01:00:17.500
So we need three points. XYZ each Vector

949
01:00:17.500 --> 01:00:18.800
 must have x y z

950
01:00:19.400 --> 01:00:22.400
You can have one that's two Dimension. Another

951
01:00:22.400 --> 01:00:25.300
 one. That's four dimensions. All three must be of the same Dimension that's

952
01:00:25.300 --> 01:00:26.000
 condition. Number one.

953
01:00:26.700 --> 01:00:29.900
Condition number two. They must be independent. What

954
01:00:29.900 --> 01:00:32.700
 does it mean for two vectors to be in two vectors

955
01:00:32.700 --> 01:00:33.200
 to be independent?

956
01:00:34.300 --> 01:00:37.200
It means that when you take the linear combination and the linear combination is this

957
01:00:37.200 --> 01:00:38.400
 so let's say you have two vectors.

958
01:00:39.400 --> 01:00:40.700
And you have two scalars.

959
01:00:41.300 --> 01:00:44.700
Multiply this scalar without Vector multiply that's going

960
01:00:44.700 --> 01:00:47.400
 to but I back here at the product. It would be equal to zero. We

961
01:00:47.400 --> 01:00:49.500
 saw this in another example. We saw this in the last session.

962
01:00:50.300 --> 01:00:53.100
So that's what a base is this. Okay for now,

963
01:00:53.100 --> 01:00:54.300
 just imagine it's just a matrix.

964
01:00:55.600 --> 01:00:57.500
If you would to put these three columns inside.

965
01:01:01.100 --> 01:01:04.600
If we would take the components of these vectors inside angle brackets,

966
01:01:04.600 --> 01:01:08.400
 it will be a matrix. So for not consider this to be a matrix column

967
01:01:07.400 --> 01:01:09.500
 one column two column three.

968
01:01:14.300 --> 01:01:15.600
How do we orthogonalize?

969
01:01:18.700 --> 01:01:21.500
You define a new variable or new Vector

970
01:01:21.500 --> 01:01:22.100
 W sub 1?

971
01:01:23.400 --> 01:01:25.700
And that is just identical to V sub 1.

972
01:01:26.700 --> 01:01:29.000
with components or with points if you

973
01:01:29.100 --> 01:01:29.900
 like 110

974
01:01:31.700 --> 01:01:34.600
Then you will use the first Vector W

975
01:01:34.600 --> 01:01:37.400
 sub 1 to create a new Vector W sub 2.

976
01:01:39.400 --> 01:01:40.900
How do you create W sub 2?

977
01:01:41.900 --> 01:01:42.900
You take Vector 2.

978
01:01:44.400 --> 01:01:46.000
And subtract it from this ratio.

979
01:01:48.600 --> 01:01:50.600
So you have the dot product of V2 and

980
01:01:51.900 --> 01:01:52.700
the first vector

981
01:01:54.700 --> 01:01:55.900
over the dot product

982
01:01:56.800 --> 01:01:58.500
of the first Factor

983
01:01:59.600 --> 01:02:01.200
I mean exactly as you see it here.

984
01:02:02.400 --> 01:02:05.700
This will become the first Vector of

985
01:02:05.700 --> 01:02:06.600
 the new Matrix.

986
01:02:07.200 --> 01:02:09.800
This will become the new Vector of the second Matrix.

987
01:02:10.800 --> 01:02:11.200
this

988
01:02:13.900 --> 01:02:16.100
the new Vector of the third Matrix

989
01:02:17.800 --> 01:02:20.100
so you must multiply the scalar value.

990
01:02:21.300 --> 01:02:23.000
by the components of this third vector

991
01:02:29.800 --> 01:02:32.000
you do this multiplication if you want if you do

992
01:02:32.200 --> 01:02:32.600
 the scalar product.

993
01:02:33.400 --> 01:02:34.300
It gives you.

994
01:02:39.300 --> 01:02:40.100
so in

995
01:02:41.200 --> 01:02:42.300
Total we will get.

996
01:02:44.900 --> 01:02:46.500
Yes, we'll get a new Matrix.

997
01:02:49.600 --> 01:02:52.500
So the original Matrix was 1 1 0 1 2

998
01:02:52.500 --> 01:02:54.400
 0 0 1 2 this new Matrix will be.

999
01:02:55.600 --> 01:02:57.100
This will be its first column.

1000
01:02:58.600 --> 01:02:59.800
This will be its second column.

1001
01:03:01.100 --> 01:03:01.900
This will be it.

1002
01:03:03.200 --> 01:03:03.800
third column

1003
01:03:09.400 --> 01:03:11.300
Now this is orthogonalization actually.

1004
01:03:13.500 --> 01:03:14.700
So these are the vectors.

1005
01:03:16.100 --> 01:03:17.300
of The orthogonal Matrix

1006
01:03:20.800 --> 01:03:23.200
These are the vectors after it has

1007
01:03:23.200 --> 01:03:23.800
 been normalized.

1008
01:03:29.700 --> 01:03:32.500
If we take the square root of 2 over 2, so that's 2

1009
01:03:32.500 --> 01:03:33.000
 over.

1010
01:03:40.100 --> 01:03:40.600
You can see.

1011
01:03:41.800 --> 01:03:44.100
It is 0.7. What I'm trying

1012
01:03:44.100 --> 01:03:45.500
 to say is none of these components.

1013
01:03:46.700 --> 01:03:47.800
this squared over to

1014
01:03:50.300 --> 01:03:53.100
any of these components are above one. So when

1015
01:03:53.100 --> 01:03:54.400
 we normalize a vector

1016
01:03:55.700 --> 01:03:58.300
None of the points in that Vector exceed one.

1017
01:03:58.300 --> 01:03:59.600
 There will be between 0 and 1.

1018
01:04:03.800 --> 01:04:06.400
if the notation is a little too overwhelming and it

1019
01:04:06.400 --> 01:04:06.700
 kind of is

1020
01:04:08.200 --> 01:04:11.600
let me simplify by taking a huge back to call app.

1021
01:04:15.300 --> 01:04:18.400
Okay, so let's actually use this as

1022
01:04:18.400 --> 01:04:18.900
 an example.

1023
01:04:19.900 --> 01:04:20.800
I will.

1024
01:04:22.300 --> 01:04:25.500
Have one ones. Okay. So the original one is 1

1025
01:04:25.500 --> 01:04:27.400
 1 0 1 2 0 0 1 2. Yes.

1026
01:04:29.200 --> 01:04:30.400
So for step number.

1027
01:04:35.400 --> 01:04:38.300
Five and six orthogonalization. I'm going to create a new

1028
01:04:38.300 --> 01:04:40.200
 notebook before we do step number five.

1029
01:04:41.800 --> 01:04:42.800
We create a new.

1030
01:04:50.400 --> 01:04:52.500
But I want everything to be the same file.

1031
01:04:58.200 --> 01:04:58.400
No.

1032
01:05:04.900 --> 01:05:06.900
I'll just call this tutorial 15 p

1033
01:05:08.800 --> 01:05:09.700
p y

1034
01:05:14.300 --> 01:05:17.600
or you know, what orthogonization could be tutorial number

1035
01:05:17.600 --> 01:05:18.400
 16 so tutorial.

1036
01:05:20.300 --> 01:05:21.100
number 16

1037
01:05:23.300 --> 01:05:25.100
Once again, I will import numpy.

1038
01:05:29.300 --> 01:05:30.700
And math just in case.

1039
01:05:31.800 --> 01:05:33.900
So the Matrix that we see in this picture.

1040
01:05:37.300 --> 01:05:39.700
Is Basis Matrix? So I'm going to call this B?

1041
01:05:40.800 --> 01:05:42.000
and P dot array

1042
01:05:44.800 --> 01:05:46.700
of course, I'm using the NP array method so

1043
01:05:47.600 --> 01:05:48.200
I can.

1044
01:05:49.900 --> 01:05:52.300
Use numpy actually beats and

1045
01:05:52.300 --> 01:05:52.500
 methods.

1046
01:05:53.100 --> 01:05:53.400
it's

1047
01:05:55.200 --> 01:05:58.800
a vectors are 1 1 0 1 2 0 1 1

1048
01:05:58.800 --> 01:05:59.300
 0.

1049
01:06:02.800 --> 01:06:04.000
1 2 0

1050
01:06:08.600 --> 01:06:09.500
0 1 2

1051
01:06:16.800 --> 01:06:19.600
and after orthog orthogonalization

1052
01:06:22.100 --> 01:06:22.700
we will get

1053
01:06:26.100 --> 01:06:27.700
these three vectors

1054
01:06:31.700 --> 01:06:32.500
one two and three

1055
01:06:34.600 --> 01:06:35.100
so

1056
01:06:37.100 --> 01:06:41.600
I will call this now. Orthogonal matrices

1057
01:06:41.600 --> 01:06:44.000
 are usually denoted with the uppercase letter q

1058
01:06:45.100 --> 01:06:46.500
What I'm just going to call this B.

1059
01:06:49.200 --> 01:06:50.100
orthogonal

1060
01:07:06.700 --> 01:07:07.200
so we have

1061
01:07:10.500 --> 01:07:13.200
one negative 1 over 2 1 over 2 and

1062
01:07:13.200 --> 01:07:13.600
 0

1063
01:07:14.300 --> 01:07:16.700
so that's just negative 0.5.

1064
01:07:19.900 --> 01:07:22.800
0.5 and 0 and third

1065
01:07:22.800 --> 01:07:23.100
 one.

1066
01:07:25.400 --> 01:07:28.500
If you multiply the scalar value by these components will

1067
01:07:28.500 --> 01:07:29.400
 get zero zero two.

1068
01:07:30.800 --> 01:07:31.200
zero

1069
01:07:32.700 --> 01:07:33.400
zero two

1070
01:07:38.300 --> 01:07:40.000
to make it orthonormal. Let me run this first.

1071
01:07:51.200 --> 01:07:53.000
To make this orthod over you see here.

1072
01:07:57.300 --> 01:08:00.500
This component is two It Isn't So this Vector is

1073
01:08:00.500 --> 01:08:01.200
 not normalized.

1074
01:08:01.700 --> 01:08:03.600
These could be normalized but

1075
01:08:05.500 --> 01:08:08.700
this is just by virtue of the operations, but

1076
01:08:11.500 --> 01:08:12.700
Let me show you how to normalize this.

1077
01:08:14.900 --> 01:08:17.400
Normalizes, we must divide we must

1078
01:08:17.400 --> 01:08:19.200
 find a magnitude of each factor.

1079
01:08:22.200 --> 01:08:23.300
And then divide each component.

1080
01:08:24.100 --> 01:08:25.300
or we can divide in

1081
01:08:26.400 --> 01:08:29.300
In vectors of matrices we can multiply it by one over the

1082
01:08:29.300 --> 01:08:29.500
 norm.

1083
01:08:30.100 --> 01:08:30.800
And let me show you what I mean.

1084
01:08:31.500 --> 01:08:31.700
so

1085
01:08:34.400 --> 01:08:36.800
I will have N Sub 1 and sub 2 and sub 3

1086
01:08:37.800 --> 01:08:39.600
for these for each row.

1087
01:08:40.300 --> 01:08:40.600
so

1088
01:08:41.700 --> 01:08:43.200
Norm one will be equal to

1089
01:08:45.300 --> 01:08:48.500
NP dot linear algebra dot

1090
01:08:48.500 --> 01:08:50.600
 Norm of the first

1091
01:08:53.900 --> 01:08:56.300
Let's just say column. So let's imagine these are columns are

1092
01:08:56.300 --> 01:08:58.400
 actually Rose. But let's imagine these are colors. I'm gonna go B.

1093
01:09:01.500 --> 01:09:01.900
0

1094
01:09:10.300 --> 01:09:11.700
that's the norm of the first Factor.

1095
01:09:12.400 --> 01:09:14.300
if I want to normalize it I'm going to go be

1096
01:09:18.500 --> 01:09:21.300
And then multiply our multiplied by 1 over.

1097
01:09:21.900 --> 01:09:22.500
the norm

1098
01:09:24.500 --> 01:09:24.900
like so

1099
01:09:29.400 --> 01:09:32.700
I'll give you the new Vector 0.7 0.70.

1100
01:09:35.700 --> 01:09:37.800
so if I return here to this picture

1101
01:09:41.600 --> 01:09:42.600
That's 0.7.

1102
01:09:45.400 --> 01:09:48.500
Another way to express square root of 2, by the way, in case you didn't

1103
01:09:48.500 --> 01:09:51.400
 catch this another way to express square

1104
01:09:51.400 --> 01:09:51.900
 root of 2.

1105
01:09:53.400 --> 01:09:54.200
in math

1106
01:09:55.200 --> 01:09:56.400
So if you have square root of 2.

1107
01:09:59.700 --> 01:10:00.200
down here

1108
01:10:01.600 --> 01:10:03.600
That's just two raised to the power.

1109
01:10:06.800 --> 01:10:07.500
0.5.

1110
01:10:09.300 --> 01:10:10.100
That's what I'm doing in.

1111
01:10:11.300 --> 01:10:13.000
the my laptop calculator

1112
01:10:17.800 --> 01:10:20.800
so the square root of 2 the square

1113
01:10:20.800 --> 01:10:21.200
 root of 2.

1114
01:10:25.500 --> 01:10:26.300
2 over the

1115
01:10:26.900 --> 01:10:29.600
To the power 0.5 over 2

1116
01:10:29.600 --> 01:10:30.700
 0.7.

1117
01:10:32.900 --> 01:10:35.400
That's what they're trying to say here. These have been normalized.

1118
01:10:35.400 --> 01:10:39.000
 If you see here what we do is we take the first Vector divided

1119
01:10:38.500 --> 01:10:39.800
 by its magnitude.

1120
01:10:40.300 --> 01:10:42.200
And that's exactly what we've done here.

1121
01:10:43.700 --> 01:10:43.900
here

1122
01:10:45.400 --> 01:10:46.100
normalized

1123
01:10:50.100 --> 01:10:50.300
so then

1124
01:10:51.200 --> 01:10:52.500
if we create a new Matrix.

1125
01:10:56.300 --> 01:10:57.400
We orthonormal.

1126
01:11:08.100 --> 01:11:09.100
then

1127
01:11:09.900 --> 01:11:12.100
the First Column and be orthonormal

1128
01:11:14.100 --> 01:11:14.500
would be

1129
01:11:16.700 --> 01:11:17.300
this vector

1130
01:11:18.900 --> 01:11:19.700
So let me run this.

1131
01:11:24.100 --> 01:11:25.600
I cannot leave this up to you. Okay?

1132
01:11:34.300 --> 01:11:37.900
I'm just going to put three zeros in here just as placeholders.

1133
01:11:41.600 --> 01:11:44.000
There's actually a method called zeros, but never mind that for now.

1134
01:11:47.100 --> 01:11:48.100
one vector

1135
01:11:52.400 --> 01:11:52.600
Okay.

1136
01:11:56.100 --> 01:11:57.400
So that's the first column.

1137
01:11:58.100 --> 01:11:59.400
of The orthonormal Matrix

1138
01:12:00.500 --> 01:12:02.000
I'll go ahead and do the same for

1139
01:12:04.200 --> 01:12:07.000
the others now just to simplify the code. I'm going to take this bit.

1140
01:12:12.300 --> 01:12:13.100
It's just remember.

1141
01:12:15.300 --> 01:12:17.200
This will normalize the first Factor.

1142
01:12:18.700 --> 01:12:21.400
And make that the First Column of the orthonormal effect

1143
01:12:21.400 --> 01:12:22.100
 Matrix.

1144
01:12:23.100 --> 01:12:26.800
And I'm just going to copy paste this for the other matrices. This

1145
01:12:26.800 --> 01:12:27.400
 would be one.

1146
01:12:32.100 --> 01:12:32.400
one

1147
01:12:37.700 --> 01:12:37.900
so

1148
01:12:40.000 --> 01:12:41.200
normalize

1149
01:12:43.600 --> 01:12:44.500
the vectors

1150
01:12:46.300 --> 01:12:46.900
of B

1151
01:12:51.500 --> 01:12:51.800
and

1152
01:13:04.900 --> 01:13:08.400
a vectors orthogonide be

1153
01:13:07.400 --> 01:13:09.300
 after

1154
01:13:10.400 --> 01:13:13.800
also, go now lization

1155
01:13:17.400 --> 01:13:18.900
You can see this picture for reference.

1156
01:13:19.700 --> 01:13:19.800
see

1157
01:13:20.900 --> 01:13:21.700
Graham

1158
01:13:22.500 --> 01:13:23.200
Schmitt

1159
01:13:24.900 --> 01:13:26.000
Algorithm here.

1160
01:13:35.900 --> 01:13:38.900
And then if I print p orthonormal

1161
01:13:54.900 --> 01:13:56.200
try to reassign it now.

1162
01:13:59.100 --> 01:13:59.400
Okay.

1163
01:14:05.600 --> 01:14:08.200
I want to let me reassign I guess I could do this.

1164
01:14:10.600 --> 01:14:13.500
And then you start at this

1165
01:14:13.500 --> 01:14:15.000
 repent. Let's try a pen.

1166
01:14:18.100 --> 01:14:19.600
So we'll append the first vector.

1167
01:14:22.100 --> 01:14:24.300
And then the second vector and then third vector.

1168
01:14:36.500 --> 01:14:37.300
once more

1169
01:14:44.400 --> 01:14:45.400
What does it push?

1170
01:14:46.300 --> 01:14:48.400
anybody know how to add a

1171
01:14:49.700 --> 01:14:51.500
element to an Empire array

1172
01:14:52.200 --> 01:14:53.200
P array

1173
01:14:58.300 --> 01:14:59.400
yeah, it's a pen.

1174
01:15:06.600 --> 01:15:07.600
Okay, maybe I should say.

1175
01:15:33.100 --> 01:15:36.700
Why is it complaining about attribute? I'm referring to a method. All

1176
01:15:36.700 --> 01:15:38.900
 right, so it's saying NPA rate does not have a method.

1177
01:15:40.200 --> 01:15:40.900
All right.

1178
01:15:54.200 --> 01:15:56.600
I guess I'll just do it a different way. I'll go NP.

1179
01:16:02.900 --> 01:16:04.000
and P dot array

1180
01:16:09.400 --> 01:16:11.300
and I'll just create them all at this.

1181
01:16:12.200 --> 01:16:13.100
simultaneously

1182
01:16:15.100 --> 01:16:15.700
like so

1183
01:16:27.200 --> 01:16:27.600
there we go.

1184
01:16:33.600 --> 01:16:36.500
There we go. That's the that's the orthonormal Matrix

1185
01:16:36.500 --> 01:16:36.600
 now.

1186
01:16:38.500 --> 01:16:40.500
You see not of it's components.

1187
01:16:42.300 --> 01:16:44.100
exceed zero or go below zero

1188
01:16:46.900 --> 01:16:49.900
If we were to plot these vectors, they

1189
01:16:49.900 --> 01:16:52.800
 would be orthogonal and they would have they

1190
01:16:52.800 --> 01:16:55.200
 would not exceed a radius of one.

1191
01:16:56.300 --> 01:16:57.800
This is what an orthonormal Matrix is.

1192
01:16:58.600 --> 01:17:00.800
Now, let me show you how to do this using.

1193
01:17:02.800 --> 01:17:05.800
Numpy without you know manually doing this calculation.

1194
01:17:06.900 --> 01:17:07.000
so

1195
01:17:17.400 --> 01:17:18.500
I will return here.

1196
01:17:20.300 --> 01:17:22.600
To show you how to order the normalize.

1197
01:17:23.900 --> 01:17:24.700
ATA

1198
01:17:25.300 --> 01:17:27.600
Okay, so if you remember ATA.

1199
01:17:28.600 --> 01:17:29.700
Is that Matrix?

1200
01:17:32.500 --> 01:17:33.600
the orthogonalize it

1201
01:17:36.800 --> 01:17:39.000
there is a method called. Let me

1202
01:17:39.300 --> 01:17:39.800
 see what it was called.

1203
01:17:51.100 --> 01:17:54.000
It's called Earth. So I'm gonna go.

1204
01:17:55.700 --> 01:17:59.200
NP Lin algebra

1205
01:18:01.200 --> 01:18:03.000
dot Force

1206
01:18:04.100 --> 01:18:05.600
this is orthonormalized I believe.

1207
01:18:07.900 --> 01:18:10.500
And I'm going to plug in.

1208
01:18:15.100 --> 01:18:16.300
Let's do 88 first.

1209
01:18:25.200 --> 01:18:28.600
So even the graphic the code I have is actually from side pie.

1210
01:18:28.600 --> 01:18:31.400
 So I'm gonna let me import although numpy does

1211
01:18:31.400 --> 01:18:34.200
 extend Psy pie. But anyway, sa pi,

1212
01:18:36.600 --> 01:18:37.500
Dot

1213
01:18:39.900 --> 01:18:41.300
I'm actually just leave it at that.

1214
01:18:42.700 --> 01:18:45.100
sci-fi linear algebra

1215
01:18:45.900 --> 01:18:47.000
or the normalize

1216
01:18:55.100 --> 01:18:55.300
why?

1217
01:19:11.300 --> 01:19:11.600
Okay. There we go.

1218
01:19:14.500 --> 01:19:16.900
So that's how you orthonalizing python.

1219
01:19:17.800 --> 01:19:20.600
That's the first that's so this is the Matrix. This is

1220
01:19:20.600 --> 01:19:22.900
 the Matrix U, right? This is u,

1221
01:19:24.200 --> 01:19:24.900
I come back here.

1222
01:19:26.600 --> 01:19:27.600
That's the U Matrix.

1223
01:19:30.700 --> 01:19:31.000
Okay.

1224
01:19:34.500 --> 01:19:36.100
And then we have the V Matrix.

1225
01:19:40.300 --> 01:19:41.800
That's step number six.

1226
01:19:57.500 --> 01:19:57.500
V

1227
01:19:59.700 --> 01:20:00.900
So if we print U.

1228
01:20:05.900 --> 01:20:06.900
We print V.

1229
01:20:12.600 --> 01:20:13.300
So this one?

1230
01:20:27.100 --> 01:20:28.500
0.70

1231
01:20:29.200 --> 01:20:31.300
so we have the same Matrix up here.

1232
01:20:36.100 --> 01:20:37.700
and for s

1233
01:20:39.600 --> 01:20:42.300
for us we will we have up here. Right? We took we

1234
01:20:42.300 --> 01:20:43.500
 have Sigma 1 and sigma 2

1235
01:20:44.400 --> 01:20:45.900
so for the Matrix as

1236
01:20:50.800 --> 01:20:52.400
That would be step.

1237
01:20:53.900 --> 01:20:56.200
Four step four we put into a

1238
01:20:56.200 --> 01:20:57.200
 matrix. So step four.

1239
01:20:58.800 --> 01:21:01.600
We have a new Matrix called S and P dot

1240
01:21:01.600 --> 01:21:01.800
 array.

1241
01:21:06.700 --> 01:21:07.200
which will be

1242
01:21:10.300 --> 01:21:12.900
let me just reorder these this will be Sigma.

1243
01:21:41.400 --> 01:21:41.900
want to

1244
01:21:53.600 --> 01:21:54.000
Be fine.

1245
01:22:02.700 --> 01:22:05.200
So we have Sigma 1 and

1246
01:22:05.200 --> 01:22:05.500
 0.

1247
01:22:08.200 --> 01:22:08.900
That's the first.

1248
01:22:11.300 --> 01:22:11.600
vector

1249
01:22:13.600 --> 01:22:14.500
the other vector

1250
01:22:15.100 --> 01:22:15.900
is zero

1251
01:22:17.200 --> 01:22:18.100
Sigma 2

1252
01:22:21.400 --> 01:22:21.800
Okay.

1253
01:22:24.800 --> 01:22:26.100
SUV

1254
01:22:28.900 --> 01:22:31.400
There's s there is

1255
01:22:31.400 --> 01:22:32.300
 you there is V.

1256
01:22:33.600 --> 01:22:35.400
If you put these three vectors together.

1257
01:22:36.400 --> 01:22:39.700
So I'm going to go NP. This is Step. This is

1258
01:22:39.700 --> 01:22:42.300
 no not this we've already done steps six at

1259
01:22:42.300 --> 01:22:42.400
 this point.

1260
01:22:43.300 --> 01:22:46.300
But I'm just gonna multiply all three vectors. I'm

1261
01:22:46.300 --> 01:22:50.000
 going to go math multiplication now math multiple takes two arguments at

1262
01:22:49.100 --> 01:22:50.100
 a time.

1263
01:22:51.100 --> 01:22:53.400
So I'm gonna first add multiply the first two vectors.

1264
01:22:56.300 --> 01:22:56.600
that's

1265
01:22:58.300 --> 01:23:01.300
You and us so I'm going to first multiply these together.

1266
01:23:02.900 --> 01:23:04.000
So I will be.

1267
01:23:09.100 --> 01:23:10.100
You and this.

1268
01:23:16.800 --> 01:23:19.200
And then this will give us a new

1269
01:23:19.200 --> 01:23:22.000
 Matrix which I'll multiply with v.

1270
01:23:23.200 --> 01:23:24.700
so NP Dot

1271
01:23:26.700 --> 01:23:27.900
matrix multiplication

1272
01:23:29.100 --> 01:23:31.600
this new Matrix with v

1273
01:23:37.300 --> 01:23:38.500
Let me run these cells again.

1274
01:23:47.600 --> 01:23:48.600
And if I come back here.

1275
01:23:50.500 --> 01:23:53.500
You can see we return to the original Matrix

1276
01:23:53.500 --> 01:23:54.800
 10 to 5 11.

1277
01:23:56.300 --> 01:23:57.100
10 2 5 11

1278
01:24:02.400 --> 01:24:05.300
and it's already well. We already went away from one

1279
01:24:05.300 --> 01:24:06.000
 one minute away from

1280
01:24:07.300 --> 01:24:08.000
the end of the session

1281
01:24:08.600 --> 01:24:08.800
but

1282
01:24:14.200 --> 01:24:15.000
let me type this.

1283
01:24:15.700 --> 01:24:16.200
to get

1284
01:24:17.800 --> 01:24:21.100
the orthogonalized so the orthogonalized orthogonal

1285
01:24:20.100 --> 01:24:22.400
 Matrix would be the Matrix.

1286
01:24:25.600 --> 01:24:27.400
This isn't correct. By the way, this is s

1287
01:24:28.300 --> 01:24:29.000
this is s

1288
01:24:33.400 --> 01:24:34.500
The Matrix U

1289
01:24:40.100 --> 01:24:41.100
The Matrix U

1290
01:24:44.000 --> 01:24:44.400
is

1291
01:24:46.200 --> 01:24:49.400
The gram Schmidt algorithm applied to that.

1292
01:24:51.100 --> 01:24:53.800
And we would be the grammishment algorithm applied to this.

1293
01:24:55.600 --> 01:24:55.900
so you

1294
01:24:58.200 --> 01:25:01.300
will be the let me type in text.

1295
01:25:02.900 --> 01:25:04.100
Ram Schmidt

1296
01:25:05.100 --> 01:25:06.400
algorithm applied to

1297
01:25:09.800 --> 01:25:10.800
ATA

1298
01:25:11.500 --> 01:25:11.800
a

1299
01:25:24.400 --> 01:25:26.200
and V is the same thing, but

1300
01:25:31.200 --> 01:25:32.100
the other way around

1301
01:25:36.700 --> 01:25:38.900
okay times a transpose.

1302
01:25:40.600 --> 01:25:43.500
Let me double check that make sure I didn't get the orders wrong.

1303
01:26:09.400 --> 01:26:10.700
Yeah, I think this is the correct order.

1304
01:26:12.100 --> 01:26:15.300
But I'll double check it anyway, but any either way, I mean, that's

1305
01:26:15.300 --> 01:26:16.700
 how you get these two matrices.

1306
01:26:17.800 --> 01:26:20.100
Okay, just keep in mind that you do not

1307
01:26:20.100 --> 01:26:23.500
 apply the grams with algorithm through just a on its own you have

1308
01:26:23.500 --> 01:26:26.900
 to multiply you have to apply this algorithm to

1309
01:26:26.900 --> 01:26:29.400
 the product of these two matrices. This

1310
01:26:29.400 --> 01:26:30.600
 is the distinction in SVD.

1311
01:26:31.100 --> 01:26:34.100
Now finally if I bring you back to numpy.

1312
01:26:34.800 --> 01:26:36.000
We could have done this whole thing.

1313
01:26:37.200 --> 01:26:38.000
using

1314
01:26:40.500 --> 01:26:43.600
the SVD algorithm from numpy. So this would be SVD.

1315
01:26:44.400 --> 01:26:46.800
Let me call a manual for lack of better words.

1316
01:26:48.200 --> 01:26:49.100
but if you want to do this

1317
01:26:51.100 --> 01:26:53.800
There's a very nice method that does this whole thing in one go.

1318
01:26:54.400 --> 01:26:56.200
So I'm gonna have here SVD.

1319
01:27:01.800 --> 01:27:03.400
the SVD method from the pi

1320
01:27:09.800 --> 01:27:12.300
So this will be what NP? I think

1321
01:27:12.300 --> 01:27:13.400
 Lin algebra.

1322
01:27:15.200 --> 01:27:18.200
dot SVD our plus an A

1323
01:27:18.200 --> 01:27:20.200
 and this method will return

1324
01:27:24.400 --> 01:27:25.700
What did you turn values?

1325
01:27:26.500 --> 01:27:29.200
Three vectors USV in that

1326
01:27:29.200 --> 01:27:30.300
 order, so I'm going to go.

1327
01:27:31.800 --> 01:27:32.400
you

1328
01:27:34.200 --> 01:27:34.500
s

1329
01:27:35.500 --> 01:27:36.000
V

1330
01:27:39.200 --> 01:27:41.700
If I print them all print you.

1331
01:27:42.700 --> 01:27:43.600
Let's try to be.

1332
01:27:49.500 --> 01:27:52.100
You see we have to say matrices.

1333
01:27:52.800 --> 01:27:53.600
This is V.

1334
01:27:54.900 --> 01:27:55.900
Like we have up here.

1335
01:27:56.700 --> 01:27:59.700
This is the this is the eigenvector. But what

1336
01:27:59.700 --> 01:28:01.400
 you would do is you would take the values.

1337
01:28:02.500 --> 01:28:04.000
And put them in a square Matrix.

1338
01:28:05.600 --> 01:28:06.900
And of course, that's Matrix U.

1339
01:28:08.900 --> 01:28:10.400
Of course if you want to multiply these together.

1340
01:28:11.700 --> 01:28:13.800
So if it works it perform this operation down here.

1341
01:28:31.200 --> 01:28:34.200
Oh, yeah, because this is not as I need

1342
01:28:34.200 --> 01:28:37.300
 to fix. So yes see because we can't just multiply this vector.

1343
01:28:38.100 --> 01:28:41.200
We need us to be a matrix. So we need

1344
01:28:41.200 --> 01:28:43.200
 us to be a matrix.

1345
01:28:45.200 --> 01:28:48.200
Anyways, that's Matrix up here. It's exactly this one up here.

1346
01:28:57.100 --> 01:28:58.200
this is really redundant but

1347
01:29:00.200 --> 01:29:02.400
What I'm saying is you'll get them say Matrix back.

1348
01:29:04.200 --> 01:29:04.300
now

1349
01:29:08.300 --> 01:29:11.400
Let me put this in here again because this is the this is

1350
01:29:11.400 --> 01:29:12.800
 this I think this was very good.

1351
01:29:13.900 --> 01:29:15.500
very concise clear

1352
01:29:18.400 --> 01:29:21.400
Example of how use gram Schmidt so I'm going to copy this and

1353
01:29:21.400 --> 01:29:23.000
 I will include it here inside.

1354
01:29:24.500 --> 01:29:26.200
this file

1355
01:29:32.500 --> 01:29:33.400
gram Schmidt

1356
01:29:34.800 --> 01:29:36.200
See grab Schmidt.

1357
01:29:38.800 --> 01:29:39.200
Okay.

1358
01:29:41.900 --> 01:29:44.300
I will write this down. Anyway, I will create a

1359
01:29:44.300 --> 01:29:44.800
 markdown file.

1360
01:29:45.600 --> 01:29:49.300
hopefully, you know you remember I mean

1361
01:29:49.300 --> 01:29:51.200
 as long as you know, what I got product is and what the

1362
01:29:54.100 --> 01:29:56.600
the norm or magnitude of a vector is

1363
01:29:57.300 --> 01:29:59.700
well, then, you know, this should completely make sense to you.

1364
01:30:02.200 --> 01:30:05.200
And the only thing special about SVD is that we don't just take the

1365
01:30:05.900 --> 01:30:09.100
we don't just apply grammishment to the origin

1366
01:30:08.100 --> 01:30:09.500
 Matrix, but

1367
01:30:10.600 --> 01:30:12.400
Matrix a times it's transpose.

1368
01:30:13.500 --> 01:30:14.300
That's u and v

1369
01:30:17.200 --> 01:30:19.300
Any questions before I wrap up?

1370
01:30:20.700 --> 01:30:23.800
But let me let me all say this while you think about your question.

1371
01:30:24.700 --> 01:30:25.800
Now that we've covered.

1372
01:30:26.900 --> 01:30:30.000
the steps for performing SVD

1373
01:30:32.800 --> 01:30:35.600
we can then talk now. I know we didn't we didn't

1374
01:30:35.600 --> 01:30:38.800
 do all of these like we did not get to we

1375
01:30:38.800 --> 01:30:41.300
 haven't yet been able to look at an application and I

1376
01:30:41.300 --> 01:30:44.000
 haven't yet talked about PCA. But if you understand SVD

1377
01:30:45.100 --> 01:30:48.100
I mean PC is just a simple small change.

1378
01:30:49.400 --> 01:30:50.400
Nsvd.

1379
01:30:55.600 --> 01:30:58.500
We can we can now start we can start with the applications

1380
01:30:58.500 --> 01:31:00.800
 up so next week Monday rather.

1381
01:31:01.800 --> 01:31:05.100
We will start with tensorflow. So we will see neural networks.

1382
01:31:08.300 --> 01:31:11.700
And you will use PCA for dimensionality reduction.

1383
01:31:13.300 --> 01:31:14.800
And with one example in finance.

1384
01:31:15.900 --> 01:31:16.600
So I have a book.

1385
01:31:19.300 --> 01:31:20.100
It's a very good book by the way.

1386
01:31:24.900 --> 01:31:27.700
Quantitative Finance or quantitative methods

1387
01:31:27.700 --> 01:31:31.200
 in finance. You know, I've I've a

1388
01:31:30.200 --> 01:31:32.900
 number of books in economics.

1389
01:31:34.200 --> 01:31:37.200
And they're surprisingly very good at explaining math.

1390
01:31:38.700 --> 01:31:42.600
mathematical Concepts intuitively differential calculus linear

1391
01:31:41.600 --> 01:31:42.900
 algebra

1392
01:31:43.800 --> 01:31:46.100
I found their explanation not just this

1393
01:31:46.100 --> 01:31:47.800
 book. This is one of them, but just

1394
01:31:49.200 --> 01:31:52.400
I think it cannotics books to a very good job of explaining

1395
01:31:52.400 --> 01:31:54.000
 math concepts like in very simple.

1396
01:31:57.200 --> 01:31:58.700
In very simple ways.

1397
01:32:00.200 --> 01:32:03.800
but I think it also helps that they give you examples and economics so

1398
01:32:04.700 --> 01:32:06.900
Whenever you put Theory and up.

1399
01:32:07.300 --> 01:32:08.700
Or theory and practice together.

1400
01:32:09.400 --> 01:32:11.500
It just makes the learning experience a lot better.

1401
01:32:12.200 --> 01:32:15.300
But yeah, I'm going to give an actual example application of

1402
01:32:15.300 --> 01:32:18.600
 Finance from this book using PCA now that we've covered records.

1403
01:32:20.800 --> 01:32:22.900
Image compression if you remember this picture I showed you.

1404
01:32:24.400 --> 01:32:26.400
image compression with SVD

1405
01:32:29.300 --> 01:32:31.900
We'll go over the code for this.

1406
01:32:33.300 --> 01:32:36.000
It will take SVD on what we will take what we've learned about

1407
01:32:36.600 --> 01:32:36.700
 SVD today.

1408
01:32:38.100 --> 01:32:40.100
So we can see how we can do image compression.

1409
01:32:40.700 --> 01:32:43.100
So computer vision example find example

1410
01:32:43.800 --> 01:32:44.100
and

1411
01:32:45.100 --> 01:32:46.400
dimensional reduction

1412
01:32:47.600 --> 01:32:48.000
everybody

1413
01:32:49.800 --> 01:32:52.200
no questions, right? No quote. No one else any questions before

1414
01:32:52.200 --> 01:32:53.300
 I had the

1415
01:32:54.700 --> 01:32:55.000
okay.

1416
01:32:57.500 --> 01:32:58.200
Very well then.

1417
01:32:59.300 --> 01:33:01.500
Thank you very much. I hope you look forward to Monday.

1418
01:33:03.100 --> 01:33:06.000
Because it's it's gonna be completely practical.

1419
01:33:07.200 --> 01:33:08.500
You will learn about tensorflow.

1420
01:33:09.300 --> 01:33:12.100
So it should be you hopefully will find it very useful

1421
01:33:12.100 --> 01:33:13.800
 in in the real world.

1422
01:33:14.700 --> 01:33:17.500
But thank you everybody. Thank you. Enjoy the rest

1423
01:33:17.500 --> 01:33:20.100
 of your weekend, and I will see you very soon for now. Take care. Bye.
